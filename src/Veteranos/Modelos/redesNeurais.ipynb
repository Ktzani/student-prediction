{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tabulate import tabulate\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Experimentando Diferentes conjuntos de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1) Flatten train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_flatten_train(y_train, y_test): \n",
    "    y_train_flatten = y_train.values.ravel()\n",
    "    y_test_flatten = y_test.values.ravel()\n",
    "\n",
    "    return y_train_flatten, y_test_flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2) Configurando LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_label_encoder(y_train, y_test):\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "    return y_train_encoded, y_test_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3) Padronizar as características (normalização)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_start_scaler(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4) Pré-processando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_one_hot(y_train_encoded, y_test_encoded):\n",
    "    num_classes = len(np.unique(y_train_encoded))\n",
    "\n",
    "    # Converta as classes em vetores one-hot (para a camada de saída)\n",
    "    y_train_onehot = to_categorical(y_train_encoded, num_classes=num_classes)\n",
    "    y_test_onehot = to_categorical(y_test_encoded, num_classes=num_classes)\n",
    "\n",
    "    return y_train_onehot, y_test_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Carregar os dados de treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_array = []\n",
    "y_train_array = []\n",
    "X_test_array = []\n",
    "y_test_array = []  \n",
    "\n",
    "def get_data_from_conjunto(conjunto: int):      \n",
    "\n",
    "    X_train = pd.read_csv(f'../Dados/RedesNeurais/Conjunto_{conjunto+1}/X_train.csv')\n",
    "    y_train = pd.read_csv(f'../Dados/RedesNeurais/Conjunto_{conjunto+1}/y_train.csv')\n",
    "    X_test = pd.read_csv(f'../Dados/RedesNeurais/Conjunto_{conjunto+1}/X_test.csv')\n",
    "    y_test = pd.read_csv(f'../Dados/RedesNeurais/Conjunto_{conjunto+1}/y_test.csv')\n",
    "\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    input = X_train.shape[1]\n",
    "    \n",
    "    y_train, y_test = config_flatten_train(y_train, y_test)\n",
    "    y_train, y_test = config_label_encoder(y_train, y_test)\n",
    "    # y_train, y_test = config_start_scaler(X_train, X_test)\n",
    "    y_train, y_test = config_one_hot(y_train, y_test)\n",
    "\n",
    "    X_train_array.append(X_train)\n",
    "    y_train_array.append(y_train)\n",
    "    X_test_array.append(X_test)\n",
    "    y_test_array.append(y_test)\n",
    "\n",
    "    return num_classes, input, X_train_array, y_train_array, X_test_array, y_test_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3) Montando rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_neural_network(num_classes, input):\n",
    "\n",
    "    neuralNetwork = Sequential()\n",
    "    neuralNetwork.add(Dense(64, input_dim=input, activation='relu'))\n",
    "    neuralNetwork.add(Dense(32, activation='relu'))\n",
    "    neuralNetwork.add(Dense(num_classes, activation='softmax'))  \n",
    "\n",
    "    neuralNetwork.summary()\n",
    "\n",
    "    return neuralNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4) Treinando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cross_validation(X_train, y_train, num_classes, input_dim):\n",
    "\n",
    "    \n",
    "    kfold = IterativeStratification(n_splits=5)\n",
    "\n",
    "    acuracias = []\n",
    "    precisoes = []\n",
    "    revocacoes = []\n",
    "    f1_scores = []\n",
    "\n",
    "    i = 1\n",
    "\n",
    "    best_acuracia = 0.0\n",
    "    best_model = None\n",
    "\n",
    "    for train_index, test_index in kfold.split(X_train, y_train):\n",
    "        print(f'\\nFold {i}')\n",
    "\n",
    "        X_treino_fold, X_teste_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_treino_fold, y_teste_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        X_treino_fold = X_treino_fold.astype('float32')\n",
    "        y_treino_fold = y_treino_fold.astype('float32')\n",
    "        X_teste_fold = X_teste_fold.astype('float32')\n",
    "\n",
    "        neuralNetwork = build_neural_network(num_classes, input_dim)\n",
    "        neuralNetwork.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        neuralNetwork.fit(X_treino_fold, y_treino_fold, epochs=100, batch_size=32)\n",
    "\n",
    "        y_pred = neuralNetwork.predict(X_teste_fold)\n",
    "\n",
    "        y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "        y_teste_labels = np.argmax(y_teste_fold, axis=1)\n",
    "\n",
    "        acuracia = accuracy_score(y_teste_labels, y_pred_labels)\n",
    "        precisao = precision_score(y_teste_labels, y_pred_labels, average='weighted')\n",
    "        revocacao = recall_score(y_teste_labels, y_pred_labels, average='weighted')\n",
    "        f1 = f1_score(y_teste_labels, y_pred_labels, average='weighted')\n",
    "\n",
    "        acuracias.append(acuracia)\n",
    "        precisoes.append(precisao)\n",
    "        revocacoes.append(revocacao)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        # Check if the current model has the best F1-score\n",
    "        if acuracia > best_acuracia:\n",
    "            best_acuracia = acuracia\n",
    "            best_model = neuralNetwork\n",
    "\n",
    "        i = i + 1\n",
    "\n",
    "    # Calculate mean and standard deviation\n",
    "    media_acuracias = np.mean(acuracias)\n",
    "    media_precisoes = np.mean(precisoes)\n",
    "    media_revocacoes = np.mean(revocacoes)\n",
    "    media_f1_scores = np.mean(f1_scores)\n",
    "\n",
    "    desvio_padrao_acuracias = np.std(acuracias)\n",
    "    desvio_padrao_precisoes = np.std(precisoes)\n",
    "    desvio_padrao_revocacoes = np.std(revocacoes)\n",
    "    desvio_padrao_f1_scores = np.std(f1_scores)\n",
    "\n",
    "    # Display results\n",
    "    print('\\n---')\n",
    "    for j in range(len(acuracias)):\n",
    "        print(f'Fold {j + 1}:')\n",
    "        print(f'Acurácia: {acuracias[j]}')\n",
    "        print(f'Precisão: {precisoes[j]}')\n",
    "        print(f'Revocação: {revocacoes[j]}')\n",
    "        print(f'F1-Score: {f1_scores[j]}')\n",
    "        print('---')\n",
    "\n",
    "    print('\\nMédias e Desvios Padrão Gerais:')\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(f'Média Acurácias: {media_acuracias}')\n",
    "    print(f'Desvio Padrão Acurácias: {desvio_padrao_acuracias}\\n')\n",
    "    print(f'Média Precisões: {media_precisoes}')\n",
    "    print(f'Desvio Padrão Precisões: {desvio_padrao_precisoes}\\n')\n",
    "    print(f'Média Revocações: {media_revocacoes}')\n",
    "    print(f'Desvio Padrão Revocações: {desvio_padrao_revocacoes}\\n')\n",
    "    print(f'Média F1-Scores: {media_f1_scores}')\n",
    "    print(f'Desvio Padrão F1-Scores: {desvio_padrao_f1_scores}\\n')\n",
    "\n",
    "    return media_acuracias, media_precisoes, media_revocacoes, media_f1_scores, best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5) Carregando dados e treinando (Cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conjunto 1\n",
      "\n",
      "Fold 1\n",
      "Model: \"sequential_206\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_618 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_619 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_620 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 941us/step - loss: 1.1242 - accuracy: 0.4464\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9410 - accuracy: 0.5071\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9331 - accuracy: 0.5071\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9252 - accuracy: 0.5071\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9171 - accuracy: 0.5071\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9087 - accuracy: 0.5071\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8979 - accuracy: 0.5071\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8917 - accuracy: 0.5071\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8853 - accuracy: 0.5125\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8689 - accuracy: 0.5107\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8573 - accuracy: 0.5125\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8512 - accuracy: 0.5268\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8337 - accuracy: 0.5268\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8193 - accuracy: 0.5393\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8083 - accuracy: 0.5429\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7949 - accuracy: 0.5929\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7772 - accuracy: 0.6000\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7587 - accuracy: 0.6161\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7400 - accuracy: 0.6375\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7157 - accuracy: 0.6411\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7093 - accuracy: 0.6857\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6813 - accuracy: 0.6911\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6551 - accuracy: 0.7054\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6342 - accuracy: 0.7411\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6206 - accuracy: 0.7321\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5992 - accuracy: 0.7482\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5687 - accuracy: 0.7786\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5511 - accuracy: 0.7893\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.5267 - accuracy: 0.8196\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5087 - accuracy: 0.8250\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.4879 - accuracy: 0.8339\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4677 - accuracy: 0.8536\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4508 - accuracy: 0.8679\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4327 - accuracy: 0.8750\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4208 - accuracy: 0.8893\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4078 - accuracy: 0.8732\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3838 - accuracy: 0.9089\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3797 - accuracy: 0.9071\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3618 - accuracy: 0.9000\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3450 - accuracy: 0.9250\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3331 - accuracy: 0.9250\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3231 - accuracy: 0.9446\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3161 - accuracy: 0.9357\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3042 - accuracy: 0.9518\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2978 - accuracy: 0.9286\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2897 - accuracy: 0.9393\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2752 - accuracy: 0.9464\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2680 - accuracy: 0.9625\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2645 - accuracy: 0.9411\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2575 - accuracy: 0.9571\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2479 - accuracy: 0.9429\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2403 - accuracy: 0.9643\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2372 - accuracy: 0.9643\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2350 - accuracy: 0.9393\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2213 - accuracy: 0.9679\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2274 - accuracy: 0.9446\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2105 - accuracy: 0.9750\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2052 - accuracy: 0.9750\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2061 - accuracy: 0.9571\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1976 - accuracy: 0.9732\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2004 - accuracy: 0.9571\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2035 - accuracy: 0.9536\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1857 - accuracy: 0.9643\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1808 - accuracy: 0.9732\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1782 - accuracy: 0.9750\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1731 - accuracy: 0.9732\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1718 - accuracy: 0.9786\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1792 - accuracy: 0.9536\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1799 - accuracy: 0.9518\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1863 - accuracy: 0.9321\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1636 - accuracy: 0.9643\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1669 - accuracy: 0.9554\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1776 - accuracy: 0.9357\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1566 - accuracy: 0.9732\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1517 - accuracy: 0.9679\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1495 - accuracy: 0.9732\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1503 - accuracy: 0.9607\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.1443 - accuracy: 0.9732\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1500 - accuracy: 0.9625\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1457 - accuracy: 0.9661\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1412 - accuracy: 0.9714\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1400 - accuracy: 0.9750\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1395 - accuracy: 0.9679\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1355 - accuracy: 0.9714\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1378 - accuracy: 0.9661\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1432 - accuracy: 0.9500\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1295 - accuracy: 0.9786\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1285 - accuracy: 0.9804\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1271 - accuracy: 0.9768\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1232 - accuracy: 0.9839\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1278 - accuracy: 0.9750\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1265 - accuracy: 0.9714\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1242 - accuracy: 0.9679\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1220 - accuracy: 0.9714\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1292 - accuracy: 0.9518\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1294 - accuracy: 0.9607\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1277 - accuracy: 0.9625\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1193 - accuracy: 0.9732\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1155 - accuracy: 0.9804\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.1283 - accuracy: 0.9571\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "Fold 2\n",
      "Model: \"sequential_207\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_621 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_622 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_623 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 1.0503 - accuracy: 0.5071\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9452 - accuracy: 0.5071\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9358 - accuracy: 0.5071\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9245 - accuracy: 0.5071\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9147 - accuracy: 0.5071\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9043 - accuracy: 0.5071\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8934 - accuracy: 0.5071\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8834 - accuracy: 0.5071\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8716 - accuracy: 0.5071\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8635 - accuracy: 0.5071\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8504 - accuracy: 0.5107\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8384 - accuracy: 0.5143\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.8266 - accuracy: 0.5250\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8149 - accuracy: 0.5304\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8183 - accuracy: 0.5696\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7987 - accuracy: 0.5607\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7944 - accuracy: 0.5482\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7629 - accuracy: 0.5714\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7560 - accuracy: 0.5696\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7405 - accuracy: 0.5946\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7293 - accuracy: 0.6286\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7033 - accuracy: 0.6125\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.6851 - accuracy: 0.6589\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6826 - accuracy: 0.6411\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6592 - accuracy: 0.6821\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6529 - accuracy: 0.6732\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6259 - accuracy: 0.6982\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5998 - accuracy: 0.7482\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5860 - accuracy: 0.7411\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5674 - accuracy: 0.7696\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5504 - accuracy: 0.7804\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5317 - accuracy: 0.8054\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.5168 - accuracy: 0.7946\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4963 - accuracy: 0.8464\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4792 - accuracy: 0.8607\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4655 - accuracy: 0.8554\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4489 - accuracy: 0.8946\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4332 - accuracy: 0.8893\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4209 - accuracy: 0.9179\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4027 - accuracy: 0.9232\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3902 - accuracy: 0.9179\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3821 - accuracy: 0.9143\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.3767 - accuracy: 0.9161\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3518 - accuracy: 0.9446\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3456 - accuracy: 0.9339\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3301 - accuracy: 0.9339\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3248 - accuracy: 0.9339\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3087 - accuracy: 0.9679\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.3010 - accuracy: 0.9571\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2901 - accuracy: 0.9661\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2813 - accuracy: 0.9679\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2764 - accuracy: 0.9625\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2641 - accuracy: 0.9536\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2562 - accuracy: 0.9732\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2557 - accuracy: 0.9589\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2414 - accuracy: 0.9643\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2560 - accuracy: 0.9286\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2339 - accuracy: 0.9661\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2293 - accuracy: 0.9714\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2350 - accuracy: 0.9357\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2164 - accuracy: 0.9821\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2089 - accuracy: 0.9821\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2056 - accuracy: 0.9804\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2099 - accuracy: 0.9625\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1986 - accuracy: 0.9696\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2007 - accuracy: 0.9589\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1901 - accuracy: 0.9821\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1962 - accuracy: 0.9464\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1892 - accuracy: 0.9589\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1770 - accuracy: 0.9750\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1803 - accuracy: 0.9714\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.9446\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1712 - accuracy: 0.9696\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1671 - accuracy: 0.9821\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1794 - accuracy: 0.9518\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1736 - accuracy: 0.9536\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1692 - accuracy: 0.9625\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1608 - accuracy: 0.9750\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1536 - accuracy: 0.9786\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1694 - accuracy: 0.9518\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1602 - accuracy: 0.9589\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1506 - accuracy: 0.9714\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1473 - accuracy: 0.9804\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1429 - accuracy: 0.9804\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1498 - accuracy: 0.9589\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 858us/step - loss: 0.1481 - accuracy: 0.9625\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1393 - accuracy: 0.9714\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1384 - accuracy: 0.9714\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1483 - accuracy: 0.9589\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1381 - accuracy: 0.9750\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1373 - accuracy: 0.9696\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1320 - accuracy: 0.9804\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1321 - accuracy: 0.9732\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1265 - accuracy: 0.9804\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1242 - accuracy: 0.9804\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1275 - accuracy: 0.9786\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1244 - accuracy: 0.9821\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1236 - accuracy: 0.9750\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1207 - accuracy: 0.9821\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1193 - accuracy: 0.9821\n",
      "5/5 [==============================] - 0s 1000us/step\n",
      "\n",
      "Fold 3\n",
      "Model: \"sequential_208\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_624 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_625 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_626 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 1.2905 - accuracy: 0.2982\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9602 - accuracy: 0.5071\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9500 - accuracy: 0.5071\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9421 - accuracy: 0.5071\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9375 - accuracy: 0.5071\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9331 - accuracy: 0.5071\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9298 - accuracy: 0.5071\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9207 - accuracy: 0.5071\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9162 - accuracy: 0.5071\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9103 - accuracy: 0.5071\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9036 - accuracy: 0.5071\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8971 - accuracy: 0.5071\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8909 - accuracy: 0.5071\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8905 - accuracy: 0.5071\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.8783 - accuracy: 0.5071\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8694 - accuracy: 0.5107\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8616 - accuracy: 0.5107\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8533 - accuracy: 0.5214\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8444 - accuracy: 0.5268\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8345 - accuracy: 0.5375\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8252 - accuracy: 0.5625\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8156 - accuracy: 0.5625\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8008 - accuracy: 0.5893\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7886 - accuracy: 0.5857\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7764 - accuracy: 0.6000\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7654 - accuracy: 0.5964\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7528 - accuracy: 0.6357\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7337 - accuracy: 0.6607\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7171 - accuracy: 0.6196\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7014 - accuracy: 0.6750\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6846 - accuracy: 0.6714\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6642 - accuracy: 0.6839\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6494 - accuracy: 0.6857\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6376 - accuracy: 0.7321\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6126 - accuracy: 0.7375\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5901 - accuracy: 0.7500\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5692 - accuracy: 0.7875\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5507 - accuracy: 0.7839\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5310 - accuracy: 0.8018\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5163 - accuracy: 0.8054\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4913 - accuracy: 0.8429\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4758 - accuracy: 0.8643\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4565 - accuracy: 0.8536\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4422 - accuracy: 0.8893\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4237 - accuracy: 0.8946\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4027 - accuracy: 0.8982\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3936 - accuracy: 0.9018\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3721 - accuracy: 0.9161\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3727 - accuracy: 0.9125\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3555 - accuracy: 0.9232\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3333 - accuracy: 0.9429\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3260 - accuracy: 0.9375\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3122 - accuracy: 0.9446\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3009 - accuracy: 0.9482\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3007 - accuracy: 0.9500\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2973 - accuracy: 0.9375\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2879 - accuracy: 0.9268\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2775 - accuracy: 0.9375\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2585 - accuracy: 0.9643\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2537 - accuracy: 0.9482\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2493 - accuracy: 0.9500\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2371 - accuracy: 0.9643\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2374 - accuracy: 0.9482\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2550 - accuracy: 0.9196\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2329 - accuracy: 0.9429\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2175 - accuracy: 0.9643\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2097 - accuracy: 0.9732\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2085 - accuracy: 0.9554\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2063 - accuracy: 0.9589\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1976 - accuracy: 0.9714\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1966 - accuracy: 0.9714\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1944 - accuracy: 0.9554\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1982 - accuracy: 0.9411\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.1889 - accuracy: 0.9589\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1842 - accuracy: 0.9500\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1830 - accuracy: 0.9446\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1869 - accuracy: 0.9536\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.1698 - accuracy: 0.9768\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1679 - accuracy: 0.9696\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1618 - accuracy: 0.9786\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1729 - accuracy: 0.9500\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1592 - accuracy: 0.9696\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1550 - accuracy: 0.9732\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1510 - accuracy: 0.9804\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1531 - accuracy: 0.9768\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1466 - accuracy: 0.9732\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1510 - accuracy: 0.9589\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1484 - accuracy: 0.9518\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1465 - accuracy: 0.9696\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1637 - accuracy: 0.9393\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1480 - accuracy: 0.9643\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1419 - accuracy: 0.9625\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1458 - accuracy: 0.9554\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1335 - accuracy: 0.9821\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1357 - accuracy: 0.9750\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1347 - accuracy: 0.9625\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1394 - accuracy: 0.9589\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.1301 - accuracy: 0.9661\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1239 - accuracy: 0.9768\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1296 - accuracy: 0.9661\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "Fold 4\n",
      "Model: \"sequential_209\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_627 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_628 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_629 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9890 - accuracy: 0.4804\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9427 - accuracy: 0.5071\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9279 - accuracy: 0.5071\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.9160 - accuracy: 0.5071\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9022 - accuracy: 0.5071\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8936 - accuracy: 0.5089\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8774 - accuracy: 0.5268\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8777 - accuracy: 0.5321\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8500 - accuracy: 0.5554\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8475 - accuracy: 0.5625\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8170 - accuracy: 0.5536\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8047 - accuracy: 0.5714\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8016 - accuracy: 0.5839\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7862 - accuracy: 0.6089\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7650 - accuracy: 0.6018\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7569 - accuracy: 0.6196\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7425 - accuracy: 0.6482\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7260 - accuracy: 0.6518\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7020 - accuracy: 0.6607\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6837 - accuracy: 0.6786\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6694 - accuracy: 0.6911\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6529 - accuracy: 0.7000\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6315 - accuracy: 0.7250\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6243 - accuracy: 0.7536\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5952 - accuracy: 0.7536\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5829 - accuracy: 0.7518\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5841 - accuracy: 0.7571\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5515 - accuracy: 0.8036\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5292 - accuracy: 0.7946\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5066 - accuracy: 0.8393\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4907 - accuracy: 0.8446\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4809 - accuracy: 0.8339\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4643 - accuracy: 0.8661\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4658 - accuracy: 0.8339\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4300 - accuracy: 0.8839\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4186 - accuracy: 0.8982\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4114 - accuracy: 0.8857\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3941 - accuracy: 0.9018\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3811 - accuracy: 0.9089\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3718 - accuracy: 0.9125\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3586 - accuracy: 0.9250\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3447 - accuracy: 0.9321\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.3349 - accuracy: 0.9411\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3346 - accuracy: 0.9268\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3137 - accuracy: 0.9429\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3094 - accuracy: 0.9357\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3052 - accuracy: 0.9536\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2922 - accuracy: 0.9500\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.2879 - accuracy: 0.9464\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2851 - accuracy: 0.9446\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2685 - accuracy: 0.9429\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2662 - accuracy: 0.9518\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2539 - accuracy: 0.9500\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2468 - accuracy: 0.9625\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2363 - accuracy: 0.9696\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2347 - accuracy: 0.9589\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.2330 - accuracy: 0.9607\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2263 - accuracy: 0.9571\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2168 - accuracy: 0.9643\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2291 - accuracy: 0.9357\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2119 - accuracy: 0.9714\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2014 - accuracy: 0.9625\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2020 - accuracy: 0.9679\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1983 - accuracy: 0.9732\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.1902 - accuracy: 0.9732\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1905 - accuracy: 0.9643\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1823 - accuracy: 0.9589\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1800 - accuracy: 0.9625\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1744 - accuracy: 0.9714\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1741 - accuracy: 0.9643\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1641 - accuracy: 0.9786\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1623 - accuracy: 0.9804\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1634 - accuracy: 0.9768\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1655 - accuracy: 0.9643\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1622 - accuracy: 0.9607\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1538 - accuracy: 0.9714\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1521 - accuracy: 0.9661\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1494 - accuracy: 0.9696\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1503 - accuracy: 0.9714\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1450 - accuracy: 0.9768\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1419 - accuracy: 0.9786\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1407 - accuracy: 0.9786\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1381 - accuracy: 0.9696\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1441 - accuracy: 0.9625\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1505 - accuracy: 0.9625\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1519 - accuracy: 0.9464\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1684 - accuracy: 0.9321\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1697 - accuracy: 0.9375\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1345 - accuracy: 0.9661\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1278 - accuracy: 0.9750\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1229 - accuracy: 0.9804\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1319 - accuracy: 0.9661\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1290 - accuracy: 0.9625\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1271 - accuracy: 0.9696\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1251 - accuracy: 0.9679\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1228 - accuracy: 0.9732\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1182 - accuracy: 0.9857\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1165 - accuracy: 0.9839\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1249 - accuracy: 0.9625\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1288 - accuracy: 0.9607\n",
      "5/5 [==============================] - 0s 1000us/step\n",
      "\n",
      "Fold 5\n",
      "Model: \"sequential_210\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_630 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_631 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_632 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 1.0705 - accuracy: 0.5071\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9445 - accuracy: 0.5071\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9348 - accuracy: 0.5071\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9277 - accuracy: 0.5071\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9170 - accuracy: 0.5071\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 831us/step - loss: 0.9120 - accuracy: 0.5071\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9055 - accuracy: 0.5071\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9023 - accuracy: 0.5071\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8933 - accuracy: 0.5071\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8884 - accuracy: 0.5071\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8746 - accuracy: 0.5107\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8663 - accuracy: 0.5179\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8572 - accuracy: 0.5250\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8499 - accuracy: 0.5464\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.8327 - accuracy: 0.5446\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.8252 - accuracy: 0.5696\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.8133 - accuracy: 0.5875\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 856us/step - loss: 0.7969 - accuracy: 0.6000\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7846 - accuracy: 0.6071\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7692 - accuracy: 0.6268\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7489 - accuracy: 0.6321\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7365 - accuracy: 0.6571\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7178 - accuracy: 0.6786\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6944 - accuracy: 0.6625\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6840 - accuracy: 0.6857\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6484 - accuracy: 0.6839\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6345 - accuracy: 0.7321\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6045 - accuracy: 0.7518\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5822 - accuracy: 0.7768\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5714 - accuracy: 0.7393\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5310 - accuracy: 0.8214\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5172 - accuracy: 0.7857\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4975 - accuracy: 0.8304\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4832 - accuracy: 0.8304\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4515 - accuracy: 0.8750\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4329 - accuracy: 0.8696\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4187 - accuracy: 0.8964\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3944 - accuracy: 0.8982\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3764 - accuracy: 0.9071\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3617 - accuracy: 0.9375\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.3504 - accuracy: 0.9268\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3339 - accuracy: 0.9464\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3202 - accuracy: 0.9571\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.3208 - accuracy: 0.9268\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2971 - accuracy: 0.9571\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3001 - accuracy: 0.9518\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2819 - accuracy: 0.9464\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2695 - accuracy: 0.9696\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2598 - accuracy: 0.9714\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2560 - accuracy: 0.9536\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2481 - accuracy: 0.9625\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2365 - accuracy: 0.9714\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2306 - accuracy: 0.9696\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2239 - accuracy: 0.9679\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2230 - accuracy: 0.9589\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2323 - accuracy: 0.9411\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2060 - accuracy: 0.9661\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2126 - accuracy: 0.9571\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1980 - accuracy: 0.9750\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1960 - accuracy: 0.9643\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1922 - accuracy: 0.9679\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1846 - accuracy: 0.9750\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1820 - accuracy: 0.9696\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1828 - accuracy: 0.9679\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1735 - accuracy: 0.9786\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1684 - accuracy: 0.9750\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1675 - accuracy: 0.9643\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1641 - accuracy: 0.9714\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1689 - accuracy: 0.9643\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1607 - accuracy: 0.9732\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1598 - accuracy: 0.9714\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1588 - accuracy: 0.9732\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1470 - accuracy: 0.9804\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.1474 - accuracy: 0.9768\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1434 - accuracy: 0.9786\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.1458 - accuracy: 0.9643\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1464 - accuracy: 0.9714\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1362 - accuracy: 0.9804\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1373 - accuracy: 0.9839\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1411 - accuracy: 0.9661\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1387 - accuracy: 0.9661\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1377 - accuracy: 0.9714\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1460 - accuracy: 0.9429\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1502 - accuracy: 0.9518\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1252 - accuracy: 0.9821\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1205 - accuracy: 0.9875\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1296 - accuracy: 0.9714\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1236 - accuracy: 0.9750\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1177 - accuracy: 0.9804\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.1169 - accuracy: 0.9714\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1253 - accuracy: 0.9750\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1167 - accuracy: 0.9821\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1130 - accuracy: 0.9839\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1141 - accuracy: 0.9804\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1134 - accuracy: 0.9857\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1224 - accuracy: 0.9643\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1179 - accuracy: 0.9643\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1398 - accuracy: 0.9393\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1256 - accuracy: 0.9625\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1181 - accuracy: 0.9661\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "---\n",
      "Fold 1:\n",
      "Acurácia: 0.9571428571428572\n",
      "Precisão: 0.9577299412915851\n",
      "Revocação: 0.9571428571428572\n",
      "F1-Score: 0.9570555555555555\n",
      "---\n",
      "Fold 2:\n",
      "Acurácia: 0.9571428571428572\n",
      "Precisão: 0.9594331065759637\n",
      "Revocação: 0.9571428571428572\n",
      "F1-Score: 0.9574803417194722\n",
      "---\n",
      "Fold 3:\n",
      "Acurácia: 0.9428571428571428\n",
      "Precisão: 0.9475249674337819\n",
      "Revocação: 0.9428571428571428\n",
      "F1-Score: 0.943446156240274\n",
      "---\n",
      "Fold 4:\n",
      "Acurácia: 0.9285714285714286\n",
      "Precisão: 0.9341709183673469\n",
      "Revocação: 0.9285714285714286\n",
      "F1-Score: 0.9267541963295761\n",
      "---\n",
      "Fold 5:\n",
      "Acurácia: 0.9785714285714285\n",
      "Precisão: 0.9791606541606541\n",
      "Revocação: 0.9785714285714285\n",
      "F1-Score: 0.9786599259092057\n",
      "---\n",
      "\n",
      "Médias e Desvios Padrão Gerais:\n",
      "----------------------------------------------------------------\n",
      "Média Acurácias: 0.9528571428571428\n",
      "Desvio Padrão Acurácias: 0.016659862556700846\n",
      "\n",
      "Média Precisões: 0.9556039175658663\n",
      "Desvio Padrão Precisões: 0.014823936010614897\n",
      "\n",
      "Média Revocações: 0.9528571428571428\n",
      "Desvio Padrão Revocações: 0.016659862556700846\n",
      "\n",
      "Média F1-Scores: 0.9526792351508167\n",
      "Desvio Padrão F1-Scores: 0.017172981575152874\n",
      "\n",
      "\n",
      "Conjunto 2\n",
      "\n",
      "Fold 1\n",
      "Model: \"sequential_211\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_633 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_634 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_635 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9932 - accuracy: 0.4786\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9695 - accuracy: 0.4750\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9569 - accuracy: 0.4750\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9471 - accuracy: 0.4750\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9329 - accuracy: 0.4750\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9252 - accuracy: 0.4750\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9117 - accuracy: 0.5250\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9060 - accuracy: 0.5036\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8940 - accuracy: 0.5054\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8791 - accuracy: 0.5214\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.8653 - accuracy: 0.5214\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8578 - accuracy: 0.5500\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8520 - accuracy: 0.5500\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8341 - accuracy: 0.5804\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8146 - accuracy: 0.5875\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8118 - accuracy: 0.6036\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7896 - accuracy: 0.5804\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7718 - accuracy: 0.6161\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7570 - accuracy: 0.6446\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7436 - accuracy: 0.6375\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7252 - accuracy: 0.6804\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7109 - accuracy: 0.6554\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6970 - accuracy: 0.6893\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6768 - accuracy: 0.7143\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6549 - accuracy: 0.7071\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6379 - accuracy: 0.7339\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6262 - accuracy: 0.7161\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5997 - accuracy: 0.7536\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5817 - accuracy: 0.7804\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5584 - accuracy: 0.7911\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5396 - accuracy: 0.8125\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5211 - accuracy: 0.8161\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5106 - accuracy: 0.8089\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5011 - accuracy: 0.8411\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4832 - accuracy: 0.8482\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.8321\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.4428 - accuracy: 0.8893\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4275 - accuracy: 0.8929\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4157 - accuracy: 0.9089\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4069 - accuracy: 0.8750\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3859 - accuracy: 0.9179\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3798 - accuracy: 0.9125\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3662 - accuracy: 0.9357\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3669 - accuracy: 0.9000\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3555 - accuracy: 0.9000\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3410 - accuracy: 0.9143\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3409 - accuracy: 0.9268\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3221 - accuracy: 0.9339\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3081 - accuracy: 0.9500\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2999 - accuracy: 0.9464\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2917 - accuracy: 0.9661\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2805 - accuracy: 0.9625\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2725 - accuracy: 0.9679\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2664 - accuracy: 0.9625\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2582 - accuracy: 0.9679\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2632 - accuracy: 0.9429\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2530 - accuracy: 0.9429\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2427 - accuracy: 0.9714\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2473 - accuracy: 0.9357\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2275 - accuracy: 0.9607\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2241 - accuracy: 0.9643\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2163 - accuracy: 0.9750\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.2141 - accuracy: 0.9607\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2160 - accuracy: 0.9554\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2051 - accuracy: 0.9679\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2101 - accuracy: 0.9411\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1952 - accuracy: 0.9750\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1968 - accuracy: 0.9696\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1904 - accuracy: 0.9589\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1814 - accuracy: 0.9768\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1848 - accuracy: 0.9661\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1807 - accuracy: 0.9643\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1734 - accuracy: 0.9643\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1699 - accuracy: 0.9804\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1761 - accuracy: 0.9643\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1833 - accuracy: 0.9536\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1659 - accuracy: 0.9714\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1627 - accuracy: 0.9589\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1544 - accuracy: 0.9821\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1531 - accuracy: 0.9804\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1568 - accuracy: 0.9786\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1675 - accuracy: 0.9554\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1524 - accuracy: 0.9696\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1559 - accuracy: 0.9714\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1529 - accuracy: 0.9643\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1388 - accuracy: 0.9821\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1410 - accuracy: 0.9804\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1464 - accuracy: 0.9571\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9696\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1530 - accuracy: 0.9536\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1482 - accuracy: 0.9554\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1321 - accuracy: 0.9821\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1292 - accuracy: 0.9804\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1345 - accuracy: 0.9679\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1445 - accuracy: 0.9589\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1256 - accuracy: 0.9839\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1219 - accuracy: 0.9857\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1279 - accuracy: 0.9714\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1222 - accuracy: 0.9786\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1261 - accuracy: 0.9696\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "Fold 2\n",
      "Model: \"sequential_212\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_636 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_637 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_638 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 1.0666 - accuracy: 0.4544\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9645 - accuracy: 0.4758\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9506 - accuracy: 0.4758\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9344 - accuracy: 0.4776\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9306 - accuracy: 0.5242\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9130 - accuracy: 0.5098\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9014 - accuracy: 0.5367\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8944 - accuracy: 0.5242\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8764 - accuracy: 0.5170\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8662 - accuracy: 0.5349\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8504 - accuracy: 0.5313\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8499 - accuracy: 0.5689\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8343 - accuracy: 0.5939\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8311 - accuracy: 0.5778\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8085 - accuracy: 0.5832\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8000 - accuracy: 0.6100\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7791 - accuracy: 0.5778\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7691 - accuracy: 0.6118\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7523 - accuracy: 0.6261\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7386 - accuracy: 0.6798\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.7236 - accuracy: 0.6708\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7105 - accuracy: 0.6905\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7049 - accuracy: 0.6565\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6828 - accuracy: 0.7084\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6666 - accuracy: 0.6959\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6531 - accuracy: 0.7209\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6412 - accuracy: 0.6995\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6368 - accuracy: 0.7191\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6103 - accuracy: 0.7585\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6005 - accuracy: 0.7281\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 858us/step - loss: 0.5831 - accuracy: 0.7621\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5627 - accuracy: 0.8032\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5452 - accuracy: 0.8104\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5360 - accuracy: 0.7961\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5201 - accuracy: 0.8229\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5024 - accuracy: 0.8533\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4891 - accuracy: 0.8515\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4718 - accuracy: 0.8658\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4612 - accuracy: 0.8748\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4489 - accuracy: 0.8658\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4295 - accuracy: 0.8998\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4199 - accuracy: 0.9016\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4070 - accuracy: 0.9123\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3928 - accuracy: 0.9088\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3893 - accuracy: 0.9123\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3791 - accuracy: 0.9052\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3625 - accuracy: 0.9320\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3502 - accuracy: 0.9302\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3597 - accuracy: 0.9070\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3540 - accuracy: 0.8927\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3256 - accuracy: 0.9267\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.3241 - accuracy: 0.9231\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3156 - accuracy: 0.9284\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3010 - accuracy: 0.9445\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2990 - accuracy: 0.9445\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2838 - accuracy: 0.9356\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2815 - accuracy: 0.9428\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2750 - accuracy: 0.9481\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2792 - accuracy: 0.9231\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2745 - accuracy: 0.9356\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2580 - accuracy: 0.9606\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2498 - accuracy: 0.9535\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2456 - accuracy: 0.9624\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2388 - accuracy: 0.9571\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2397 - accuracy: 0.9463\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2254 - accuracy: 0.9714\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2203 - accuracy: 0.9678\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2199 - accuracy: 0.9571\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2135 - accuracy: 0.9696\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2084 - accuracy: 0.9624\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2072 - accuracy: 0.9678\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2011 - accuracy: 0.9606\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2055 - accuracy: 0.9589\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1947 - accuracy: 0.9642\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1899 - accuracy: 0.9660\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1901 - accuracy: 0.9624\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1812 - accuracy: 0.9696\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1825 - accuracy: 0.9750\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1879 - accuracy: 0.9571\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1855 - accuracy: 0.9606\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1685 - accuracy: 0.9678\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1751 - accuracy: 0.9571\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1649 - accuracy: 0.9678\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1712 - accuracy: 0.9642\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1581 - accuracy: 0.9767\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1603 - accuracy: 0.9642\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1557 - accuracy: 0.9732\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1535 - accuracy: 0.9732\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1478 - accuracy: 0.9875\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1528 - accuracy: 0.9750\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1503 - accuracy: 0.9678\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1449 - accuracy: 0.9785\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1488 - accuracy: 0.9696\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1427 - accuracy: 0.9714\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1380 - accuracy: 0.9821\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1427 - accuracy: 0.9767\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1498 - accuracy: 0.9642\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1460 - accuracy: 0.9606\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1366 - accuracy: 0.9606\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1352 - accuracy: 0.9714\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "Fold 3\n",
      "Model: \"sequential_213\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_639 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_640 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_641 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9869 - accuracy: 0.4669\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9823 - accuracy: 0.4615\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9465 - accuracy: 0.4776\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9414 - accuracy: 0.4794\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9269 - accuracy: 0.4848\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9144 - accuracy: 0.4902\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9074 - accuracy: 0.5081\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8988 - accuracy: 0.4991\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8793 - accuracy: 0.5259\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8650 - accuracy: 0.5224\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8514 - accuracy: 0.5367\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8375 - accuracy: 0.5581\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8268 - accuracy: 0.5599\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8138 - accuracy: 0.6029\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7974 - accuracy: 0.5886\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7800 - accuracy: 0.6154\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7793 - accuracy: 0.6029\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7582 - accuracy: 0.6476\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7385 - accuracy: 0.6583\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7328 - accuracy: 0.6798\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7209 - accuracy: 0.6655\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.7013\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6776 - accuracy: 0.7048\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6612 - accuracy: 0.7013\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6450 - accuracy: 0.7174\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6243 - accuracy: 0.7531\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6125 - accuracy: 0.7603\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5981 - accuracy: 0.7496\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.5937 - accuracy: 0.7549\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5623 - accuracy: 0.7728\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5426 - accuracy: 0.8014\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5249 - accuracy: 0.8122\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5126 - accuracy: 0.8265\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5201 - accuracy: 0.7782\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4852 - accuracy: 0.8336\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4691 - accuracy: 0.8462\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4521 - accuracy: 0.8533\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4502 - accuracy: 0.8712\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4254 - accuracy: 0.8891\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4122 - accuracy: 0.8909\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3953 - accuracy: 0.9106\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3847 - accuracy: 0.9088\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3757 - accuracy: 0.9159\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3683 - accuracy: 0.9070\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3497 - accuracy: 0.9195\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3484 - accuracy: 0.9159\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3286 - accuracy: 0.9356\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3221 - accuracy: 0.9356\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3104 - accuracy: 0.9535\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3039 - accuracy: 0.9392\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2965 - accuracy: 0.9338\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2920 - accuracy: 0.9284\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2780 - accuracy: 0.9410\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2699 - accuracy: 0.9571\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2634 - accuracy: 0.9499\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2673 - accuracy: 0.9428\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2500 - accuracy: 0.9660\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2468 - accuracy: 0.9571\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2428 - accuracy: 0.9481\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2376 - accuracy: 0.9517\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2304 - accuracy: 0.9553\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2201 - accuracy: 0.9660\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.2170 - accuracy: 0.9678\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2153 - accuracy: 0.9553\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2100 - accuracy: 0.9624\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2009 - accuracy: 0.9767\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1981 - accuracy: 0.9785\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2125 - accuracy: 0.9338\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1925 - accuracy: 0.9750\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1896 - accuracy: 0.9714\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1918 - accuracy: 0.9499\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1791 - accuracy: 0.9821\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1851 - accuracy: 0.9714\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1805 - accuracy: 0.9589\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1807 - accuracy: 0.9589\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1724 - accuracy: 0.9714\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1686 - accuracy: 0.9857\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1629 - accuracy: 0.9750\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1765 - accuracy: 0.9553\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1638 - accuracy: 0.9606\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1597 - accuracy: 0.9696\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1677 - accuracy: 0.9589\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1577 - accuracy: 0.9642\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1661 - accuracy: 0.9660\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1556 - accuracy: 0.9624\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1668 - accuracy: 0.9338\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1852 - accuracy: 0.9249\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1465 - accuracy: 0.9624\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1409 - accuracy: 0.9911\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1391 - accuracy: 0.9821\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1394 - accuracy: 0.9767\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1398 - accuracy: 0.9785\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1393 - accuracy: 0.9714\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1317 - accuracy: 0.9857\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1296 - accuracy: 0.9821\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1347 - accuracy: 0.9767\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1316 - accuracy: 0.9750\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1325 - accuracy: 0.9750\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1311 - accuracy: 0.9678\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1235 - accuracy: 0.9785\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "Fold 4\n",
      "Model: \"sequential_214\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_642 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_643 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_644 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 1.0048 - accuracy: 0.4617\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9709 - accuracy: 0.4759\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9420 - accuracy: 0.4759\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9396 - accuracy: 0.4938\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9146 - accuracy: 0.5152\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8964 - accuracy: 0.5312\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8762 - accuracy: 0.5223\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.8831 - accuracy: 0.5383\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 940us/step - loss: 0.8587 - accuracy: 0.5330\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8636 - accuracy: 0.5258\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8487 - accuracy: 0.5526\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8234 - accuracy: 0.5829\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8275 - accuracy: 0.5561\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7958 - accuracy: 0.5651\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7800 - accuracy: 0.5882\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7626 - accuracy: 0.6007\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7540 - accuracy: 0.6275\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7370 - accuracy: 0.6221\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7233 - accuracy: 0.6506\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7074 - accuracy: 0.6578\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6925 - accuracy: 0.6684\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.6852 - accuracy: 0.6898\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.6601 - accuracy: 0.6934\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6393 - accuracy: 0.7184\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.6376 - accuracy: 0.7130\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6184 - accuracy: 0.7130\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5893 - accuracy: 0.7861\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.5671 - accuracy: 0.7879\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5565 - accuracy: 0.8004\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5332 - accuracy: 0.8075\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5152 - accuracy: 0.8182\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.8253\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4890 - accuracy: 0.8538\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4578 - accuracy: 0.8717\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4456 - accuracy: 0.8717\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4252 - accuracy: 0.8966\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4112 - accuracy: 0.9002\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4004 - accuracy: 0.8948\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3866 - accuracy: 0.9109\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3733 - accuracy: 0.9037\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3615 - accuracy: 0.9091\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3560 - accuracy: 0.9002\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3389 - accuracy: 0.9091\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3235 - accuracy: 0.9376\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3183 - accuracy: 0.9323\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3030 - accuracy: 0.9465\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2947 - accuracy: 0.9430\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2870 - accuracy: 0.9483\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2841 - accuracy: 0.9376\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2709 - accuracy: 0.9323\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2937 - accuracy: 0.9073\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2763 - accuracy: 0.9251\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2546 - accuracy: 0.9465\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2420 - accuracy: 0.9483\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2403 - accuracy: 0.9608\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2390 - accuracy: 0.9447\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2278 - accuracy: 0.9661\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2288 - accuracy: 0.9412\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2423 - accuracy: 0.9394\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2210 - accuracy: 0.9537\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2116 - accuracy: 0.9643\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2088 - accuracy: 0.9643\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2015 - accuracy: 0.9554\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.2104 - accuracy: 0.9537\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2048 - accuracy: 0.9661\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1893 - accuracy: 0.9661\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1967 - accuracy: 0.9590\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1934 - accuracy: 0.9626\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1795 - accuracy: 0.9715\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1799 - accuracy: 0.9643\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1759 - accuracy: 0.9679\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1708 - accuracy: 0.9768\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1679 - accuracy: 0.9715\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1654 - accuracy: 0.9661\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1630 - accuracy: 0.9804\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1737 - accuracy: 0.9554\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1717 - accuracy: 0.9519\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1759 - accuracy: 0.9412\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1745 - accuracy: 0.9447\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1606 - accuracy: 0.9661\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1522 - accuracy: 0.9768\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1471 - accuracy: 0.9715\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.1531 - accuracy: 0.9661\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1445 - accuracy: 0.9804\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1462 - accuracy: 0.9697\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1531 - accuracy: 0.9554\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1469 - accuracy: 0.9554\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1615 - accuracy: 0.9447\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1941 - accuracy: 0.9162\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1515 - accuracy: 0.9554\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1457 - accuracy: 0.9590\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1340 - accuracy: 0.9804\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1425 - accuracy: 0.9554\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1460 - accuracy: 0.9519\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1298 - accuracy: 0.9750\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1263 - accuracy: 0.9822\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1228 - accuracy: 0.9750\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1238 - accuracy: 0.9840\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1470 - accuracy: 0.9519\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1366 - accuracy: 0.9626\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "Fold 5\n",
      "Model: \"sequential_215\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_645 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_646 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_647 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 1.1669 - accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9828 - accuracy: 0.4759\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9753 - accuracy: 0.4759\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9652 - accuracy: 0.4759\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9638 - accuracy: 0.4759\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9464 - accuracy: 0.4759\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9366 - accuracy: 0.4759\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9224 - accuracy: 0.4920\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9110 - accuracy: 0.4866\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8969 - accuracy: 0.5098\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8845 - accuracy: 0.5294\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.8758 - accuracy: 0.5651\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8619 - accuracy: 0.5561\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8533 - accuracy: 0.5722\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8409 - accuracy: 0.5740\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8256 - accuracy: 0.5989\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8132 - accuracy: 0.6150\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8012 - accuracy: 0.5971\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7931 - accuracy: 0.6096\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7829 - accuracy: 0.6185\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7709 - accuracy: 0.6310\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7529 - accuracy: 0.6346\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7371 - accuracy: 0.6506\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7267 - accuracy: 0.6595\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7147 - accuracy: 0.6488\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6948 - accuracy: 0.6738\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6820 - accuracy: 0.6827\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6677 - accuracy: 0.6934\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6505 - accuracy: 0.7077\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6364 - accuracy: 0.7291\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6240 - accuracy: 0.7326\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6289 - accuracy: 0.7112\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5990 - accuracy: 0.7451\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5790 - accuracy: 0.7914\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5652 - accuracy: 0.7718\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5502 - accuracy: 0.8039\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5374 - accuracy: 0.8075\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5215 - accuracy: 0.8004\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5178 - accuracy: 0.8378\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5068 - accuracy: 0.8217\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4995 - accuracy: 0.8217\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4703 - accuracy: 0.8538\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4579 - accuracy: 0.8717\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4465 - accuracy: 0.8859\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4410 - accuracy: 0.8841\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4230 - accuracy: 0.8895\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4155 - accuracy: 0.9037\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4066 - accuracy: 0.8788\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3927 - accuracy: 0.9109\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3794 - accuracy: 0.9127\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3663 - accuracy: 0.9216\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3594 - accuracy: 0.9198\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3468 - accuracy: 0.9269\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3393 - accuracy: 0.9287\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3315 - accuracy: 0.9251\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3300 - accuracy: 0.9162\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.3125 - accuracy: 0.9483\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3056 - accuracy: 0.9376\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3001 - accuracy: 0.9323\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2958 - accuracy: 0.9412\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2839 - accuracy: 0.9483\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2831 - accuracy: 0.9234\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2686 - accuracy: 0.9537\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2696 - accuracy: 0.9394\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2587 - accuracy: 0.9572\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2605 - accuracy: 0.9430\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2510 - accuracy: 0.9519\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2443 - accuracy: 0.9643\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2473 - accuracy: 0.9483\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2406 - accuracy: 0.9501\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2293 - accuracy: 0.9572\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2423 - accuracy: 0.9412\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2315 - accuracy: 0.9412\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2321 - accuracy: 0.9340\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2206 - accuracy: 0.9626\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2126 - accuracy: 0.9537\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2126 - accuracy: 0.9679\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2240 - accuracy: 0.9376\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2051 - accuracy: 0.9608\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1941 - accuracy: 0.9822\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1967 - accuracy: 0.9554\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1913 - accuracy: 0.9715\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1907 - accuracy: 0.9661\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1944 - accuracy: 0.9572\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1826 - accuracy: 0.9715\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1845 - accuracy: 0.9661\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1764 - accuracy: 0.9750\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1756 - accuracy: 0.9750\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1848 - accuracy: 0.9483\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1793 - accuracy: 0.9519\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1751 - accuracy: 0.9590\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1698 - accuracy: 0.9608\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1631 - accuracy: 0.9857\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1634 - accuracy: 0.9715\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1947 - accuracy: 0.9340\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1570 - accuracy: 0.9804\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1606 - accuracy: 0.9715\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1563 - accuracy: 0.9715\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1547 - accuracy: 0.9786\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1532 - accuracy: 0.9804\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "---\n",
      "Fold 1:\n",
      "Acurácia: 0.9857142857142858\n",
      "Precisão: 0.9859605911330049\n",
      "Revocação: 0.9857142857142858\n",
      "F1-Score: 0.9857500895094878\n",
      "---\n",
      "Fold 2:\n",
      "Acurácia: 0.9574468085106383\n",
      "Precisão: 0.9595744680851063\n",
      "Revocação: 0.9574468085106383\n",
      "F1-Score: 0.9577076176192644\n",
      "---\n",
      "Fold 3:\n",
      "Acurácia: 0.9787234042553191\n",
      "Precisão: 0.9787625259181015\n",
      "Revocação: 0.9787234042553191\n",
      "F1-Score: 0.9786443709573429\n",
      "---\n",
      "Fold 4:\n",
      "Acurácia: 0.9784172661870504\n",
      "Precisão: 0.9797386580531494\n",
      "Revocação: 0.9784172661870504\n",
      "F1-Score: 0.978123259906007\n",
      "---\n",
      "Fold 5:\n",
      "Acurácia: 0.9712230215827338\n",
      "Precisão: 0.9722488125726793\n",
      "Revocação: 0.9712230215827338\n",
      "F1-Score: 0.9709520287697011\n",
      "---\n",
      "\n",
      "Médias e Desvios Padrão Gerais:\n",
      "----------------------------------------------------------------\n",
      "Média Acurácias: 0.9743049572500055\n",
      "Desvio Padrão Acurácias: 0.009594811526175258\n",
      "\n",
      "Média Precisões: 0.9752570111524083\n",
      "Desvio Padrão Precisões: 0.008965844442876663\n",
      "\n",
      "Média Revocações: 0.9743049572500055\n",
      "Desvio Padrão Revocações: 0.009594811526175258\n",
      "\n",
      "Média F1-Scores: 0.9742354733523607\n",
      "Desvio Padrão F1-Scores: 0.009498322705460645\n",
      "\n",
      "\n",
      "Conjunto 3\n",
      "\n",
      "Fold 1\n",
      "Model: \"sequential_216\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_648 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_649 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_650 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 1.4594 - accuracy: 0.3304\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 1.0175 - accuracy: 0.4946\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9708 - accuracy: 0.4946\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9614 - accuracy: 0.4946\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9557 - accuracy: 0.4946\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9479 - accuracy: 0.4946\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9361 - accuracy: 0.4946\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9351 - accuracy: 0.4946\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9164 - accuracy: 0.4946\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9041 - accuracy: 0.4946\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8960 - accuracy: 0.4964\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8797 - accuracy: 0.5071\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8735 - accuracy: 0.5018\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8556 - accuracy: 0.5125\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8424 - accuracy: 0.5125\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8267 - accuracy: 0.5536\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8174 - accuracy: 0.5446\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8022 - accuracy: 0.5589\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7875 - accuracy: 0.6054\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7808 - accuracy: 0.5929\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7651 - accuracy: 0.6036\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7551 - accuracy: 0.6482\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7414 - accuracy: 0.6304\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7343 - accuracy: 0.6429\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7138 - accuracy: 0.6554\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7085 - accuracy: 0.6750\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6907 - accuracy: 0.6625\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6796 - accuracy: 0.6875\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6700 - accuracy: 0.6982\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6522 - accuracy: 0.7000\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6357 - accuracy: 0.7214\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6229 - accuracy: 0.7321\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6103 - accuracy: 0.7393\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.5945 - accuracy: 0.7411\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5859 - accuracy: 0.7589\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5748 - accuracy: 0.7804\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5607 - accuracy: 0.7982\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5450 - accuracy: 0.7911\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5314 - accuracy: 0.7857\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5109 - accuracy: 0.8125\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4979 - accuracy: 0.8393\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4842 - accuracy: 0.8500\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.8500\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4562 - accuracy: 0.8857\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4477 - accuracy: 0.8589\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.4318 - accuracy: 0.9054\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4216 - accuracy: 0.8929\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4075 - accuracy: 0.9161\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.3948 - accuracy: 0.9179\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3868 - accuracy: 0.9089\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3754 - accuracy: 0.9250\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3647 - accuracy: 0.9214\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3518 - accuracy: 0.9393\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3487 - accuracy: 0.9268\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.9179\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.9268\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3211 - accuracy: 0.9393\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3193 - accuracy: 0.9286\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3145 - accuracy: 0.9375\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2975 - accuracy: 0.9393\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2880 - accuracy: 0.9464\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2938 - accuracy: 0.9304\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2919 - accuracy: 0.9304\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2752 - accuracy: 0.9393\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2669 - accuracy: 0.9518\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2584 - accuracy: 0.9679\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2509 - accuracy: 0.9661\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2457 - accuracy: 0.9607\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2373 - accuracy: 0.9714\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2421 - accuracy: 0.9482\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2315 - accuracy: 0.9661\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.9643\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.9661\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2248 - accuracy: 0.9571\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2147 - accuracy: 0.9661\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2153 - accuracy: 0.9607\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.9589\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.2059 - accuracy: 0.9643\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.9643\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1961 - accuracy: 0.9679\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1910 - accuracy: 0.9696\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1859 - accuracy: 0.9768\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1799 - accuracy: 0.9768\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1898 - accuracy: 0.9589\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1775 - accuracy: 0.9696\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1785 - accuracy: 0.9661\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1763 - accuracy: 0.9679\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1709 - accuracy: 0.9714\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1649 - accuracy: 0.9786\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1651 - accuracy: 0.9804\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1669 - accuracy: 0.9679\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1629 - accuracy: 0.9732\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1599 - accuracy: 0.9732\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1582 - accuracy: 0.9768\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1500 - accuracy: 0.9804\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1490 - accuracy: 0.9732\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1488 - accuracy: 0.9750\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1495 - accuracy: 0.9786\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 818us/step - loss: 0.1417 - accuracy: 0.9714\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1556 - accuracy: 0.9643\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "\n",
      "Fold 2\n",
      "Model: \"sequential_217\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_651 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_652 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_653 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 1.2281 - accuracy: 0.3048\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9861 - accuracy: 0.4938\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9699 - accuracy: 0.4938\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9636 - accuracy: 0.4938\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9539 - accuracy: 0.4938\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9472 - accuracy: 0.4938\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9390 - accuracy: 0.4938\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9362 - accuracy: 0.4938\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9271 - accuracy: 0.4938\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9153 - accuracy: 0.4938\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9040 - accuracy: 0.4938\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8927 - accuracy: 0.4938\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8826 - accuracy: 0.4938\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8734 - accuracy: 0.4955\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8580 - accuracy: 0.5116\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8496 - accuracy: 0.5134\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8351 - accuracy: 0.5401\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8225 - accuracy: 0.5758\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8106 - accuracy: 0.5633\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7947 - accuracy: 0.5936\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7801 - accuracy: 0.6150\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7669 - accuracy: 0.6007\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7532 - accuracy: 0.6471\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7453 - accuracy: 0.6185\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7299 - accuracy: 0.6417\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7138 - accuracy: 0.6399\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7009 - accuracy: 0.6756\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6820 - accuracy: 0.6827\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6684 - accuracy: 0.6898\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.6988\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.7041\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6319 - accuracy: 0.7130\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6164 - accuracy: 0.7291\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.6005 - accuracy: 0.7558\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5853 - accuracy: 0.7291\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.5696 - accuracy: 0.7647\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.5530 - accuracy: 0.7879\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5393 - accuracy: 0.7879\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5279 - accuracy: 0.7950\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.8235\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.8271\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4806 - accuracy: 0.8592\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4677 - accuracy: 0.8610\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4544 - accuracy: 0.8734\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4457 - accuracy: 0.8574\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4315 - accuracy: 0.8948\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4201 - accuracy: 0.8895\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4166 - accuracy: 0.8734\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3921 - accuracy: 0.9287\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3811 - accuracy: 0.9144\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3731 - accuracy: 0.9091\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3712 - accuracy: 0.8984\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.3579 - accuracy: 0.9091\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3511 - accuracy: 0.9180\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3328 - accuracy: 0.9269\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3228 - accuracy: 0.9412\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3139 - accuracy: 0.9519\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3070 - accuracy: 0.9340\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3008 - accuracy: 0.9430\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2970 - accuracy: 0.9234\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2857 - accuracy: 0.9519\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2777 - accuracy: 0.9572\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2699 - accuracy: 0.9590\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2693 - accuracy: 0.9376\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.2606 - accuracy: 0.9501\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2531 - accuracy: 0.9661\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2480 - accuracy: 0.9715\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2420 - accuracy: 0.9661\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.2462 - accuracy: 0.9430\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.2345 - accuracy: 0.9715\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2340 - accuracy: 0.9465\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2213 - accuracy: 0.9733\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2171 - accuracy: 0.9750\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2112 - accuracy: 0.9643\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2119 - accuracy: 0.9643\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2079 - accuracy: 0.9608\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1996 - accuracy: 0.9697\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1931 - accuracy: 0.9750\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2032 - accuracy: 0.9519\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1897 - accuracy: 0.9608\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1864 - accuracy: 0.9679\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1986 - accuracy: 0.9483\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.9501\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1802 - accuracy: 0.9697\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1811 - accuracy: 0.9661\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1724 - accuracy: 0.9768\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1699 - accuracy: 0.9750\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1641 - accuracy: 0.9804\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1622 - accuracy: 0.9857\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1647 - accuracy: 0.9608\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1634 - accuracy: 0.9715\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1575 - accuracy: 0.9750\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1547 - accuracy: 0.9715\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1479 - accuracy: 0.9768\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1637 - accuracy: 0.9537\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1477 - accuracy: 0.9786\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1460 - accuracy: 0.9786\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1500 - accuracy: 0.9643\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1447 - accuracy: 0.9733\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1375 - accuracy: 0.9840\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "Fold 3\n",
      "Model: \"sequential_218\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_654 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_655 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_656 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 1.1825 - accuracy: 0.3107\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.9584 - accuracy: 0.4946\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9431 - accuracy: 0.4946\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9331 - accuracy: 0.4946\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9247 - accuracy: 0.4946\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9131 - accuracy: 0.4946\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9040 - accuracy: 0.4946\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8938 - accuracy: 0.4946\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8832 - accuracy: 0.4946\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8712 - accuracy: 0.5054\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8617 - accuracy: 0.5179\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8500 - accuracy: 0.5196\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8394 - accuracy: 0.5554\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8251 - accuracy: 0.5607\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8123 - accuracy: 0.5821\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.7939 - accuracy: 0.5839\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7815 - accuracy: 0.6107\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7668 - accuracy: 0.6161\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7522 - accuracy: 0.6375\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7397 - accuracy: 0.6339\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7212 - accuracy: 0.6536\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7059 - accuracy: 0.6732\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6825 - accuracy: 0.7000\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6656 - accuracy: 0.7107\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6451 - accuracy: 0.7054\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6263 - accuracy: 0.7161\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6031 - accuracy: 0.7482\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5882 - accuracy: 0.7607\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5561 - accuracy: 0.7661\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5323 - accuracy: 0.7964\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5112 - accuracy: 0.8268\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4866 - accuracy: 0.8357\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4704 - accuracy: 0.8321\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4419 - accuracy: 0.8804\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4191 - accuracy: 0.8893\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4042 - accuracy: 0.8982\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3890 - accuracy: 0.9036\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3747 - accuracy: 0.9089\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3491 - accuracy: 0.9304\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3398 - accuracy: 0.9250\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3232 - accuracy: 0.9357\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3145 - accuracy: 0.9250\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2948 - accuracy: 0.9446\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2840 - accuracy: 0.9571\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2778 - accuracy: 0.9571\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2627 - accuracy: 0.9607\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2591 - accuracy: 0.9536\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2467 - accuracy: 0.9625\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2415 - accuracy: 0.9571\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2353 - accuracy: 0.9482\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2232 - accuracy: 0.9643\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2142 - accuracy: 0.9643\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2084 - accuracy: 0.9714\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2060 - accuracy: 0.9625\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2050 - accuracy: 0.9661\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2062 - accuracy: 0.9536\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1967 - accuracy: 0.9607\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1829 - accuracy: 0.9696\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1794 - accuracy: 0.9661\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1760 - accuracy: 0.9679\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1725 - accuracy: 0.9732\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1654 - accuracy: 0.9786\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1655 - accuracy: 0.9750\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1605 - accuracy: 0.9750\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1612 - accuracy: 0.9750\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1648 - accuracy: 0.9607\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1631 - accuracy: 0.9607\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1507 - accuracy: 0.9732\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1481 - accuracy: 0.9732\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1408 - accuracy: 0.9786\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1471 - accuracy: 0.9750\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1463 - accuracy: 0.9661\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1370 - accuracy: 0.9732\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1403 - accuracy: 0.9661\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1358 - accuracy: 0.9732\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9607\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1301 - accuracy: 0.9714\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1239 - accuracy: 0.9821\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1295 - accuracy: 0.9768\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1306 - accuracy: 0.9643\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1229 - accuracy: 0.9786\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1211 - accuracy: 0.9804\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1178 - accuracy: 0.9804\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1201 - accuracy: 0.9839\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1129 - accuracy: 0.9804\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1220 - accuracy: 0.9625\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1169 - accuracy: 0.9804\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1141 - accuracy: 0.9804\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1218 - accuracy: 0.9643\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1223 - accuracy: 0.9571\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1211 - accuracy: 0.9571\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1124 - accuracy: 0.9732\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1071 - accuracy: 0.9804\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1042 - accuracy: 0.9857\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0999 - accuracy: 0.9893\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.1110 - accuracy: 0.9679\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1130 - accuracy: 0.9643\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1091 - accuracy: 0.9768\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0983 - accuracy: 0.9821\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1008 - accuracy: 0.9804\n",
      "5/5 [==============================] - 0s 1000us/step\n",
      "\n",
      "Fold 4\n",
      "Model: \"sequential_219\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_657 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_658 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_659 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 1.1453 - accuracy: 0.4607\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9606 - accuracy: 0.4946\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9444 - accuracy: 0.4946\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9291 - accuracy: 0.4946\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9143 - accuracy: 0.4946\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9005 - accuracy: 0.4946\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8954 - accuracy: 0.4982\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8743 - accuracy: 0.4964\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8595 - accuracy: 0.5179\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8517 - accuracy: 0.5393\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8329 - accuracy: 0.5554\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8164 - accuracy: 0.5679\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8008 - accuracy: 0.5857\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7840 - accuracy: 0.5946\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7723 - accuracy: 0.6036\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7550 - accuracy: 0.6286\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7364 - accuracy: 0.6339\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7298 - accuracy: 0.6571\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7099 - accuracy: 0.6714\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6840 - accuracy: 0.6839\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6770 - accuracy: 0.6786\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.7143\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6264 - accuracy: 0.7125\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6122 - accuracy: 0.7411\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5935 - accuracy: 0.7464\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5770 - accuracy: 0.7536\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5547 - accuracy: 0.7839\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5318 - accuracy: 0.7875\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5082 - accuracy: 0.8214\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5022 - accuracy: 0.8196\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4767 - accuracy: 0.8589\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4533 - accuracy: 0.8714\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4405 - accuracy: 0.8643\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4236 - accuracy: 0.8875\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4086 - accuracy: 0.9125\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3981 - accuracy: 0.9054\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4018 - accuracy: 0.8875\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3667 - accuracy: 0.9161\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3556 - accuracy: 0.9268\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3462 - accuracy: 0.9268\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3299 - accuracy: 0.9411\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3237 - accuracy: 0.9393\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3133 - accuracy: 0.9411\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3033 - accuracy: 0.9375\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2979 - accuracy: 0.9357\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2893 - accuracy: 0.9411\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2753 - accuracy: 0.9482\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2722 - accuracy: 0.9446\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.2679 - accuracy: 0.9375\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2503 - accuracy: 0.9571\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2493 - accuracy: 0.9518\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2391 - accuracy: 0.9589\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2309 - accuracy: 0.9714\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2328 - accuracy: 0.9446\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2503 - accuracy: 0.9196\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2437 - accuracy: 0.9214\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2124 - accuracy: 0.9679\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2044 - accuracy: 0.9714\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2073 - accuracy: 0.9536\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1951 - accuracy: 0.9732\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1906 - accuracy: 0.9786\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.9714\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1850 - accuracy: 0.9732\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1899 - accuracy: 0.9518\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1809 - accuracy: 0.9661\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1780 - accuracy: 0.9679\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1905 - accuracy: 0.9500\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1717 - accuracy: 0.9679\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1775 - accuracy: 0.9554\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1715 - accuracy: 0.9536\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1695 - accuracy: 0.9643\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1690 - accuracy: 0.9464\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1590 - accuracy: 0.9696\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1651 - accuracy: 0.9446\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1532 - accuracy: 0.9714\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1583 - accuracy: 0.9643\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1495 - accuracy: 0.9714\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1422 - accuracy: 0.9821\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1631 - accuracy: 0.9500\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1453 - accuracy: 0.9661\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1392 - accuracy: 0.9786\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1432 - accuracy: 0.9679\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1400 - accuracy: 0.9768\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1341 - accuracy: 0.9750\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1385 - accuracy: 0.9661\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1311 - accuracy: 0.9696\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1240 - accuracy: 0.9786\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1327 - accuracy: 0.9696\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1271 - accuracy: 0.9768\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1240 - accuracy: 0.9750\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1208 - accuracy: 0.9750\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1234 - accuracy: 0.9768\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1182 - accuracy: 0.9786\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1163 - accuracy: 0.9786\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1151 - accuracy: 0.9768\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1254 - accuracy: 0.9679\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1210 - accuracy: 0.9696\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1106 - accuracy: 0.9821\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1239 - accuracy: 0.9661\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1130 - accuracy: 0.9839\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "Fold 5\n",
      "Model: \"sequential_220\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_660 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_661 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_662 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9737 - accuracy: 0.4830\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9457 - accuracy: 0.4937\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9257 - accuracy: 0.4937\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9089 - accuracy: 0.4937\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8987 - accuracy: 0.5098\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.8854 - accuracy: 0.5045\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8770 - accuracy: 0.5474\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8610 - accuracy: 0.5581\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8415 - accuracy: 0.5707\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8306 - accuracy: 0.5742\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8172 - accuracy: 0.5564\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7995 - accuracy: 0.5939\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7916 - accuracy: 0.6082\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7696 - accuracy: 0.6190\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7624 - accuracy: 0.6047\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7706 - accuracy: 0.6118\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7299 - accuracy: 0.6333\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7042 - accuracy: 0.6619\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6934 - accuracy: 0.6583\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6762 - accuracy: 0.6565\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6701 - accuracy: 0.6798\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6461 - accuracy: 0.6923\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6300 - accuracy: 0.6977\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6100 - accuracy: 0.7281\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6085 - accuracy: 0.7013\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5893 - accuracy: 0.7513\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5631 - accuracy: 0.7424\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5464 - accuracy: 0.7853\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5289 - accuracy: 0.7853\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5125 - accuracy: 0.7818\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4952 - accuracy: 0.8283\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4936 - accuracy: 0.7943\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4689 - accuracy: 0.8694\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4580 - accuracy: 0.8497\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4489 - accuracy: 0.8658\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4313 - accuracy: 0.8301\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4172 - accuracy: 0.9052\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4105 - accuracy: 0.8605\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3942 - accuracy: 0.9016\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3844 - accuracy: 0.9141\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3737 - accuracy: 0.9123\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3603 - accuracy: 0.9123\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3539 - accuracy: 0.9159\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3511 - accuracy: 0.9195\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3332 - accuracy: 0.9267\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3217 - accuracy: 0.9374\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3245 - accuracy: 0.9141\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3028 - accuracy: 0.9410\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2948 - accuracy: 0.9463\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2905 - accuracy: 0.9445\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2968 - accuracy: 0.9267\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2740 - accuracy: 0.9517\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2687 - accuracy: 0.9463\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2597 - accuracy: 0.9624\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2557 - accuracy: 0.9463\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2592 - accuracy: 0.9392\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2460 - accuracy: 0.9481\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2387 - accuracy: 0.9678\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.2320 - accuracy: 0.9696\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2302 - accuracy: 0.9571\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2279 - accuracy: 0.9660\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2207 - accuracy: 0.9642\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2160 - accuracy: 0.9660\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2198 - accuracy: 0.9553\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2200 - accuracy: 0.9410\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2035 - accuracy: 0.9678\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2011 - accuracy: 0.9624\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2004 - accuracy: 0.9678\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1888 - accuracy: 0.9678\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1857 - accuracy: 0.9732\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1793 - accuracy: 0.9732\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.1942 - accuracy: 0.9553\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1822 - accuracy: 0.9642\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1783 - accuracy: 0.9642\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1680 - accuracy: 0.9750\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1744 - accuracy: 0.9642\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1695 - accuracy: 0.9678\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1643 - accuracy: 0.9696\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1676 - accuracy: 0.9696\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1688 - accuracy: 0.9660\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1620 - accuracy: 0.9553\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1533 - accuracy: 0.9785\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1608 - accuracy: 0.9714\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1505 - accuracy: 0.9803\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1527 - accuracy: 0.9732\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1654 - accuracy: 0.9571\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1433 - accuracy: 0.9803\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1469 - accuracy: 0.9589\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1419 - accuracy: 0.9750\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1433 - accuracy: 0.9732\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1421 - accuracy: 0.9821\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1370 - accuracy: 0.9696\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1386 - accuracy: 0.9803\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1421 - accuracy: 0.9732\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1502 - accuracy: 0.9481\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1331 - accuracy: 0.9714\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1335 - accuracy: 0.9714\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1276 - accuracy: 0.9785\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1284 - accuracy: 0.9803\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1255 - accuracy: 0.9732\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "---\n",
      "Fold 1:\n",
      "Acurácia: 0.9714285714285714\n",
      "Precisão: 0.9719812925170069\n",
      "Revocação: 0.9714285714285714\n",
      "F1-Score: 0.971256923596042\n",
      "---\n",
      "Fold 2:\n",
      "Acurácia: 0.9784172661870504\n",
      "Precisão: 0.9788397853146055\n",
      "Revocação: 0.9784172661870504\n",
      "F1-Score: 0.978276626294147\n",
      "---\n",
      "Fold 3:\n",
      "Acurácia: 0.9571428571428572\n",
      "Precisão: 0.9585891748003549\n",
      "Revocação: 0.9571428571428572\n",
      "F1-Score: 0.9570658767103964\n",
      "---\n",
      "Fold 4:\n",
      "Acurácia: 0.9285714285714286\n",
      "Precisão: 0.930639455782313\n",
      "Revocação: 0.9285714285714286\n",
      "F1-Score: 0.9274908637873754\n",
      "---\n",
      "Fold 5:\n",
      "Acurácia: 0.9716312056737588\n",
      "Precisão: 0.9721757166193324\n",
      "Revocação: 0.9716312056737588\n",
      "F1-Score: 0.9714624827265628\n",
      "---\n",
      "\n",
      "Médias e Desvios Padrão Gerais:\n",
      "----------------------------------------------------------------\n",
      "Média Acurácias: 0.9614382658007333\n",
      "Desvio Padrão Acurácias: 0.017836301236002095\n",
      "\n",
      "Média Precisões: 0.9624450850067225\n",
      "Desvio Padrão Precisões: 0.01720974571180533\n",
      "\n",
      "Média Revocações: 0.9614382658007333\n",
      "Desvio Padrão Revocações: 0.017836301236002095\n",
      "\n",
      "Média F1-Scores: 0.9611105546229048\n",
      "Desvio Padrão F1-Scores: 0.01817376277338889\n",
      "\n",
      "\n",
      "Conjunto 4\n",
      "\n",
      "Fold 1\n",
      "Model: \"sequential_221\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_663 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_664 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_665 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 1.0403 - accuracy: 0.4393\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9746 - accuracy: 0.4821\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9521 - accuracy: 0.4821\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9433 - accuracy: 0.4821\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9373 - accuracy: 0.4821\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9263 - accuracy: 0.4821\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9210 - accuracy: 0.4857\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9134 - accuracy: 0.4875\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9001 - accuracy: 0.5036\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8927 - accuracy: 0.5054\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8845 - accuracy: 0.5250\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8681 - accuracy: 0.5768\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8603 - accuracy: 0.5304\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8432 - accuracy: 0.5679\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8297 - accuracy: 0.5786\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8154 - accuracy: 0.5768\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7979 - accuracy: 0.6054\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7827 - accuracy: 0.6196\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7674 - accuracy: 0.6196\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.7480 - accuracy: 0.6464\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7281 - accuracy: 0.6518\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7088 - accuracy: 0.6696\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6847 - accuracy: 0.6875\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6707 - accuracy: 0.6911\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6544 - accuracy: 0.6964\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6261 - accuracy: 0.7482\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5988 - accuracy: 0.7357\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5865 - accuracy: 0.7875\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5584 - accuracy: 0.7929\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5354 - accuracy: 0.8286\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5164 - accuracy: 0.8321\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4958 - accuracy: 0.8696\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4793 - accuracy: 0.8661\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4689 - accuracy: 0.8518\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.8839\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4248 - accuracy: 0.8911\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.4148 - accuracy: 0.9000\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3949 - accuracy: 0.9125\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3813 - accuracy: 0.9125\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3709 - accuracy: 0.9375\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3527 - accuracy: 0.9357\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3430 - accuracy: 0.9357\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3394 - accuracy: 0.9161\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3180 - accuracy: 0.9446\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3070 - accuracy: 0.9571\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2976 - accuracy: 0.9643\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2881 - accuracy: 0.9571\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2779 - accuracy: 0.9625\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2791 - accuracy: 0.9446\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2616 - accuracy: 0.9679\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2540 - accuracy: 0.9696\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.2486 - accuracy: 0.9661\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2491 - accuracy: 0.9482\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2477 - accuracy: 0.9393\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2387 - accuracy: 0.9589\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2245 - accuracy: 0.9696\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2203 - accuracy: 0.9589\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2110 - accuracy: 0.9732\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2074 - accuracy: 0.9679\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2061 - accuracy: 0.9750\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1963 - accuracy: 0.9804\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 0.9857\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1861 - accuracy: 0.9821\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1822 - accuracy: 0.9750\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1937 - accuracy: 0.9571\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1871 - accuracy: 0.9571\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1805 - accuracy: 0.9554\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1731 - accuracy: 0.9732\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1670 - accuracy: 0.9750\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1631 - accuracy: 0.9839\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1659 - accuracy: 0.9714\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1955 - accuracy: 0.9304\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1683 - accuracy: 0.9679\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1585 - accuracy: 0.9804\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1685 - accuracy: 0.9482\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1455 - accuracy: 0.9893\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1741 - accuracy: 0.9429\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1532 - accuracy: 0.9571\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1432 - accuracy: 0.9839\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1444 - accuracy: 0.9750\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1555 - accuracy: 0.9536\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1438 - accuracy: 0.9768\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1483 - accuracy: 0.9643\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1391 - accuracy: 0.9750\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1420 - accuracy: 0.9643\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1377 - accuracy: 0.9732\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1324 - accuracy: 0.9768\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1244 - accuracy: 0.9875\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1250 - accuracy: 0.9839\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1309 - accuracy: 0.9750\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1343 - accuracy: 0.9679\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1244 - accuracy: 0.9839\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1200 - accuracy: 0.9821\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1302 - accuracy: 0.9696\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1302 - accuracy: 0.9679\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1188 - accuracy: 0.9857\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1130 - accuracy: 0.9929\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1150 - accuracy: 0.9839\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1135 - accuracy: 0.9911\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.9786\n",
      "5/5 [==============================] - 0s 1000us/step\n",
      "\n",
      "Fold 2\n",
      "Model: \"sequential_222\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_666 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_667 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_668 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1598 - accuracy: 0.4347\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9612 - accuracy: 0.4866\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9467 - accuracy: 0.4830\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9423 - accuracy: 0.4830\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9337 - accuracy: 0.4830\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9270 - accuracy: 0.4830\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9203 - accuracy: 0.4830\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9137 - accuracy: 0.4848\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9070 - accuracy: 0.4902\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9009 - accuracy: 0.4919\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.8882 - accuracy: 0.4991\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8817 - accuracy: 0.4884\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8735 - accuracy: 0.5277\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8677 - accuracy: 0.5027\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8550 - accuracy: 0.5206\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8436 - accuracy: 0.5259\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8330 - accuracy: 0.5456\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8221 - accuracy: 0.5438\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.8121 - accuracy: 0.5671\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8028 - accuracy: 0.5850\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7888 - accuracy: 0.6082\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7760 - accuracy: 0.5850\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7637 - accuracy: 0.6118\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7481 - accuracy: 0.6404\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7304 - accuracy: 0.6351\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7158 - accuracy: 0.6404\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7039 - accuracy: 0.7048\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6812 - accuracy: 0.6905\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6662 - accuracy: 0.7048\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6469 - accuracy: 0.7245\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6286 - accuracy: 0.7496\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6218 - accuracy: 0.7585\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5971 - accuracy: 0.7692\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5993 - accuracy: 0.7889\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5649 - accuracy: 0.8140\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5455 - accuracy: 0.8372\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5270 - accuracy: 0.8479\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5105 - accuracy: 0.8569\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4963 - accuracy: 0.8623\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4812 - accuracy: 0.8855\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4669 - accuracy: 0.8909\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4554 - accuracy: 0.8837\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4366 - accuracy: 0.9016\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4229 - accuracy: 0.9070\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4196 - accuracy: 0.8801\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4013 - accuracy: 0.9106\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3907 - accuracy: 0.9177\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3733 - accuracy: 0.9249\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3646 - accuracy: 0.9428\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3553 - accuracy: 0.9338\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3512 - accuracy: 0.9159\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3372 - accuracy: 0.9320\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3307 - accuracy: 0.9445\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3235 - accuracy: 0.9267\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3128 - accuracy: 0.9428\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3053 - accuracy: 0.9463\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2914 - accuracy: 0.9696\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2857 - accuracy: 0.9606\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2776 - accuracy: 0.9750\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2804 - accuracy: 0.9338\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2690 - accuracy: 0.9589\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2634 - accuracy: 0.9624\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2681 - accuracy: 0.9410\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2758 - accuracy: 0.9159\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2701 - accuracy: 0.9177\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2426 - accuracy: 0.9589\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2318 - accuracy: 0.9785\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2335 - accuracy: 0.9606\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2252 - accuracy: 0.9750\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2197 - accuracy: 0.9839\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.2154 - accuracy: 0.9767\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2111 - accuracy: 0.9803\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2083 - accuracy: 0.9696\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2110 - accuracy: 0.9624\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2119 - accuracy: 0.9481\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1983 - accuracy: 0.9785\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1946 - accuracy: 0.9714\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.1907 - accuracy: 0.9821\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1956 - accuracy: 0.9624\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1926 - accuracy: 0.9571\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1827 - accuracy: 0.9767\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1811 - accuracy: 0.9803\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1784 - accuracy: 0.9696\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1759 - accuracy: 0.9732\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1853 - accuracy: 0.9517\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1685 - accuracy: 0.9857\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1679 - accuracy: 0.9803\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1630 - accuracy: 0.9839\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1656 - accuracy: 0.9696\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1680 - accuracy: 0.9678\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1587 - accuracy: 0.9678\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1564 - accuracy: 0.9785\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1581 - accuracy: 0.9767\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1534 - accuracy: 0.9732\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1512 - accuracy: 0.9821\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1503 - accuracy: 0.9714\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1524 - accuracy: 0.9642\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.9660\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1446 - accuracy: 0.9803\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1389 - accuracy: 0.9839\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "Fold 3\n",
      "Model: \"sequential_223\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_669 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_670 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_671 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 1.3332 - accuracy: 0.3286\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 1.0263 - accuracy: 0.4839\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9863 - accuracy: 0.4839\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9774 - accuracy: 0.4839\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9666 - accuracy: 0.4839\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.9580 - accuracy: 0.4839\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9537 - accuracy: 0.4839\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.9447 - accuracy: 0.4839\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9351 - accuracy: 0.4839\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9274 - accuracy: 0.4839\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9144 - accuracy: 0.4964\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9105 - accuracy: 0.4929\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8997 - accuracy: 0.4857\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8920 - accuracy: 0.5339\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8762 - accuracy: 0.5143\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8609 - accuracy: 0.5429\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8449 - accuracy: 0.5482\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8341 - accuracy: 0.5554\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8220 - accuracy: 0.5696\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8116 - accuracy: 0.5589\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8022 - accuracy: 0.5964\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7787 - accuracy: 0.5839\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7648 - accuracy: 0.6411\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7404 - accuracy: 0.6429\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7258 - accuracy: 0.6411\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7150 - accuracy: 0.6661\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6968 - accuracy: 0.6661\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6642 - accuracy: 0.7071\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6463 - accuracy: 0.7161\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6299 - accuracy: 0.7036\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6082 - accuracy: 0.7625\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5968 - accuracy: 0.7821\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5758 - accuracy: 0.7804\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5458 - accuracy: 0.8125\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5269 - accuracy: 0.8339\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5097 - accuracy: 0.8536\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.4963 - accuracy: 0.8357\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4789 - accuracy: 0.8732\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4566 - accuracy: 0.8893\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4393 - accuracy: 0.8875\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4403 - accuracy: 0.8929\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4208 - accuracy: 0.8946\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4017 - accuracy: 0.9054\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3918 - accuracy: 0.9125\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3755 - accuracy: 0.9304\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3633 - accuracy: 0.9339\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3518 - accuracy: 0.9411\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3408 - accuracy: 0.9482\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3310 - accuracy: 0.9536\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3195 - accuracy: 0.9589\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3223 - accuracy: 0.9214\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3076 - accuracy: 0.9429\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3032 - accuracy: 0.9446\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2870 - accuracy: 0.9625\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2790 - accuracy: 0.9625\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2687 - accuracy: 0.9679\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2686 - accuracy: 0.9607\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2602 - accuracy: 0.9518\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2535 - accuracy: 0.9643\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2430 - accuracy: 0.9571\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2376 - accuracy: 0.9679\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2333 - accuracy: 0.9696\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2312 - accuracy: 0.9679\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2298 - accuracy: 0.9571\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2156 - accuracy: 0.9750\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2121 - accuracy: 0.9661\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2139 - accuracy: 0.9571\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1991 - accuracy: 0.9839\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1945 - accuracy: 0.9732\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2004 - accuracy: 0.9643\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1969 - accuracy: 0.9696\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2012 - accuracy: 0.9411\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1921 - accuracy: 0.9625\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1905 - accuracy: 0.9625\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1819 - accuracy: 0.9643\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1761 - accuracy: 0.9696\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1781 - accuracy: 0.9679\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1686 - accuracy: 0.9732\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1608 - accuracy: 0.9875\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1665 - accuracy: 0.9750\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1646 - accuracy: 0.9732\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1565 - accuracy: 0.9839\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1511 - accuracy: 0.9875\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1540 - accuracy: 0.9804\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.1485 - accuracy: 0.9821\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1519 - accuracy: 0.9714\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1447 - accuracy: 0.9786\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1429 - accuracy: 0.9750\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1405 - accuracy: 0.9804\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1358 - accuracy: 0.9875\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1371 - accuracy: 0.9839\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1347 - accuracy: 0.9786\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1346 - accuracy: 0.9786\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1365 - accuracy: 0.9786\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1355 - accuracy: 0.9732\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1323 - accuracy: 0.9661\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1258 - accuracy: 0.9857\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1284 - accuracy: 0.9821\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1384 - accuracy: 0.9589\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1272 - accuracy: 0.9768\n",
      "5/5 [==============================] - 0s 1000us/step\n",
      "\n",
      "Fold 4\n",
      "Model: \"sequential_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_672 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_673 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_674 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 1.0244 - accuracy: 0.4831\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9549 - accuracy: 0.4831\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9396 - accuracy: 0.4831\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9289 - accuracy: 0.4831\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9199 - accuracy: 0.4848\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9068 - accuracy: 0.4866\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8942 - accuracy: 0.4938\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8815 - accuracy: 0.5062\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8715 - accuracy: 0.5098\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8596 - accuracy: 0.5365\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8391 - accuracy: 0.5276\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8442 - accuracy: 0.5633\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8214 - accuracy: 0.5526\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8092 - accuracy: 0.5722\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7874 - accuracy: 0.6007\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7716 - accuracy: 0.6061\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7541 - accuracy: 0.6346\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7333 - accuracy: 0.6453\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7209 - accuracy: 0.6560\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7092 - accuracy: 0.6791\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6831 - accuracy: 0.7023\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6609 - accuracy: 0.6863\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6372 - accuracy: 0.7291\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6158 - accuracy: 0.7736\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.5959 - accuracy: 0.7504\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5779 - accuracy: 0.8021\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5520 - accuracy: 0.7897\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5300 - accuracy: 0.7986\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5122 - accuracy: 0.8378\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4893 - accuracy: 0.8538\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4741 - accuracy: 0.8663\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4551 - accuracy: 0.8859\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4365 - accuracy: 0.8841\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4208 - accuracy: 0.8930\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4042 - accuracy: 0.9020\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3914 - accuracy: 0.9002\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3757 - accuracy: 0.9109\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3587 - accuracy: 0.9216\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3493 - accuracy: 0.9127\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3415 - accuracy: 0.9198\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3218 - accuracy: 0.9323\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3146 - accuracy: 0.9430\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3034 - accuracy: 0.9394\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3000 - accuracy: 0.9412\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2885 - accuracy: 0.9447\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2788 - accuracy: 0.9465\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.2695 - accuracy: 0.9483\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2596 - accuracy: 0.9501\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2564 - accuracy: 0.9483\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2484 - accuracy: 0.9519\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2449 - accuracy: 0.9519\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2357 - accuracy: 0.9537\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2287 - accuracy: 0.9501\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2266 - accuracy: 0.9572\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2187 - accuracy: 0.9537\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2263 - accuracy: 0.9465\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2253 - accuracy: 0.9323\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2138 - accuracy: 0.9554\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2145 - accuracy: 0.9394\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2002 - accuracy: 0.9643\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1938 - accuracy: 0.9697\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.1827 - accuracy: 0.9715\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2198 - accuracy: 0.9162\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1802 - accuracy: 0.9733\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1785 - accuracy: 0.9679\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1687 - accuracy: 0.9768\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1691 - accuracy: 0.9626\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1679 - accuracy: 0.9661\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1706 - accuracy: 0.9643\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1643 - accuracy: 0.9768\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1563 - accuracy: 0.9750\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1527 - accuracy: 0.9893\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1516 - accuracy: 0.9733\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1485 - accuracy: 0.9840\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1471 - accuracy: 0.9733\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1433 - accuracy: 0.9786\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1458 - accuracy: 0.9697\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1486 - accuracy: 0.9697\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1392 - accuracy: 0.9822\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1320 - accuracy: 0.9857\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1335 - accuracy: 0.9786\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1296 - accuracy: 0.9822\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1323 - accuracy: 0.9786\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1325 - accuracy: 0.9768\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1273 - accuracy: 0.9715\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1315 - accuracy: 0.9715\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1181 - accuracy: 0.9840\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1195 - accuracy: 0.9822\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1157 - accuracy: 0.9875\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1161 - accuracy: 0.9857\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1176 - accuracy: 0.9822\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1127 - accuracy: 0.9804\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1105 - accuracy: 0.9911\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1116 - accuracy: 0.9804\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1145 - accuracy: 0.9840\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1102 - accuracy: 0.9804\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1095 - accuracy: 0.9804\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1078 - accuracy: 0.9822\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1147 - accuracy: 0.9733\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1057 - accuracy: 0.9822\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "Fold 5\n",
      "Model: \"sequential_225\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_675 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_676 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_677 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 1.2214 - accuracy: 0.3036\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9834 - accuracy: 0.4821\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9795 - accuracy: 0.4821\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9773 - accuracy: 0.4821\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9714 - accuracy: 0.4821\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9674 - accuracy: 0.4821\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9628 - accuracy: 0.4821\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9589 - accuracy: 0.4821\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9549 - accuracy: 0.4821\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9507 - accuracy: 0.4821\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9468 - accuracy: 0.4821\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9429 - accuracy: 0.4821\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9360 - accuracy: 0.4821\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.9298 - accuracy: 0.4839\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9149 - accuracy: 0.4839\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9071 - accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8886 - accuracy: 0.5107\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8708 - accuracy: 0.5375\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8546 - accuracy: 0.5393\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8378 - accuracy: 0.5357\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8218 - accuracy: 0.5643\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8027 - accuracy: 0.5607\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7884 - accuracy: 0.5732\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7683 - accuracy: 0.5982\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7385 - accuracy: 0.6446\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7218 - accuracy: 0.6375\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6950 - accuracy: 0.6804\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6724 - accuracy: 0.7000\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6513 - accuracy: 0.7196\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6401 - accuracy: 0.7161\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6116 - accuracy: 0.7250\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5879 - accuracy: 0.7750\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5631 - accuracy: 0.7911\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5507 - accuracy: 0.7804\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5345 - accuracy: 0.8107\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5066 - accuracy: 0.8482\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4871 - accuracy: 0.8393\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4794 - accuracy: 0.8643\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4578 - accuracy: 0.8804\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4417 - accuracy: 0.8821\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4267 - accuracy: 0.9000\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4118 - accuracy: 0.9143\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4022 - accuracy: 0.9054\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3882 - accuracy: 0.9196\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3721 - accuracy: 0.9179\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3594 - accuracy: 0.9357\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3495 - accuracy: 0.9500\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3417 - accuracy: 0.9339\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3272 - accuracy: 0.9571\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3215 - accuracy: 0.9411\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3215 - accuracy: 0.9321\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3116 - accuracy: 0.9375\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2924 - accuracy: 0.9536\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2801 - accuracy: 0.9732\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2743 - accuracy: 0.9661\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2679 - accuracy: 0.9679\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2676 - accuracy: 0.9500\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2645 - accuracy: 0.9482\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2495 - accuracy: 0.9679\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2414 - accuracy: 0.9714\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.2365 - accuracy: 0.9679\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2397 - accuracy: 0.9607\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2306 - accuracy: 0.9554\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2228 - accuracy: 0.9696\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2243 - accuracy: 0.9571\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2130 - accuracy: 0.9750\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2263 - accuracy: 0.9536\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2058 - accuracy: 0.9679\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2058 - accuracy: 0.9589\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1969 - accuracy: 0.9768\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1914 - accuracy: 0.9768\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1852 - accuracy: 0.9839\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1886 - accuracy: 0.9768\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1810 - accuracy: 0.9786\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1879 - accuracy: 0.9643\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1741 - accuracy: 0.9786\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1707 - accuracy: 0.9857\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1715 - accuracy: 0.9804\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1670 - accuracy: 0.9821\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1675 - accuracy: 0.9804\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1643 - accuracy: 0.9804\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1661 - accuracy: 0.9786\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1626 - accuracy: 0.9768\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1577 - accuracy: 0.9857\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1486 - accuracy: 0.9893\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1483 - accuracy: 0.9821\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1600 - accuracy: 0.9661\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1587 - accuracy: 0.9607\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1456 - accuracy: 0.9768\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1423 - accuracy: 0.9821\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1393 - accuracy: 0.9893\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1461 - accuracy: 0.9750\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1438 - accuracy: 0.9804\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1386 - accuracy: 0.9750\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1385 - accuracy: 0.9661\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1318 - accuracy: 0.9857\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1327 - accuracy: 0.9804\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1280 - accuracy: 0.9893\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1275 - accuracy: 0.9875\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1247 - accuracy: 0.9839\n",
      "5/5 [==============================] - 0s 1000us/step\n",
      "\n",
      "---\n",
      "Fold 1:\n",
      "Acurácia: 0.9785714285714285\n",
      "Precisão: 0.9791351943076082\n",
      "Revocação: 0.9785714285714285\n",
      "F1-Score: 0.9786478606376751\n",
      "---\n",
      "Fold 2:\n",
      "Acurácia: 0.9787234042553191\n",
      "Precisão: 0.9792750197005516\n",
      "Revocação: 0.9787234042553191\n",
      "F1-Score: 0.9787971853597244\n",
      "---\n",
      "Fold 3:\n",
      "Acurácia: 0.9785714285714285\n",
      "Precisão: 0.9793269746007931\n",
      "Revocação: 0.9785714285714285\n",
      "F1-Score: 0.9786595182537624\n",
      "---\n",
      "Fold 4:\n",
      "Acurácia: 0.9640287769784173\n",
      "Precisão: 0.965123607057329\n",
      "Revocação: 0.9640287769784173\n",
      "F1-Score: 0.9637456461243468\n",
      "---\n",
      "Fold 5:\n",
      "Acurácia: 0.9857142857142858\n",
      "Precisão: 0.9858178053830228\n",
      "Revocação: 0.9857142857142858\n",
      "F1-Score: 0.9856754194710401\n",
      "---\n",
      "\n",
      "Médias e Desvios Padrão Gerais:\n",
      "----------------------------------------------------------------\n",
      "Média Acurácias: 0.9771218648181759\n",
      "Desvio Padrão Acurácias: 0.007099662594148451\n",
      "\n",
      "Média Precisões: 0.9777357202098609\n",
      "Desvio Padrão Precisões: 0.006800669968870389\n",
      "\n",
      "Média Revocações: 0.9771218648181759\n",
      "Desvio Padrão Revocações: 0.007099662594148451\n",
      "\n",
      "Média F1-Scores: 0.9771051259693098\n",
      "Desvio Padrão F1-Scores: 0.007205343337349109\n",
      "\n",
      "\n",
      "Conjunto 5\n",
      "\n",
      "Fold 1\n",
      "Model: \"sequential_226\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_678 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_679 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_680 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 1s 941us/step - loss: 1.8306 - accuracy: 0.2625\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 1.0429 - accuracy: 0.4750\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 1.0129 - accuracy: 0.4750\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9962 - accuracy: 0.4750\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9868 - accuracy: 0.4750\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9804 - accuracy: 0.4750\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9712 - accuracy: 0.4750\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9593 - accuracy: 0.4750\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9516 - accuracy: 0.4750\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9438 - accuracy: 0.4750\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9357 - accuracy: 0.4750\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9215 - accuracy: 0.4750\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9095 - accuracy: 0.4946\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8969 - accuracy: 0.4804\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8954 - accuracy: 0.5089\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8704 - accuracy: 0.5143\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8694 - accuracy: 0.5375\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8493 - accuracy: 0.5411\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8380 - accuracy: 0.5625\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8276 - accuracy: 0.5607\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8150 - accuracy: 0.5821\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7976 - accuracy: 0.5893\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7886 - accuracy: 0.5964\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7727 - accuracy: 0.6339\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7568 - accuracy: 0.6268\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7446 - accuracy: 0.6429\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7171 - accuracy: 0.6714\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6994 - accuracy: 0.6893\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6818 - accuracy: 0.7071\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6634 - accuracy: 0.7179\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6433 - accuracy: 0.7125\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6237 - accuracy: 0.7589\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5955 - accuracy: 0.7679\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5717 - accuracy: 0.8250\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.5577 - accuracy: 0.7982\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5340 - accuracy: 0.8268\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.8464\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5014 - accuracy: 0.8589\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4823 - accuracy: 0.8625\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4618 - accuracy: 0.8804\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4382 - accuracy: 0.9000\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4227 - accuracy: 0.9018\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4057 - accuracy: 0.9232\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3925 - accuracy: 0.9232\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3763 - accuracy: 0.9250\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3624 - accuracy: 0.9393\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3515 - accuracy: 0.9321\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3391 - accuracy: 0.9268\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3262 - accuracy: 0.9357\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3208 - accuracy: 0.9393\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.3119 - accuracy: 0.9393\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2942 - accuracy: 0.9536\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2853 - accuracy: 0.9429\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2776 - accuracy: 0.9518\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2710 - accuracy: 0.9554\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2634 - accuracy: 0.9518\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2554 - accuracy: 0.9589\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2470 - accuracy: 0.9768\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2499 - accuracy: 0.9500\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2466 - accuracy: 0.9393\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2258 - accuracy: 0.9714\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2214 - accuracy: 0.9679\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2186 - accuracy: 0.9625\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.2171 - accuracy: 0.9518\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.2079 - accuracy: 0.9696\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2169 - accuracy: 0.9357\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.2035 - accuracy: 0.9589\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.2032 - accuracy: 0.9625\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1887 - accuracy: 0.9750\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1875 - accuracy: 0.9679\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1893 - accuracy: 0.9518\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1782 - accuracy: 0.9768\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1747 - accuracy: 0.9750\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1819 - accuracy: 0.9714\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1771 - accuracy: 0.9643\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1711 - accuracy: 0.9643\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1737 - accuracy: 0.9625\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1725 - accuracy: 0.9482\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1596 - accuracy: 0.9732\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1600 - accuracy: 0.9714\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1577 - accuracy: 0.9679\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1582 - accuracy: 0.9643\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1497 - accuracy: 0.9768\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1582 - accuracy: 0.9661\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1502 - accuracy: 0.9714\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1463 - accuracy: 0.9732\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1475 - accuracy: 0.9696\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1457 - accuracy: 0.9661\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1408 - accuracy: 0.9768\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1426 - accuracy: 0.9643\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1360 - accuracy: 0.9732\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.9768\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1318 - accuracy: 0.9786\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1314 - accuracy: 0.9839\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1288 - accuracy: 0.9786\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1313 - accuracy: 0.9750\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1309 - accuracy: 0.9696\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1345 - accuracy: 0.9518\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1486 - accuracy: 0.9464\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1238 - accuracy: 0.9768\n",
      "5/5 [==============================] - 0s 1000us/step\n",
      "\n",
      "Fold 2\n",
      "Model: \"sequential_227\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_681 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_682 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_683 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1789 - accuracy: 0.3703\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9910 - accuracy: 0.4741\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9752 - accuracy: 0.4741\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9599 - accuracy: 0.4741\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9487 - accuracy: 0.4741\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9393 - accuracy: 0.4741\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9250 - accuracy: 0.4741\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9207 - accuracy: 0.4919\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9029 - accuracy: 0.5116\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8930 - accuracy: 0.5188\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8804 - accuracy: 0.5206\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8659 - accuracy: 0.5492\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8512 - accuracy: 0.5474\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8374 - accuracy: 0.5653\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8255 - accuracy: 0.5760\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8165 - accuracy: 0.5725\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7965 - accuracy: 0.5707\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7795 - accuracy: 0.5814\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7695 - accuracy: 0.5903\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7559 - accuracy: 0.5993\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7413 - accuracy: 0.6190\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7171 - accuracy: 0.6225\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7004 - accuracy: 0.6601\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6917 - accuracy: 0.6547\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6701 - accuracy: 0.7174\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6508 - accuracy: 0.7030\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6440 - accuracy: 0.7048\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6194 - accuracy: 0.7084\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6054 - accuracy: 0.7424\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5866 - accuracy: 0.7657\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5673 - accuracy: 0.7657\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5473 - accuracy: 0.7710\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5283 - accuracy: 0.8140\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5118 - accuracy: 0.8247\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5057 - accuracy: 0.8497\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4969 - accuracy: 0.8247\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4667 - accuracy: 0.8712\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4501 - accuracy: 0.8694\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4361 - accuracy: 0.8855\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4220 - accuracy: 0.9016\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4101 - accuracy: 0.9070\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3973 - accuracy: 0.9088\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3840 - accuracy: 0.9195\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3809 - accuracy: 0.9034\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3658 - accuracy: 0.9088\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3485 - accuracy: 0.9302\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3397 - accuracy: 0.9267\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3259 - accuracy: 0.9499\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3153 - accuracy: 0.9392\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3117 - accuracy: 0.9320\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3006 - accuracy: 0.9320\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2901 - accuracy: 0.9571\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2849 - accuracy: 0.9517\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2841 - accuracy: 0.9284\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2731 - accuracy: 0.9535\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2610 - accuracy: 0.9624\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2525 - accuracy: 0.9678\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2472 - accuracy: 0.9606\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2416 - accuracy: 0.9463\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2625 - accuracy: 0.9231\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2386 - accuracy: 0.9553\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2281 - accuracy: 0.9642\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2180 - accuracy: 0.9696\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2162 - accuracy: 0.9660\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2135 - accuracy: 0.9606\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2118 - accuracy: 0.9571\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2201 - accuracy: 0.9284\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2154 - accuracy: 0.9302\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2323 - accuracy: 0.9284\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2054 - accuracy: 0.9445\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1904 - accuracy: 0.9642\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1878 - accuracy: 0.9696\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1823 - accuracy: 0.9714\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1819 - accuracy: 0.9750\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.1818 - accuracy: 0.9624\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1731 - accuracy: 0.9767\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1699 - accuracy: 0.9767\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1693 - accuracy: 0.9696\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1709 - accuracy: 0.9571\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1705 - accuracy: 0.9589\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1695 - accuracy: 0.9553\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1631 - accuracy: 0.9660\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1703 - accuracy: 0.9517\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1601 - accuracy: 0.9589\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.1523 - accuracy: 0.9767\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1495 - accuracy: 0.9750\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1502 - accuracy: 0.9803\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1517 - accuracy: 0.9624\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1461 - accuracy: 0.9732\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1473 - accuracy: 0.9785\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1484 - accuracy: 0.9606\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1534 - accuracy: 0.9571\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1383 - accuracy: 0.9696\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1467 - accuracy: 0.9553\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1571 - accuracy: 0.9428\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1481 - accuracy: 0.9499\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1407 - accuracy: 0.9589\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1357 - accuracy: 0.9767\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1375 - accuracy: 0.9535\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1320 - accuracy: 0.9750\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "\n",
      "Fold 3\n",
      "Model: \"sequential_228\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_684 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_685 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_686 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9773 - accuracy: 0.4750\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9583 - accuracy: 0.4750\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9478 - accuracy: 0.4750\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9396 - accuracy: 0.4857\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9295 - accuracy: 0.5054\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9227 - accuracy: 0.5036\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9117 - accuracy: 0.4929\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9011 - accuracy: 0.5232\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8893 - accuracy: 0.5143\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8814 - accuracy: 0.5339\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8748 - accuracy: 0.5357\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8641 - accuracy: 0.5446\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8549 - accuracy: 0.5643\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8390 - accuracy: 0.5554\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8240 - accuracy: 0.5607\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8122 - accuracy: 0.5661\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7952 - accuracy: 0.5786\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7823 - accuracy: 0.5804\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7703 - accuracy: 0.5964\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7525 - accuracy: 0.6018\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7393 - accuracy: 0.6214\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7331 - accuracy: 0.5982\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7016 - accuracy: 0.6125\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6877 - accuracy: 0.6429\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6748 - accuracy: 0.6429\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6512 - accuracy: 0.6946\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6345 - accuracy: 0.6857\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6123 - accuracy: 0.7143\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5893 - accuracy: 0.7268\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5705 - accuracy: 0.7786\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5563 - accuracy: 0.7929\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.5423 - accuracy: 0.7482\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5218 - accuracy: 0.8250\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5097 - accuracy: 0.8018\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4871 - accuracy: 0.8357\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4641 - accuracy: 0.8821\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4468 - accuracy: 0.8821\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4357 - accuracy: 0.9018\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4257 - accuracy: 0.8857\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4020 - accuracy: 0.9250\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3970 - accuracy: 0.8964\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3844 - accuracy: 0.9036\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.3673 - accuracy: 0.9089\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3496 - accuracy: 0.9411\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3357 - accuracy: 0.9446\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3297 - accuracy: 0.9393\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3244 - accuracy: 0.9214\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3043 - accuracy: 0.9554\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2972 - accuracy: 0.9500\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2867 - accuracy: 0.9554\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2830 - accuracy: 0.9429\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2808 - accuracy: 0.9411\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2642 - accuracy: 0.9607\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2580 - accuracy: 0.9571\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2502 - accuracy: 0.9661\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2506 - accuracy: 0.9482\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2382 - accuracy: 0.9643\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.2387 - accuracy: 0.9464\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2324 - accuracy: 0.9554\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2228 - accuracy: 0.9643\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2152 - accuracy: 0.9679\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2101 - accuracy: 0.9696\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.2082 - accuracy: 0.9661\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2034 - accuracy: 0.9750\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2134 - accuracy: 0.9482\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1983 - accuracy: 0.9625\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1941 - accuracy: 0.9696\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2122 - accuracy: 0.9286\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1982 - accuracy: 0.9429\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1867 - accuracy: 0.9661\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1768 - accuracy: 0.9750\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1784 - accuracy: 0.9732\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1709 - accuracy: 0.9732\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1671 - accuracy: 0.9750\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1670 - accuracy: 0.9643\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1709 - accuracy: 0.9607\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1739 - accuracy: 0.9589\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1722 - accuracy: 0.9446\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1959 - accuracy: 0.9393\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1547 - accuracy: 0.9786\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1514 - accuracy: 0.9786\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1530 - accuracy: 0.9786\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1516 - accuracy: 0.9768\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1485 - accuracy: 0.9714\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1523 - accuracy: 0.9696\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1452 - accuracy: 0.9714\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1477 - accuracy: 0.9696\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1383 - accuracy: 0.9821\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9804\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1352 - accuracy: 0.9768\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1368 - accuracy: 0.9679\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1372 - accuracy: 0.9679\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1315 - accuracy: 0.9839\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1359 - accuracy: 0.9714\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1311 - accuracy: 0.9768\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1296 - accuracy: 0.9750\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1263 - accuracy: 0.9768\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1261 - accuracy: 0.9750\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1261 - accuracy: 0.9768\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1452 - accuracy: 0.9554\n",
      "5/5 [==============================] - 0s 1000us/step\n",
      "\n",
      "Fold 4\n",
      "Model: \"sequential_229\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_687 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_688 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_689 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.9958 - accuracy: 0.4768\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9733 - accuracy: 0.4750\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9506 - accuracy: 0.4750\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9341 - accuracy: 0.4750\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9233 - accuracy: 0.4768\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9136 - accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8966 - accuracy: 0.5071\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8853 - accuracy: 0.5214\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8750 - accuracy: 0.5304\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8655 - accuracy: 0.5375\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8427 - accuracy: 0.5607\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8269 - accuracy: 0.5589\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8198 - accuracy: 0.5643\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8114 - accuracy: 0.5929\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7844 - accuracy: 0.6018\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7668 - accuracy: 0.6179\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7560 - accuracy: 0.6232\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7303 - accuracy: 0.6375\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7068 - accuracy: 0.6643\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6973 - accuracy: 0.6857\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6834 - accuracy: 0.7089\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6521 - accuracy: 0.7036\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6310 - accuracy: 0.7143\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6120 - accuracy: 0.7482\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5859 - accuracy: 0.7714\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5662 - accuracy: 0.7875\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5406 - accuracy: 0.7946\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5217 - accuracy: 0.8429\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4971 - accuracy: 0.8518\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4893 - accuracy: 0.8429\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4587 - accuracy: 0.8821\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4444 - accuracy: 0.8839\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4190 - accuracy: 0.8911\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4036 - accuracy: 0.9161\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3850 - accuracy: 0.9214\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3767 - accuracy: 0.9214\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3592 - accuracy: 0.9232\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3407 - accuracy: 0.9286\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3325 - accuracy: 0.9321\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.3169 - accuracy: 0.9482\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3082 - accuracy: 0.9304\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2985 - accuracy: 0.9357\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2826 - accuracy: 0.9429\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2725 - accuracy: 0.9446\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2727 - accuracy: 0.9286\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2538 - accuracy: 0.9500\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2452 - accuracy: 0.9661\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2403 - accuracy: 0.9589\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.2317 - accuracy: 0.9571\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2232 - accuracy: 0.9750\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2276 - accuracy: 0.9464\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2197 - accuracy: 0.9464\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2106 - accuracy: 0.9554\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2069 - accuracy: 0.9625\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1957 - accuracy: 0.9714\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1940 - accuracy: 0.9607\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1987 - accuracy: 0.9500\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2088 - accuracy: 0.9375\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1971 - accuracy: 0.9429\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1789 - accuracy: 0.9589\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1732 - accuracy: 0.9643\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1754 - accuracy: 0.9589\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1669 - accuracy: 0.9714\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1710 - accuracy: 0.9607\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1636 - accuracy: 0.9571\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1642 - accuracy: 0.9643\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1583 - accuracy: 0.9661\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.1633 - accuracy: 0.9643\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1605 - accuracy: 0.9625\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1524 - accuracy: 0.9661\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1458 - accuracy: 0.9714\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1431 - accuracy: 0.9750\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1481 - accuracy: 0.9679\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1430 - accuracy: 0.9607\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.1498 - accuracy: 0.9625\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1452 - accuracy: 0.9679\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1490 - accuracy: 0.9518\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1449 - accuracy: 0.9643\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1405 - accuracy: 0.9661\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1358 - accuracy: 0.9679\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1292 - accuracy: 0.9750\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1356 - accuracy: 0.9643\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1254 - accuracy: 0.9679\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1268 - accuracy: 0.9661\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1335 - accuracy: 0.9607\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1230 - accuracy: 0.9714\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1278 - accuracy: 0.9696\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1249 - accuracy: 0.9786\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1303 - accuracy: 0.9714\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1183 - accuracy: 0.9696\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1153 - accuracy: 0.9839\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1211 - accuracy: 0.9607\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1148 - accuracy: 0.9768\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1164 - accuracy: 0.9696\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1232 - accuracy: 0.9607\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1123 - accuracy: 0.9714\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1172 - accuracy: 0.9571\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1093 - accuracy: 0.9750\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1058 - accuracy: 0.9768\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1143 - accuracy: 0.9714\n",
      "5/5 [==============================] - 0s 1000us/step\n",
      "\n",
      "Fold 5\n",
      "Model: \"sequential_230\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_690 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_691 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_692 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 1.1908 - accuracy: 0.3922\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9780 - accuracy: 0.4724\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9704 - accuracy: 0.4724\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9583 - accuracy: 0.4724\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9524 - accuracy: 0.4742\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9412 - accuracy: 0.4795\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9283 - accuracy: 0.4724\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9194 - accuracy: 0.5098\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9059 - accuracy: 0.5241\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9029 - accuracy: 0.5152\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8793 - accuracy: 0.5223\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8633 - accuracy: 0.5490\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8499 - accuracy: 0.5544\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8364 - accuracy: 0.5651\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8244 - accuracy: 0.5847\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8023 - accuracy: 0.5936\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7848 - accuracy: 0.6007\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7709 - accuracy: 0.6025\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7479 - accuracy: 0.6061\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7300 - accuracy: 0.6310\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7185 - accuracy: 0.6417\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6987 - accuracy: 0.6453\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6750 - accuracy: 0.6738\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6523 - accuracy: 0.6881\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6269 - accuracy: 0.7255\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5991 - accuracy: 0.7291\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5812 - accuracy: 0.7754\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5519 - accuracy: 0.7736\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5360 - accuracy: 0.8004\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5065 - accuracy: 0.8324\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4828 - accuracy: 0.8645\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4673 - accuracy: 0.8503\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4446 - accuracy: 0.8948\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4219 - accuracy: 0.8930\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4047 - accuracy: 0.9020\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3888 - accuracy: 0.9144\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.9287\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.9340\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3377 - accuracy: 0.9394\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3202 - accuracy: 0.9554\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3099 - accuracy: 0.9519\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3029 - accuracy: 0.9340\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2841 - accuracy: 0.9447\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2797 - accuracy: 0.9412\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2748 - accuracy: 0.9465\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2586 - accuracy: 0.9483\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2619 - accuracy: 0.9394\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2426 - accuracy: 0.9643\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2336 - accuracy: 0.9608\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2291 - accuracy: 0.9679\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2203 - accuracy: 0.9661\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2240 - accuracy: 0.9465\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2110 - accuracy: 0.9554\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2109 - accuracy: 0.9572\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2027 - accuracy: 0.9626\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2026 - accuracy: 0.9572\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1915 - accuracy: 0.9679\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1865 - accuracy: 0.9679\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1825 - accuracy: 0.9679\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1869 - accuracy: 0.9590\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1781 - accuracy: 0.9626\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1708 - accuracy: 0.9768\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1651 - accuracy: 0.9786\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1663 - accuracy: 0.9697\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1624 - accuracy: 0.9697\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1591 - accuracy: 0.9679\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1566 - accuracy: 0.9697\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1594 - accuracy: 0.9643\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1637 - accuracy: 0.9590\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1524 - accuracy: 0.9750\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1560 - accuracy: 0.9572\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1452 - accuracy: 0.9697\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1534 - accuracy: 0.9590\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1530 - accuracy: 0.9572\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1380 - accuracy: 0.9679\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1443 - accuracy: 0.9643\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1463 - accuracy: 0.9626\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1528 - accuracy: 0.9519\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1429 - accuracy: 0.9608\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1414 - accuracy: 0.9590\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1316 - accuracy: 0.9750\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1358 - accuracy: 0.9715\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1261 - accuracy: 0.9750\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1266 - accuracy: 0.9804\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1224 - accuracy: 0.9768\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1245 - accuracy: 0.9643\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1245 - accuracy: 0.9750\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.1248 - accuracy: 0.9733\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1247 - accuracy: 0.9643\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1392 - accuracy: 0.9483\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1335 - accuracy: 0.9590\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1225 - accuracy: 0.9715\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1227 - accuracy: 0.9626\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1268 - accuracy: 0.9643\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1281 - accuracy: 0.9572\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1125 - accuracy: 0.9750\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1233 - accuracy: 0.9608\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1099 - accuracy: 0.9750\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1080 - accuracy: 0.9768\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1059 - accuracy: 0.9804\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "---\n",
      "Fold 1:\n",
      "Acurácia: 0.9428571428571428\n",
      "Precisão: 0.9443518252371372\n",
      "Revocação: 0.9428571428571428\n",
      "F1-Score: 0.9422805017976957\n",
      "---\n",
      "Fold 2:\n",
      "Acurácia: 0.9929078014184397\n",
      "Precisão: 0.9931365820178448\n",
      "Revocação: 0.9929078014184397\n",
      "F1-Score: 0.9929251744317354\n",
      "---\n",
      "Fold 3:\n",
      "Acurácia: 0.9571428571428572\n",
      "Precisão: 0.9588052612349287\n",
      "Revocação: 0.9571428571428572\n",
      "F1-Score: 0.9567052492638847\n",
      "---\n",
      "Fold 4:\n",
      "Acurácia: 0.9714285714285714\n",
      "Precisão: 0.9725906631937487\n",
      "Revocação: 0.9714285714285714\n",
      "F1-Score: 0.9715554103201836\n",
      "---\n",
      "Fold 5:\n",
      "Acurácia: 0.9712230215827338\n",
      "Precisão: 0.9713538260300849\n",
      "Revocação: 0.9712230215827338\n",
      "F1-Score: 0.9712028516603055\n",
      "---\n",
      "\n",
      "Médias e Desvios Padrão Gerais:\n",
      "----------------------------------------------------------------\n",
      "Média Acurácias: 0.967111878885949\n",
      "Desvio Padrão Acurácias: 0.01666516464019738\n",
      "\n",
      "Média Precisões: 0.9680476315427488\n",
      "Desvio Padrão Precisões: 0.016173670825708274\n",
      "\n",
      "Média Revocações: 0.967111878885949\n",
      "Desvio Padrão Revocações: 0.01666516464019738\n",
      "\n",
      "Média F1-Scores: 0.966933837494761\n",
      "Desvio Padrão F1-Scores: 0.016897005600322503\n",
      "\n",
      "\n",
      "Conjunto 6\n",
      "\n",
      "Fold 1\n",
      "Model: \"sequential_231\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_693 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_694 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_695 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9514 - accuracy: 0.5152\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9171 - accuracy: 0.5241\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9164 - accuracy: 0.5241\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8916 - accuracy: 0.5241\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8780 - accuracy: 0.5241\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8680 - accuracy: 0.5241\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8501 - accuracy: 0.5276\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8356 - accuracy: 0.5401\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8217 - accuracy: 0.5544\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8014 - accuracy: 0.5722\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.7871 - accuracy: 0.6025\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7718 - accuracy: 0.6132\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7550 - accuracy: 0.6310\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7396 - accuracy: 0.6310\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7212 - accuracy: 0.6417\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7143 - accuracy: 0.6346\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6990 - accuracy: 0.6560\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6777 - accuracy: 0.6863\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6612 - accuracy: 0.6898\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6441 - accuracy: 0.7041\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6294 - accuracy: 0.6934\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.6167 - accuracy: 0.7201\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6022 - accuracy: 0.7219\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5845 - accuracy: 0.7398\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5697 - accuracy: 0.7469\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5531 - accuracy: 0.7772\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5365 - accuracy: 0.7772\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5226 - accuracy: 0.7790\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5018 - accuracy: 0.8039\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4844 - accuracy: 0.8200\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4706 - accuracy: 0.8324\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4576 - accuracy: 0.8520\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4497 - accuracy: 0.8271\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4383 - accuracy: 0.8449\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4189 - accuracy: 0.8663\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.4094 - accuracy: 0.8627\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3858 - accuracy: 0.9073\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3760 - accuracy: 0.8948\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3699 - accuracy: 0.9020\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3559 - accuracy: 0.9073\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3450 - accuracy: 0.9037\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3278 - accuracy: 0.9287\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3333 - accuracy: 0.8948\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3136 - accuracy: 0.9358\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3035 - accuracy: 0.9358\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2963 - accuracy: 0.9340\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.2899 - accuracy: 0.9323\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2795 - accuracy: 0.9358\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2751 - accuracy: 0.9376\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2714 - accuracy: 0.9519\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2592 - accuracy: 0.9537\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2657 - accuracy: 0.9216\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2615 - accuracy: 0.9198\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2459 - accuracy: 0.9430\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2420 - accuracy: 0.9358\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2318 - accuracy: 0.9590\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2239 - accuracy: 0.9537\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2192 - accuracy: 0.9554\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2153 - accuracy: 0.9608\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2155 - accuracy: 0.9608\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2175 - accuracy: 0.9501\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2299 - accuracy: 0.9251\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2413 - accuracy: 0.9180\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1999 - accuracy: 0.9572\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2030 - accuracy: 0.9465\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2041 - accuracy: 0.9394\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1879 - accuracy: 0.9608\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1861 - accuracy: 0.9590\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1776 - accuracy: 0.9661\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1794 - accuracy: 0.9643\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1764 - accuracy: 0.9661\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1735 - accuracy: 0.9697\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1733 - accuracy: 0.9608\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1706 - accuracy: 0.9626\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1639 - accuracy: 0.9733\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1649 - accuracy: 0.9715\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1589 - accuracy: 0.9733\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1590 - accuracy: 0.9626\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1667 - accuracy: 0.9554\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1576 - accuracy: 0.9608\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9715\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1504 - accuracy: 0.9715\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1564 - accuracy: 0.9537\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1592 - accuracy: 0.9465\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1493 - accuracy: 0.9661\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1582 - accuracy: 0.9554\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1526 - accuracy: 0.9572\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1379 - accuracy: 0.9786\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1420 - accuracy: 0.9626\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1348 - accuracy: 0.9750\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1402 - accuracy: 0.9608\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1392 - accuracy: 0.9661\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1338 - accuracy: 0.9733\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1458 - accuracy: 0.9537\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1342 - accuracy: 0.9661\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1295 - accuracy: 0.9768\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1277 - accuracy: 0.9822\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1370 - accuracy: 0.9590\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1253 - accuracy: 0.9768\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1230 - accuracy: 0.9733\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "\n",
      "Fold 2\n",
      "Model: \"sequential_232\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_696 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_697 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_698 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 1.1912 - accuracy: 0.3957\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9462 - accuracy: 0.5241\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9299 - accuracy: 0.5241\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9196 - accuracy: 0.5241\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9166 - accuracy: 0.5241\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9069 - accuracy: 0.5241\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8947 - accuracy: 0.5241\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8894 - accuracy: 0.5241\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8822 - accuracy: 0.5241\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8710 - accuracy: 0.5258\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8592 - accuracy: 0.5241\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8482 - accuracy: 0.5258\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8342 - accuracy: 0.5383\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8234 - accuracy: 0.5455\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8063 - accuracy: 0.5668\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7936 - accuracy: 0.5758\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7874 - accuracy: 0.5900\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7656 - accuracy: 0.6132\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7525 - accuracy: 0.6310\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7425 - accuracy: 0.6310\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7256 - accuracy: 0.6506\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7123 - accuracy: 0.6578\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7013 - accuracy: 0.6774\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6851 - accuracy: 0.6702\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6677 - accuracy: 0.7005\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6626 - accuracy: 0.6845\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6518 - accuracy: 0.7130\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6343 - accuracy: 0.6970\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6274 - accuracy: 0.7344\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5978 - accuracy: 0.7415\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5991 - accuracy: 0.7201\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5858 - accuracy: 0.7469\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5621 - accuracy: 0.7611\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5441 - accuracy: 0.7807\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5250 - accuracy: 0.7879\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5128 - accuracy: 0.8093\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4953 - accuracy: 0.8128\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4796 - accuracy: 0.8342\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4649 - accuracy: 0.8414\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4577 - accuracy: 0.8360\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4461 - accuracy: 0.8360\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4290 - accuracy: 0.8627\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4101 - accuracy: 0.8788\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4016 - accuracy: 0.8824\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3944 - accuracy: 0.8734\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3843 - accuracy: 0.8752\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3643 - accuracy: 0.8948\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3611 - accuracy: 0.8913\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3521 - accuracy: 0.9002\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3366 - accuracy: 0.9109\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3287 - accuracy: 0.9234\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3206 - accuracy: 0.9234\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3189 - accuracy: 0.9109\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3062 - accuracy: 0.9269\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.2969 - accuracy: 0.9251\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.2913 - accuracy: 0.9251\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2866 - accuracy: 0.9287\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2800 - accuracy: 0.9305\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2706 - accuracy: 0.9483\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2663 - accuracy: 0.9394\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2590 - accuracy: 0.9394\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2632 - accuracy: 0.9323\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2487 - accuracy: 0.9430\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2456 - accuracy: 0.9340\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2490 - accuracy: 0.9412\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.2318 - accuracy: 0.9447\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2444 - accuracy: 0.9305\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2321 - accuracy: 0.9483\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2261 - accuracy: 0.9608\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2208 - accuracy: 0.9376\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2116 - accuracy: 0.9608\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2099 - accuracy: 0.9519\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2056 - accuracy: 0.9572\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2063 - accuracy: 0.9554\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2092 - accuracy: 0.9537\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2181 - accuracy: 0.9305\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2127 - accuracy: 0.9394\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2183 - accuracy: 0.9340\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2172 - accuracy: 0.9305\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1915 - accuracy: 0.9554\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1835 - accuracy: 0.9572\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1781 - accuracy: 0.9626\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1776 - accuracy: 0.9626\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1759 - accuracy: 0.9626\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1834 - accuracy: 0.9447\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1911 - accuracy: 0.9483\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1703 - accuracy: 0.9554\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1684 - accuracy: 0.9590\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1735 - accuracy: 0.9626\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1674 - accuracy: 0.9590\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1680 - accuracy: 0.9519\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1577 - accuracy: 0.9715\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1576 - accuracy: 0.9715\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1586 - accuracy: 0.9626\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1530 - accuracy: 0.9643\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1549 - accuracy: 0.9626\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1563 - accuracy: 0.9590\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1474 - accuracy: 0.9750\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1477 - accuracy: 0.9679\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1475 - accuracy: 0.9608\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "\n",
      "Fold 3\n",
      "Model: \"sequential_233\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_699 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_700 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_701 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 1.4115 - accuracy: 0.3238\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9406 - accuracy: 0.5242\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9110 - accuracy: 0.5242\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9039 - accuracy: 0.5242\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8935 - accuracy: 0.5242\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8889 - accuracy: 0.5242\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8825 - accuracy: 0.5242\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8753 - accuracy: 0.5242\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8673 - accuracy: 0.5242\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8602 - accuracy: 0.5492\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8501 - accuracy: 0.5420\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8394 - accuracy: 0.5546\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8304 - accuracy: 0.5689\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8235 - accuracy: 0.5689\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8127 - accuracy: 0.5903\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8037 - accuracy: 0.5868\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7974 - accuracy: 0.5957\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7847 - accuracy: 0.6118\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7776 - accuracy: 0.6082\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7630 - accuracy: 0.6029\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7524 - accuracy: 0.6333\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7411 - accuracy: 0.6297\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7331 - accuracy: 0.6530\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7286 - accuracy: 0.6351\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7105 - accuracy: 0.6601\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6976 - accuracy: 0.6673\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6863 - accuracy: 0.6852\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6804 - accuracy: 0.6708\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6635 - accuracy: 0.6834\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6514 - accuracy: 0.6959\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6380 - accuracy: 0.7156\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6288 - accuracy: 0.7084\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6187 - accuracy: 0.7156\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6025 - accuracy: 0.7335\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5882 - accuracy: 0.7442\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5756 - accuracy: 0.7549\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5608 - accuracy: 0.7692\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5512 - accuracy: 0.7567\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5386 - accuracy: 0.7800\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5178 - accuracy: 0.7925\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5091 - accuracy: 0.8068\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4974 - accuracy: 0.8086\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4770 - accuracy: 0.8354\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4665 - accuracy: 0.8301\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4476 - accuracy: 0.8426\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4367 - accuracy: 0.8533\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4198 - accuracy: 0.8623\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4164 - accuracy: 0.8712\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4041 - accuracy: 0.8766\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3891 - accuracy: 0.8766\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3751 - accuracy: 0.8927\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3631 - accuracy: 0.9088\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.3589 - accuracy: 0.9052\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.3552 - accuracy: 0.9088\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.9106\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3283 - accuracy: 0.9213\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3158 - accuracy: 0.9213\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3075 - accuracy: 0.9428\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3021 - accuracy: 0.9302\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2950 - accuracy: 0.9320\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2974 - accuracy: 0.9356\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2881 - accuracy: 0.9249\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2909 - accuracy: 0.9195\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2705 - accuracy: 0.9338\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2624 - accuracy: 0.9410\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2592 - accuracy: 0.9553\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2516 - accuracy: 0.9481\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2440 - accuracy: 0.9428\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2380 - accuracy: 0.9606\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2333 - accuracy: 0.9481\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2266 - accuracy: 0.9535\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2218 - accuracy: 0.9517\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2146 - accuracy: 0.9517\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2130 - accuracy: 0.9517\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2178 - accuracy: 0.9338\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2061 - accuracy: 0.9499\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1984 - accuracy: 0.9642\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1975 - accuracy: 0.9517\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1941 - accuracy: 0.9499\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2000 - accuracy: 0.9481\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1904 - accuracy: 0.9535\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1785 - accuracy: 0.9535\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1785 - accuracy: 0.9571\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1739 - accuracy: 0.9732\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1703 - accuracy: 0.9624\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1656 - accuracy: 0.9678\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1626 - accuracy: 0.9642\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1613 - accuracy: 0.9696\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1596 - accuracy: 0.9678\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1607 - accuracy: 0.9732\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1648 - accuracy: 0.9499\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1694 - accuracy: 0.9481\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1585 - accuracy: 0.9481\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1466 - accuracy: 0.9767\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1514 - accuracy: 0.9589\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1503 - accuracy: 0.9553\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9642\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1380 - accuracy: 0.9714\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1433 - accuracy: 0.9678\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1441 - accuracy: 0.9624\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "\n",
      "Fold 4\n",
      "Model: \"sequential_234\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_702 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_703 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_704 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 1.1299 - accuracy: 0.3875\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9455 - accuracy: 0.5250\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9263 - accuracy: 0.5250\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9098 - accuracy: 0.5250\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9006 - accuracy: 0.5250\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8945 - accuracy: 0.5250\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8785 - accuracy: 0.5250\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8667 - accuracy: 0.5250\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8582 - accuracy: 0.5321\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8469 - accuracy: 0.5250\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8465 - accuracy: 0.5500\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8269 - accuracy: 0.5589\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8208 - accuracy: 0.5554\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8048 - accuracy: 0.5786\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7943 - accuracy: 0.5732\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.7845 - accuracy: 0.5929\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7750 - accuracy: 0.6250\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7692 - accuracy: 0.6000\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7540 - accuracy: 0.6232\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7488 - accuracy: 0.6321\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7355 - accuracy: 0.6411\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7241 - accuracy: 0.6625\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7203 - accuracy: 0.6536\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7103 - accuracy: 0.6500\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6906 - accuracy: 0.6732\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6866 - accuracy: 0.6857\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6754 - accuracy: 0.6679\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6616 - accuracy: 0.6839\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6461 - accuracy: 0.7107\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6362 - accuracy: 0.7107\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6210 - accuracy: 0.7179\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6075 - accuracy: 0.7268\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5989 - accuracy: 0.7286\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5811 - accuracy: 0.7536\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5673 - accuracy: 0.7589\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5513 - accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5362 - accuracy: 0.7946\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5188 - accuracy: 0.8143\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5033 - accuracy: 0.8232\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4876 - accuracy: 0.8357\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4785 - accuracy: 0.8357\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4605 - accuracy: 0.8482\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.8607\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.4344 - accuracy: 0.8554\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4206 - accuracy: 0.8821\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4095 - accuracy: 0.8964\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3946 - accuracy: 0.8893\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3901 - accuracy: 0.8857\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3750 - accuracy: 0.9089\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3635 - accuracy: 0.9054\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3540 - accuracy: 0.9214\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3453 - accuracy: 0.9107\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3495 - accuracy: 0.9107\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3335 - accuracy: 0.9054\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3198 - accuracy: 0.9250\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3081 - accuracy: 0.9286\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3000 - accuracy: 0.9321\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2924 - accuracy: 0.9357\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2933 - accuracy: 0.9375\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.2874 - accuracy: 0.9411\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2732 - accuracy: 0.9554\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2653 - accuracy: 0.9429\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2599 - accuracy: 0.9518\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2581 - accuracy: 0.9482\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2593 - accuracy: 0.9446\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2447 - accuracy: 0.9554\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2427 - accuracy: 0.9446\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2425 - accuracy: 0.9411\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2405 - accuracy: 0.9321\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2290 - accuracy: 0.9500\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2296 - accuracy: 0.9375\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2212 - accuracy: 0.9482\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2224 - accuracy: 0.9464\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2101 - accuracy: 0.9679\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2142 - accuracy: 0.9446\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2064 - accuracy: 0.9554\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2021 - accuracy: 0.9571\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1970 - accuracy: 0.9536\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1924 - accuracy: 0.9554\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1910 - accuracy: 0.9696\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1935 - accuracy: 0.9661\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1858 - accuracy: 0.9607\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1824 - accuracy: 0.9607\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1809 - accuracy: 0.9607\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1923 - accuracy: 0.9357\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1752 - accuracy: 0.9625\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.9625\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.9571\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1676 - accuracy: 0.9714\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1666 - accuracy: 0.9571\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1659 - accuracy: 0.9732\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1653 - accuracy: 0.9607\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1696 - accuracy: 0.9446\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1599 - accuracy: 0.9625\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1555 - accuracy: 0.9625\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1540 - accuracy: 0.9625\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1680 - accuracy: 0.9411\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1605 - accuracy: 0.9554\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1482 - accuracy: 0.9625\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1501 - accuracy: 0.9625\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "\n",
      "Fold 5\n",
      "Model: \"sequential_235\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_705 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_706 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_707 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 1.0704 - accuracy: 0.4365\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9407 - accuracy: 0.5242\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9130 - accuracy: 0.5242\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9044 - accuracy: 0.5242\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8926 - accuracy: 0.5242\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8836 - accuracy: 0.5242\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8713 - accuracy: 0.5242\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8594 - accuracy: 0.5313\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8466 - accuracy: 0.5367\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8377 - accuracy: 0.5510\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8226 - accuracy: 0.5760\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8058 - accuracy: 0.5671\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7984 - accuracy: 0.5939\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7867 - accuracy: 0.6029\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7740 - accuracy: 0.6333\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7551 - accuracy: 0.6243\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7436 - accuracy: 0.6208\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7265 - accuracy: 0.6261\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7145 - accuracy: 0.6512\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6982 - accuracy: 0.6547\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6841 - accuracy: 0.6762\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6648 - accuracy: 0.6941\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6492 - accuracy: 0.6816\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6216 - accuracy: 0.7263\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6106 - accuracy: 0.6977\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5938 - accuracy: 0.7263\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5686 - accuracy: 0.7567\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5497 - accuracy: 0.7692\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5318 - accuracy: 0.7853\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5043 - accuracy: 0.8032\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4880 - accuracy: 0.8068\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4722 - accuracy: 0.8265\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4557 - accuracy: 0.8372\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4353 - accuracy: 0.8497\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4247 - accuracy: 0.8748\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4027 - accuracy: 0.8676\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3852 - accuracy: 0.8927\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3712 - accuracy: 0.9034\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3562 - accuracy: 0.9106\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3458 - accuracy: 0.9177\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3353 - accuracy: 0.9213\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3283 - accuracy: 0.9177\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3215 - accuracy: 0.9034\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3088 - accuracy: 0.9374\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2949 - accuracy: 0.9392\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2940 - accuracy: 0.9284\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3093 - accuracy: 0.8927\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2899 - accuracy: 0.9052\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2684 - accuracy: 0.9320\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2548 - accuracy: 0.9463\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2494 - accuracy: 0.9463\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2440 - accuracy: 0.9463\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2534 - accuracy: 0.9195\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2383 - accuracy: 0.9374\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2379 - accuracy: 0.9445\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2243 - accuracy: 0.9445\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2265 - accuracy: 0.9445\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2181 - accuracy: 0.9553\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2121 - accuracy: 0.9445\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2043 - accuracy: 0.9606\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2087 - accuracy: 0.9410\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1987 - accuracy: 0.9624\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1961 - accuracy: 0.9624\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1986 - accuracy: 0.9535\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1867 - accuracy: 0.9589\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1818 - accuracy: 0.9714\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1971 - accuracy: 0.9481\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1855 - accuracy: 0.9481\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1741 - accuracy: 0.9750\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1944 - accuracy: 0.9410\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2094 - accuracy: 0.9267\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1722 - accuracy: 0.9624\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1681 - accuracy: 0.9624\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1621 - accuracy: 0.9696\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1646 - accuracy: 0.9624\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1710 - accuracy: 0.9606\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1721 - accuracy: 0.9410\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1650 - accuracy: 0.9356\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1565 - accuracy: 0.9606\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1510 - accuracy: 0.9750\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1650 - accuracy: 0.9410\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1548 - accuracy: 0.9589\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1460 - accuracy: 0.9678\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1527 - accuracy: 0.9517\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1807 - accuracy: 0.9338\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1730 - accuracy: 0.9374\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1629 - accuracy: 0.9428\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1534 - accuracy: 0.9517\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1412 - accuracy: 0.9660\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1465 - accuracy: 0.9517\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1404 - accuracy: 0.9678\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1364 - accuracy: 0.9660\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1383 - accuracy: 0.9553\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1346 - accuracy: 0.9571\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1292 - accuracy: 0.9696\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1291 - accuracy: 0.9714\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1257 - accuracy: 0.9767\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1325 - accuracy: 0.9624\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1242 - accuracy: 0.9803\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1333 - accuracy: 0.9642\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "\n",
      "---\n",
      "Fold 1:\n",
      "Acurácia: 0.9568345323741008\n",
      "Precisão: 0.9576981297844607\n",
      "Revocação: 0.9568345323741008\n",
      "F1-Score: 0.9561988662708085\n",
      "---\n",
      "Fold 2:\n",
      "Acurácia: 0.9424460431654677\n",
      "Precisão: 0.9456192189105859\n",
      "Revocação: 0.9424460431654677\n",
      "F1-Score: 0.9412527853499093\n",
      "---\n",
      "Fold 3:\n",
      "Acurácia: 0.9716312056737588\n",
      "Precisão: 0.9726443768996961\n",
      "Revocação: 0.9716312056737588\n",
      "F1-Score: 0.9717967262900713\n",
      "---\n",
      "Fold 4:\n",
      "Acurácia: 0.9785714285714285\n",
      "Precisão: 0.9800324675324674\n",
      "Revocação: 0.9785714285714285\n",
      "F1-Score: 0.9786392350043467\n",
      "---\n",
      "Fold 5:\n",
      "Acurácia: 0.9645390070921985\n",
      "Precisão: 0.9655709407482456\n",
      "Revocação: 0.9645390070921985\n",
      "F1-Score: 0.9648561967275402\n",
      "---\n",
      "\n",
      "Médias e Desvios Padrão Gerais:\n",
      "----------------------------------------------------------------\n",
      "Média Acurácias: 0.9628044433753908\n",
      "Desvio Padrão Acurácias: 0.012486973713453173\n",
      "\n",
      "Média Precisões: 0.9643130267750912\n",
      "Desvio Padrão Precisões: 0.011927362448244503\n",
      "\n",
      "Média Revocações: 0.9628044433753908\n",
      "Desvio Padrão Revocações: 0.012486973713453173\n",
      "\n",
      "Média F1-Scores: 0.9625487619285351\n",
      "Desvio Padrão F1-Scores: 0.012989166388099847\n",
      "\n",
      "\n",
      "Conjunto 7\n",
      "\n",
      "Fold 1\n",
      "Model: \"sequential_236\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_708 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_709 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_710 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9765 - accuracy: 0.5107\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9436 - accuracy: 0.5107\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9292 - accuracy: 0.5107\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9172 - accuracy: 0.5107\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9007 - accuracy: 0.5107\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8884 - accuracy: 0.5107\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8793 - accuracy: 0.5107\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8659 - accuracy: 0.5125\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8518 - accuracy: 0.5161\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8361 - accuracy: 0.5250\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8274 - accuracy: 0.5464\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8123 - accuracy: 0.5518\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7961 - accuracy: 0.5661\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7816 - accuracy: 0.5804\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7662 - accuracy: 0.6125\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7557 - accuracy: 0.6018\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7388 - accuracy: 0.6214\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7215 - accuracy: 0.6589\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7098 - accuracy: 0.6518\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.6959 - accuracy: 0.6679\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6846 - accuracy: 0.6804\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6693 - accuracy: 0.7000\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6475 - accuracy: 0.7071\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6366 - accuracy: 0.7054\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6223 - accuracy: 0.7125\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6025 - accuracy: 0.7411\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5852 - accuracy: 0.7446\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5782 - accuracy: 0.7589\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5603 - accuracy: 0.7679\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5440 - accuracy: 0.7911\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5432 - accuracy: 0.7643\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5344 - accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5009 - accuracy: 0.8304\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4849 - accuracy: 0.8411\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4703 - accuracy: 0.8411\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4665 - accuracy: 0.8446\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4418 - accuracy: 0.8696\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4363 - accuracy: 0.8625\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4157 - accuracy: 0.8911\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4170 - accuracy: 0.8482\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3945 - accuracy: 0.8946\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.3788 - accuracy: 0.9054\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3695 - accuracy: 0.9036\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3643 - accuracy: 0.8982\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3552 - accuracy: 0.9054\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3453 - accuracy: 0.9143\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3380 - accuracy: 0.9339\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3216 - accuracy: 0.9232\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.3127 - accuracy: 0.9286\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3066 - accuracy: 0.9339\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3017 - accuracy: 0.9357\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2951 - accuracy: 0.9357\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2923 - accuracy: 0.9393\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2876 - accuracy: 0.9321\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2793 - accuracy: 0.9375\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2672 - accuracy: 0.9411\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2672 - accuracy: 0.9375\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2578 - accuracy: 0.9571\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2498 - accuracy: 0.9518\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2482 - accuracy: 0.9554\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2388 - accuracy: 0.9589\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.2375 - accuracy: 0.9571\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2310 - accuracy: 0.9500\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2384 - accuracy: 0.9357\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2315 - accuracy: 0.9500\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2206 - accuracy: 0.9500\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2173 - accuracy: 0.9518\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2112 - accuracy: 0.9500\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2114 - accuracy: 0.9607\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2063 - accuracy: 0.9589\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1969 - accuracy: 0.9714\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2194 - accuracy: 0.9411\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2014 - accuracy: 0.9536\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1964 - accuracy: 0.9554\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1948 - accuracy: 0.9679\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2091 - accuracy: 0.9339\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1869 - accuracy: 0.9696\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1851 - accuracy: 0.9696\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1789 - accuracy: 0.9661\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1783 - accuracy: 0.9625\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1793 - accuracy: 0.9643\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1738 - accuracy: 0.9643\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1748 - accuracy: 0.9661\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1726 - accuracy: 0.9571\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1685 - accuracy: 0.9661\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1744 - accuracy: 0.9500\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1836 - accuracy: 0.9393\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1627 - accuracy: 0.9750\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1637 - accuracy: 0.9554\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1588 - accuracy: 0.9768\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1550 - accuracy: 0.9750\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1570 - accuracy: 0.9625\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1715 - accuracy: 0.9500\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1508 - accuracy: 0.9679\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1537 - accuracy: 0.9661\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1461 - accuracy: 0.9768\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1472 - accuracy: 0.9679\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1709 - accuracy: 0.9286\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1582 - accuracy: 0.9589\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.1423 - accuracy: 0.9732\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "Fold 2\n",
      "Model: \"sequential_237\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_711 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_712 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_713 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.2243 - accuracy: 0.3882\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.9670 - accuracy: 0.5116\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9494 - accuracy: 0.5116\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9446 - accuracy: 0.5116\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9388 - accuracy: 0.5116\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9317 - accuracy: 0.5116\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9276 - accuracy: 0.5116\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9238 - accuracy: 0.5116\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9159 - accuracy: 0.5116\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9062 - accuracy: 0.5116\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9032 - accuracy: 0.5116\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8973 - accuracy: 0.5116\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8858 - accuracy: 0.5116\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8800 - accuracy: 0.5116\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8664 - accuracy: 0.5134\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8492 - accuracy: 0.5134\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8340 - accuracy: 0.5492\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8328 - accuracy: 0.5742\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8038 - accuracy: 0.5599\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8019 - accuracy: 0.5707\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7798 - accuracy: 0.6082\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7678 - accuracy: 0.6172\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7517 - accuracy: 0.6243\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7409 - accuracy: 0.6565\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7315 - accuracy: 0.6422\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 873us/step - loss: 0.7140 - accuracy: 0.6583\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6991 - accuracy: 0.6762\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6853 - accuracy: 0.6905\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6728 - accuracy: 0.6869\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6658 - accuracy: 0.7084\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6466 - accuracy: 0.7066\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6310 - accuracy: 0.7424\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6220 - accuracy: 0.7245\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6005 - accuracy: 0.7496\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5926 - accuracy: 0.7531\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5767 - accuracy: 0.7585\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5672 - accuracy: 0.7871\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5496 - accuracy: 0.7800\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5338 - accuracy: 0.7835\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5228 - accuracy: 0.8247\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.5101 - accuracy: 0.8157\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5038 - accuracy: 0.8122\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4852 - accuracy: 0.8444\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4785 - accuracy: 0.8462\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4590 - accuracy: 0.8479\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4480 - accuracy: 0.8766\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4539 - accuracy: 0.8497\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4320 - accuracy: 0.8640\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4281 - accuracy: 0.8712\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4062 - accuracy: 0.8891\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4048 - accuracy: 0.8837\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3951 - accuracy: 0.8873\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3927 - accuracy: 0.8855\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3672 - accuracy: 0.9123\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3709 - accuracy: 0.9231\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.3529 - accuracy: 0.9123\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3477 - accuracy: 0.9195\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3365 - accuracy: 0.9249\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3321 - accuracy: 0.9410\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3306 - accuracy: 0.9213\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3163 - accuracy: 0.9499\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3183 - accuracy: 0.9195\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3033 - accuracy: 0.9571\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2998 - accuracy: 0.9517\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3009 - accuracy: 0.9320\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2872 - accuracy: 0.9445\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2886 - accuracy: 0.9410\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2865 - accuracy: 0.9356\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2763 - accuracy: 0.9392\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2650 - accuracy: 0.9606\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2624 - accuracy: 0.9535\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2574 - accuracy: 0.9660\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2498 - accuracy: 0.9606\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2468 - accuracy: 0.9714\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2549 - accuracy: 0.9356\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2517 - accuracy: 0.9553\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2351 - accuracy: 0.9571\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2323 - accuracy: 0.9678\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2293 - accuracy: 0.9714\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2237 - accuracy: 0.9696\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2209 - accuracy: 0.9732\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2170 - accuracy: 0.9714\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2176 - accuracy: 0.9571\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2115 - accuracy: 0.9750\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2096 - accuracy: 0.9642\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2055 - accuracy: 0.9750\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2013 - accuracy: 0.9785\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2021 - accuracy: 0.9660\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2034 - accuracy: 0.9499\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1951 - accuracy: 0.9624\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1894 - accuracy: 0.9696\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1924 - accuracy: 0.9642\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1826 - accuracy: 0.9839\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1854 - accuracy: 0.9785\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1883 - accuracy: 0.9553\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1811 - accuracy: 0.9714\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1808 - accuracy: 0.9606\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1722 - accuracy: 0.9767\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1923 - accuracy: 0.9356\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1785 - accuracy: 0.9481\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "\n",
      "Fold 3\n",
      "Model: \"sequential_238\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_714 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_715 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_716 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 1.1429 - accuracy: 0.4043\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9596 - accuracy: 0.5116\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9423 - accuracy: 0.5116\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9359 - accuracy: 0.5116\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9290 - accuracy: 0.5116\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9212 - accuracy: 0.5116\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9142 - accuracy: 0.5116\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9082 - accuracy: 0.5116\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8988 - accuracy: 0.5116\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8915 - accuracy: 0.5116\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8801 - accuracy: 0.5116\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8727 - accuracy: 0.5116\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8505 - accuracy: 0.5188\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8387 - accuracy: 0.5152\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8208 - accuracy: 0.5456\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8041 - accuracy: 0.5868\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7906 - accuracy: 0.6082\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7721 - accuracy: 0.6118\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7505 - accuracy: 0.6386\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7362 - accuracy: 0.6512\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7214 - accuracy: 0.6458\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6902 - accuracy: 0.6708\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6718 - accuracy: 0.7048\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6526 - accuracy: 0.7156\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6362 - accuracy: 0.7156\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6104 - accuracy: 0.7424\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5936 - accuracy: 0.7531\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5735 - accuracy: 0.7764\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5523 - accuracy: 0.7889\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5340 - accuracy: 0.7871\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5138 - accuracy: 0.8104\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4961 - accuracy: 0.8265\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5044 - accuracy: 0.7979\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4809 - accuracy: 0.8140\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4476 - accuracy: 0.8623\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4320 - accuracy: 0.8766\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4198 - accuracy: 0.8712\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4078 - accuracy: 0.8730\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3936 - accuracy: 0.8927\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3818 - accuracy: 0.8945\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3760 - accuracy: 0.9034\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3590 - accuracy: 0.9052\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3528 - accuracy: 0.9034\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3351 - accuracy: 0.9338\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3313 - accuracy: 0.9267\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3156 - accuracy: 0.9463\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3186 - accuracy: 0.9249\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3027 - accuracy: 0.9374\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3004 - accuracy: 0.9231\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2863 - accuracy: 0.9606\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2778 - accuracy: 0.9571\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2713 - accuracy: 0.9660\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2670 - accuracy: 0.9571\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2639 - accuracy: 0.9428\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2561 - accuracy: 0.9517\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2533 - accuracy: 0.9481\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2439 - accuracy: 0.9624\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2348 - accuracy: 0.9714\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2310 - accuracy: 0.9642\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2269 - accuracy: 0.9696\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2268 - accuracy: 0.9624\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2294 - accuracy: 0.9445\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2164 - accuracy: 0.9571\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2237 - accuracy: 0.9428\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2189 - accuracy: 0.9589\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2070 - accuracy: 0.9535\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2001 - accuracy: 0.9714\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2008 - accuracy: 0.9624\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2023 - accuracy: 0.9463\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1893 - accuracy: 0.9696\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1877 - accuracy: 0.9732\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1853 - accuracy: 0.9571\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1975 - accuracy: 0.9338\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1965 - accuracy: 0.9481\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1815 - accuracy: 0.9678\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1822 - accuracy: 0.9642\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1749 - accuracy: 0.9678\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1760 - accuracy: 0.9660\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1647 - accuracy: 0.9839\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1645 - accuracy: 0.9732\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1672 - accuracy: 0.9624\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1578 - accuracy: 0.9839\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1601 - accuracy: 0.9660\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1551 - accuracy: 0.9875\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1596 - accuracy: 0.9714\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1531 - accuracy: 0.9767\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1548 - accuracy: 0.9732\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1648 - accuracy: 0.9517\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1537 - accuracy: 0.9642\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1483 - accuracy: 0.9803\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1461 - accuracy: 0.9714\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1480 - accuracy: 0.9660\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1453 - accuracy: 0.9696\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1435 - accuracy: 0.9660\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1431 - accuracy: 0.9767\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1412 - accuracy: 0.9660\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1377 - accuracy: 0.9767\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1355 - accuracy: 0.9642\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1372 - accuracy: 0.9839\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1339 - accuracy: 0.9803\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "\n",
      "Fold 4\n",
      "Model: \"sequential_239\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_717 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_718 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_719 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 1.1263 - accuracy: 0.5116\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9595 - accuracy: 0.4938\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9312 - accuracy: 0.5116\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9124 - accuracy: 0.5116\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9062 - accuracy: 0.5116\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8964 - accuracy: 0.5169\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8899 - accuracy: 0.5116\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8743 - accuracy: 0.5152\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8657 - accuracy: 0.5116\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8600 - accuracy: 0.5330\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8458 - accuracy: 0.5241\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8344 - accuracy: 0.5401\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8210 - accuracy: 0.5544\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8164 - accuracy: 0.5633\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8026 - accuracy: 0.5740\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7918 - accuracy: 0.5954\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7749 - accuracy: 0.6114\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7599 - accuracy: 0.6132\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7456 - accuracy: 0.6168\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7279 - accuracy: 0.6471\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7115 - accuracy: 0.6702\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6930 - accuracy: 0.6578\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6877 - accuracy: 0.6863\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6677 - accuracy: 0.6934\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6469 - accuracy: 0.7094\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6346 - accuracy: 0.7184\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6101 - accuracy: 0.7790\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5976 - accuracy: 0.7522\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5757 - accuracy: 0.7879\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5600 - accuracy: 0.7968\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5479 - accuracy: 0.7932\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5249 - accuracy: 0.8111\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5245 - accuracy: 0.7807\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4977 - accuracy: 0.8520\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4779 - accuracy: 0.8485\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4700 - accuracy: 0.8592\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4494 - accuracy: 0.8788\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4342 - accuracy: 0.8734\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4213 - accuracy: 0.8806\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4139 - accuracy: 0.8841\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4080 - accuracy: 0.8717\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.3947 - accuracy: 0.8859\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3797 - accuracy: 0.9037\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3679 - accuracy: 0.9002\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3669 - accuracy: 0.8930\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3436 - accuracy: 0.9234\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3452 - accuracy: 0.9216\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3352 - accuracy: 0.9162\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3188 - accuracy: 0.9430\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3142 - accuracy: 0.9287\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3051 - accuracy: 0.9376\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.3159 - accuracy: 0.9073\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2937 - accuracy: 0.9501\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2865 - accuracy: 0.9287\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2846 - accuracy: 0.9465\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2780 - accuracy: 0.9305\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.2693 - accuracy: 0.9554\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2620 - accuracy: 0.9519\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2580 - accuracy: 0.9554\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2525 - accuracy: 0.9483\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2435 - accuracy: 0.9661\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2418 - accuracy: 0.9537\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2377 - accuracy: 0.9554\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2318 - accuracy: 0.9768\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2357 - accuracy: 0.9483\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2275 - accuracy: 0.9465\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2336 - accuracy: 0.9340\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2272 - accuracy: 0.9465\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2135 - accuracy: 0.9697\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2100 - accuracy: 0.9661\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2070 - accuracy: 0.9733\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2065 - accuracy: 0.9608\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2070 - accuracy: 0.9519\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1989 - accuracy: 0.9679\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1953 - accuracy: 0.9590\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2080 - accuracy: 0.9376\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1896 - accuracy: 0.9715\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1895 - accuracy: 0.9661\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1969 - accuracy: 0.9501\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1864 - accuracy: 0.9608\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1782 - accuracy: 0.9768\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1771 - accuracy: 0.9679\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1813 - accuracy: 0.9661\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1740 - accuracy: 0.9626\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1784 - accuracy: 0.9554\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1864 - accuracy: 0.9376\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1764 - accuracy: 0.9572\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1715 - accuracy: 0.9626\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.9483\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1732 - accuracy: 0.9501\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1587 - accuracy: 0.9768\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1628 - accuracy: 0.9661\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9661\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1564 - accuracy: 0.9697\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1620 - accuracy: 0.9572\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1633 - accuracy: 0.9554\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1591 - accuracy: 0.9412\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1552 - accuracy: 0.9572\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1532 - accuracy: 0.9679\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1478 - accuracy: 0.9679\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "\n",
      "Fold 5\n",
      "Model: \"sequential_240\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_720 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_721 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_722 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9569 - accuracy: 0.5116\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9362 - accuracy: 0.5116\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9345 - accuracy: 0.5116\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9198 - accuracy: 0.5116\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9151 - accuracy: 0.5116\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9033 - accuracy: 0.5116\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9067 - accuracy: 0.5365\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8914 - accuracy: 0.5134\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8769 - accuracy: 0.5116\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8665 - accuracy: 0.5205\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8558 - accuracy: 0.5223\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8448 - accuracy: 0.5490\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8288 - accuracy: 0.5490\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8154 - accuracy: 0.5704\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8043 - accuracy: 0.5740\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7857 - accuracy: 0.5829\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7729 - accuracy: 0.5971\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7530 - accuracy: 0.6114\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7384 - accuracy: 0.6061\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7208 - accuracy: 0.6150\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7024 - accuracy: 0.6292\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6881 - accuracy: 0.6257\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6643 - accuracy: 0.6560\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6488 - accuracy: 0.6720\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6357 - accuracy: 0.6881\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6387 - accuracy: 0.7112\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6057 - accuracy: 0.7005\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5802 - accuracy: 0.7522\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5595 - accuracy: 0.7683\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5399 - accuracy: 0.8004\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5268 - accuracy: 0.8021\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5140 - accuracy: 0.8324\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4971 - accuracy: 0.8271\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4760 - accuracy: 0.8574\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4637 - accuracy: 0.8592\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4530 - accuracy: 0.8610\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4370 - accuracy: 0.8663\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4210 - accuracy: 0.8841\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4097 - accuracy: 0.8966\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3984 - accuracy: 0.8930\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3861 - accuracy: 0.9002\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3722 - accuracy: 0.9144\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3607 - accuracy: 0.9109\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3522 - accuracy: 0.9109\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3403 - accuracy: 0.9323\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3332 - accuracy: 0.9323\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3251 - accuracy: 0.9305\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3294 - accuracy: 0.9287\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3108 - accuracy: 0.9376\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3016 - accuracy: 0.9251\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2895 - accuracy: 0.9465\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2831 - accuracy: 0.9554\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2863 - accuracy: 0.9340\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2713 - accuracy: 0.9501\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2729 - accuracy: 0.9412\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2600 - accuracy: 0.9447\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2622 - accuracy: 0.9412\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2454 - accuracy: 0.9537\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2411 - accuracy: 0.9626\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2362 - accuracy: 0.9626\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2306 - accuracy: 0.9590\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2266 - accuracy: 0.9626\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2256 - accuracy: 0.9519\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2201 - accuracy: 0.9608\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2129 - accuracy: 0.9661\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2100 - accuracy: 0.9608\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2049 - accuracy: 0.9697\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2021 - accuracy: 0.9733\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1965 - accuracy: 0.9750\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1946 - accuracy: 0.9715\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1921 - accuracy: 0.9661\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1987 - accuracy: 0.9519\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1861 - accuracy: 0.9697\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1865 - accuracy: 0.9679\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1788 - accuracy: 0.9715\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.9679\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1771 - accuracy: 0.9661\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1727 - accuracy: 0.9715\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1677 - accuracy: 0.9786\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1651 - accuracy: 0.9840\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1611 - accuracy: 0.9857\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1625 - accuracy: 0.9786\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1631 - accuracy: 0.9733\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1606 - accuracy: 0.9679\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1581 - accuracy: 0.9733\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1529 - accuracy: 0.9750\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1538 - accuracy: 0.9715\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.1587 - accuracy: 0.9643\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1629 - accuracy: 0.9572\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1646 - accuracy: 0.9483\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1485 - accuracy: 0.9643\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1464 - accuracy: 0.9750\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1428 - accuracy: 0.9786\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1501 - accuracy: 0.9626\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1387 - accuracy: 0.9750\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1428 - accuracy: 0.9697\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1430 - accuracy: 0.9661\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1418 - accuracy: 0.9643\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1373 - accuracy: 0.9750\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1335 - accuracy: 0.9750\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "\n",
      "---\n",
      "Fold 1:\n",
      "Acurácia: 0.95\n",
      "Precisão: 0.9534202866099418\n",
      "Revocação: 0.95\n",
      "F1-Score: 0.9504951117137502\n",
      "---\n",
      "Fold 2:\n",
      "Acurácia: 0.9290780141843972\n",
      "Precisão: 0.9326106411847918\n",
      "Revocação: 0.9290780141843972\n",
      "F1-Score: 0.9295696961532833\n",
      "---\n",
      "Fold 3:\n",
      "Acurácia: 0.9361702127659575\n",
      "Precisão: 0.9405606214116853\n",
      "Revocação: 0.9361702127659575\n",
      "F1-Score: 0.9368625683918387\n",
      "---\n",
      "Fold 4:\n",
      "Acurácia: 0.9928057553956835\n",
      "Precisão: 0.9929056754596323\n",
      "Revocação: 0.9928057553956835\n",
      "F1-Score: 0.9927865011797865\n",
      "---\n",
      "Fold 5:\n",
      "Acurácia: 1.0\n",
      "Precisão: 1.0\n",
      "Revocação: 1.0\n",
      "F1-Score: 1.0\n",
      "---\n",
      "\n",
      "Médias e Desvios Padrão Gerais:\n",
      "----------------------------------------------------------------\n",
      "Média Acurácias: 0.9616107964692077\n",
      "Desvio Padrão Acurácias: 0.02928232308801827\n",
      "\n",
      "Média Precisões: 0.9638994449332102\n",
      "Desvio Padrão Precisões: 0.02748859460948237\n",
      "\n",
      "Média Revocações: 0.9616107964692077\n",
      "Desvio Padrão Revocações: 0.02928232308801827\n",
      "\n",
      "Média F1-Scores: 0.9619427754877318\n",
      "Desvio Padrão F1-Scores: 0.029009549502167095\n",
      "\n",
      "\n",
      "Conjunto 8\n",
      "\n",
      "Fold 1\n",
      "Model: \"sequential_241\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_723 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_724 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_725 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 2.0801 - accuracy: 0.2299\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 1.1510 - accuracy: 0.3761\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9824 - accuracy: 0.4938\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9789 - accuracy: 0.4938\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9690 - accuracy: 0.4938\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9666 - accuracy: 0.4938\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9636 - accuracy: 0.4938\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 944us/step - loss: 0.9576 - accuracy: 0.4938\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9534 - accuracy: 0.4938\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9467 - accuracy: 0.4938\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9407 - accuracy: 0.4938\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9371 - accuracy: 0.4938\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9273 - accuracy: 0.4938\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9220 - accuracy: 0.4938\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9151 - accuracy: 0.4938\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9100 - accuracy: 0.4938\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9019 - accuracy: 0.5062\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8921 - accuracy: 0.4938\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8840 - accuracy: 0.5205\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8757 - accuracy: 0.5187\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8734 - accuracy: 0.5490\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8605 - accuracy: 0.5134\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8495 - accuracy: 0.5365\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8372 - accuracy: 0.5419\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8288 - accuracy: 0.5472\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8198 - accuracy: 0.5704\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8082 - accuracy: 0.5954\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7952 - accuracy: 0.5971\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7835 - accuracy: 0.5954\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7732 - accuracy: 0.6257\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7590 - accuracy: 0.6203\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7478 - accuracy: 0.6417\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7267 - accuracy: 0.6524\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7168 - accuracy: 0.6578\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6972 - accuracy: 0.6649\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6820 - accuracy: 0.6916\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6643 - accuracy: 0.6952\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6472 - accuracy: 0.7077\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6275 - accuracy: 0.7273\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6111 - accuracy: 0.7308\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5932 - accuracy: 0.7540\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5761 - accuracy: 0.7611\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5573 - accuracy: 0.7772\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5435 - accuracy: 0.7986\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5364 - accuracy: 0.7772\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5115 - accuracy: 0.8146\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4891 - accuracy: 0.8271\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4779 - accuracy: 0.8414\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4635 - accuracy: 0.8538\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4515 - accuracy: 0.8681\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4365 - accuracy: 0.8592\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4219 - accuracy: 0.8806\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4057 - accuracy: 0.9020\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3975 - accuracy: 0.8913\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3856 - accuracy: 0.9037\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3724 - accuracy: 0.9020\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3599 - accuracy: 0.9127\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3603 - accuracy: 0.9002\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3390 - accuracy: 0.9358\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3374 - accuracy: 0.9144\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3326 - accuracy: 0.9127\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3154 - accuracy: 0.9251\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3084 - accuracy: 0.9251\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.3048 - accuracy: 0.9216\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2911 - accuracy: 0.9501\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2946 - accuracy: 0.9340\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2749 - accuracy: 0.9501\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2764 - accuracy: 0.9358\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2619 - accuracy: 0.9537\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2586 - accuracy: 0.9590\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.2545 - accuracy: 0.9537\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2483 - accuracy: 0.9465\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2447 - accuracy: 0.9465\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2413 - accuracy: 0.9626\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2594 - accuracy: 0.9251\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2439 - accuracy: 0.9323\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2234 - accuracy: 0.9572\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2138 - accuracy: 0.9572\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2113 - accuracy: 0.9715\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2058 - accuracy: 0.9661\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2022 - accuracy: 0.9661\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2147 - accuracy: 0.9483\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1966 - accuracy: 0.9750\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1951 - accuracy: 0.9643\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1923 - accuracy: 0.9679\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1881 - accuracy: 0.9697\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1893 - accuracy: 0.9626\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1862 - accuracy: 0.9697\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1781 - accuracy: 0.9786\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1792 - accuracy: 0.9643\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1780 - accuracy: 0.9679\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1724 - accuracy: 0.9750\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1671 - accuracy: 0.9750\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1782 - accuracy: 0.9572\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1688 - accuracy: 0.9697\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1904 - accuracy: 0.9305\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1614 - accuracy: 0.9733\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1581 - accuracy: 0.9750\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1560 - accuracy: 0.9697\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1631 - accuracy: 0.9643\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "\n",
      "Fold 2\n",
      "Model: \"sequential_242\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_726 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_727 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_728 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 1.5451 - accuracy: 0.3725\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 1.0177 - accuracy: 0.4938\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9745 - accuracy: 0.4938\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9563 - accuracy: 0.4938\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9556 - accuracy: 0.4938\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9464 - accuracy: 0.4938\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9383 - accuracy: 0.4938\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9335 - accuracy: 0.4938\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9285 - accuracy: 0.4938\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9178 - accuracy: 0.4938\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9109 - accuracy: 0.4938\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9059 - accuracy: 0.4955\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8994 - accuracy: 0.4938\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8913 - accuracy: 0.5027\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8811 - accuracy: 0.5169\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8694 - accuracy: 0.5098\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8599 - accuracy: 0.5098\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8486 - accuracy: 0.5312\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8395 - accuracy: 0.5348\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8328 - accuracy: 0.5633\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8182 - accuracy: 0.5775\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8061 - accuracy: 0.5740\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8004 - accuracy: 0.5722\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7915 - accuracy: 0.5954\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7667 - accuracy: 0.6114\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7543 - accuracy: 0.6239\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7366 - accuracy: 0.6542\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7168 - accuracy: 0.6506\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7032 - accuracy: 0.6542\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6815 - accuracy: 0.6791\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6549 - accuracy: 0.6952\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6464 - accuracy: 0.7112\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6207 - accuracy: 0.7094\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5925 - accuracy: 0.7522\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5720 - accuracy: 0.7736\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5494 - accuracy: 0.7950\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5271 - accuracy: 0.8039\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5051 - accuracy: 0.8235\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4860 - accuracy: 0.8449\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4674 - accuracy: 0.8610\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4487 - accuracy: 0.8538\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4292 - accuracy: 0.8948\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4150 - accuracy: 0.8913\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3952 - accuracy: 0.9287\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3800 - accuracy: 0.9198\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3657 - accuracy: 0.9323\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3486 - accuracy: 0.9340\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3621 - accuracy: 0.9037\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3311 - accuracy: 0.9501\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3236 - accuracy: 0.9305\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3084 - accuracy: 0.9465\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3035 - accuracy: 0.9447\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2916 - accuracy: 0.9483\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2800 - accuracy: 0.9537\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2757 - accuracy: 0.9519\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2798 - accuracy: 0.9198\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2734 - accuracy: 0.9358\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2589 - accuracy: 0.9643\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2450 - accuracy: 0.9697\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2425 - accuracy: 0.9554\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2397 - accuracy: 0.9537\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2433 - accuracy: 0.9323\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2304 - accuracy: 0.9483\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2212 - accuracy: 0.9537\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2153 - accuracy: 0.9679\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2101 - accuracy: 0.9679\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2060 - accuracy: 0.9679\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1998 - accuracy: 0.9715\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1983 - accuracy: 0.9643\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2051 - accuracy: 0.9501\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1864 - accuracy: 0.9786\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1871 - accuracy: 0.9697\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1850 - accuracy: 0.9626\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1896 - accuracy: 0.9447\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1782 - accuracy: 0.9626\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1774 - accuracy: 0.9572\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1695 - accuracy: 0.9733\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1707 - accuracy: 0.9661\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1661 - accuracy: 0.9643\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1613 - accuracy: 0.9697\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1776 - accuracy: 0.9447\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1644 - accuracy: 0.9697\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1554 - accuracy: 0.9661\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1562 - accuracy: 0.9715\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1594 - accuracy: 0.9537\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1524 - accuracy: 0.9643\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1503 - accuracy: 0.9661\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1492 - accuracy: 0.9715\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1545 - accuracy: 0.9590\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1462 - accuracy: 0.9643\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1396 - accuracy: 0.9804\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.1445 - accuracy: 0.9608\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1369 - accuracy: 0.9679\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1465 - accuracy: 0.9519\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.1381 - accuracy: 0.9590\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.1311 - accuracy: 0.9822\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1310 - accuracy: 0.9768\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1353 - accuracy: 0.9590\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1338 - accuracy: 0.9661\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1233 - accuracy: 0.9768\n",
      "5/5 [==============================] - 0s 1000us/step\n",
      "\n",
      "Fold 3\n",
      "Model: \"sequential_243\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_729 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_730 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_731 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 1.7034 - accuracy: 0.3739\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 1.0100 - accuracy: 0.4937\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9646 - accuracy: 0.4937\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9493 - accuracy: 0.4937\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9428 - accuracy: 0.4937\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9350 - accuracy: 0.4937\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9289 - accuracy: 0.4937\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9223 - accuracy: 0.4937\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9145 - accuracy: 0.4937\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9062 - accuracy: 0.4955\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8955 - accuracy: 0.4955\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8871 - accuracy: 0.4937\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8767 - accuracy: 0.5098\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8711 - accuracy: 0.5045\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8518 - accuracy: 0.5134\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8443 - accuracy: 0.5188\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8284 - accuracy: 0.5420\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8136 - accuracy: 0.5546\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8053 - accuracy: 0.5975\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8057 - accuracy: 0.5760\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7892 - accuracy: 0.6225\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7690 - accuracy: 0.6297\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7527 - accuracy: 0.6547\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7474 - accuracy: 0.6476\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7221 - accuracy: 0.6601\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7045 - accuracy: 0.6673\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6902 - accuracy: 0.7066\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6725 - accuracy: 0.7084\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6582 - accuracy: 0.6959\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6462 - accuracy: 0.7335\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6265 - accuracy: 0.7156\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6073 - accuracy: 0.7531\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5894 - accuracy: 0.7710\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5757 - accuracy: 0.7764\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5617 - accuracy: 0.7925\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5500 - accuracy: 0.7835\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5259 - accuracy: 0.8104\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5079 - accuracy: 0.8211\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4955 - accuracy: 0.8301\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4758 - accuracy: 0.8640\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4705 - accuracy: 0.8354\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4498 - accuracy: 0.8748\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4335 - accuracy: 0.8801\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4214 - accuracy: 0.8891\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4071 - accuracy: 0.8927\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3966 - accuracy: 0.9106\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3858 - accuracy: 0.9034\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3764 - accuracy: 0.9070\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3590 - accuracy: 0.9338\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3487 - accuracy: 0.9356\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3387 - accuracy: 0.9320\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3282 - accuracy: 0.9481\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3193 - accuracy: 0.9535\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3097 - accuracy: 0.9445\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3062 - accuracy: 0.9231\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3174 - accuracy: 0.9123\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3212 - accuracy: 0.8962\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2788 - accuracy: 0.9642\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2781 - accuracy: 0.9410\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 820us/step - loss: 0.2737 - accuracy: 0.9320\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2929 - accuracy: 0.9088\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2655 - accuracy: 0.9535\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2558 - accuracy: 0.9535\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2522 - accuracy: 0.9302\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2404 - accuracy: 0.9535\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2344 - accuracy: 0.9624\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2387 - accuracy: 0.9445\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2286 - accuracy: 0.9660\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2219 - accuracy: 0.9678\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2244 - accuracy: 0.9481\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2225 - accuracy: 0.9338\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2113 - accuracy: 0.9642\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2131 - accuracy: 0.9535\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2042 - accuracy: 0.9553\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2031 - accuracy: 0.9445\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1988 - accuracy: 0.9589\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1998 - accuracy: 0.9553\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2144 - accuracy: 0.9481\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1907 - accuracy: 0.9606\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1840 - accuracy: 0.9696\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1840 - accuracy: 0.9642\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1800 - accuracy: 0.9589\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1798 - accuracy: 0.9642\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1811 - accuracy: 0.9535\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1868 - accuracy: 0.9356\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1762 - accuracy: 0.9481\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1755 - accuracy: 0.9445\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1715 - accuracy: 0.9499\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1624 - accuracy: 0.9660\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1615 - accuracy: 0.9678\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1620 - accuracy: 0.9660\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1668 - accuracy: 0.9589\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1615 - accuracy: 0.9642\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1522 - accuracy: 0.9732\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1612 - accuracy: 0.9535\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1532 - accuracy: 0.9624\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1486 - accuracy: 0.9678\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1481 - accuracy: 0.9660\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1499 - accuracy: 0.9624\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1478 - accuracy: 0.9606\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "\n",
      "Fold 4\n",
      "Model: \"sequential_244\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_732 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_733 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_734 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.2453 - accuracy: 0.3363\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9818 - accuracy: 0.4955\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9663 - accuracy: 0.4955\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9572 - accuracy: 0.4955\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9518 - accuracy: 0.4973\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9505 - accuracy: 0.4955\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9428 - accuracy: 0.4955\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9360 - accuracy: 0.4955\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9332 - accuracy: 0.4955\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9268 - accuracy: 0.4991\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9230 - accuracy: 0.4955\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9186 - accuracy: 0.4955\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9081 - accuracy: 0.4955\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9018 - accuracy: 0.4991\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8933 - accuracy: 0.5045\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8903 - accuracy: 0.5009\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8813 - accuracy: 0.5188\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8759 - accuracy: 0.5134\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8609 - accuracy: 0.5081\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8520 - accuracy: 0.5224\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8398 - accuracy: 0.5546\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8285 - accuracy: 0.5617\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8136 - accuracy: 0.5492\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7996 - accuracy: 0.5707\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7846 - accuracy: 0.5903\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7646 - accuracy: 0.6315\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7446 - accuracy: 0.6154\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7286 - accuracy: 0.6547\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7124 - accuracy: 0.6691\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6973 - accuracy: 0.6637\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6741 - accuracy: 0.6762\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6593 - accuracy: 0.6869\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6327 - accuracy: 0.7227\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6124 - accuracy: 0.7352\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5875 - accuracy: 0.7460\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5726 - accuracy: 0.7746\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5545 - accuracy: 0.7692\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5294 - accuracy: 0.8086\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5237 - accuracy: 0.7943\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.8104\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4835 - accuracy: 0.8390\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4626 - accuracy: 0.8640\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4414 - accuracy: 0.8819\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4282 - accuracy: 0.8819\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4133 - accuracy: 0.9016\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4024 - accuracy: 0.8873\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3884 - accuracy: 0.9070\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3719 - accuracy: 0.9249\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3628 - accuracy: 0.9231\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3555 - accuracy: 0.8998\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3418 - accuracy: 0.9410\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3252 - accuracy: 0.9481\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3128 - accuracy: 0.9535\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3072 - accuracy: 0.9445\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2974 - accuracy: 0.9463\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2874 - accuracy: 0.9445\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2828 - accuracy: 0.9481\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2704 - accuracy: 0.9445\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2632 - accuracy: 0.9499\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2531 - accuracy: 0.9463\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2431 - accuracy: 0.9660\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2355 - accuracy: 0.9606\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2536 - accuracy: 0.9195\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2252 - accuracy: 0.9589\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2220 - accuracy: 0.9606\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2156 - accuracy: 0.9589\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2138 - accuracy: 0.9410\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2023 - accuracy: 0.9696\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2020 - accuracy: 0.9606\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2007 - accuracy: 0.9553\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2097 - accuracy: 0.9267\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1924 - accuracy: 0.9463\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1843 - accuracy: 0.9767\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1822 - accuracy: 0.9589\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1845 - accuracy: 0.9517\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1706 - accuracy: 0.9732\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1720 - accuracy: 0.9678\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1705 - accuracy: 0.9571\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1621 - accuracy: 0.9767\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1635 - accuracy: 0.9571\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1599 - accuracy: 0.9696\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1665 - accuracy: 0.9553\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1637 - accuracy: 0.9589\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1521 - accuracy: 0.9696\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1499 - accuracy: 0.9750\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9785\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1457 - accuracy: 0.9785\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9732\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1472 - accuracy: 0.9517\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.1428 - accuracy: 0.9606\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1434 - accuracy: 0.9642\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1369 - accuracy: 0.9624\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1406 - accuracy: 0.9606\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1402 - accuracy: 0.9660\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1439 - accuracy: 0.9517\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1336 - accuracy: 0.9571\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1425 - accuracy: 0.9445\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1364 - accuracy: 0.9624\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1387 - accuracy: 0.9589\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1274 - accuracy: 0.9660\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "Fold 5\n",
      "Model: \"sequential_245\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_735 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_736 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_737 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 1.0486 - accuracy: 0.4196\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9616 - accuracy: 0.4946\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9454 - accuracy: 0.4946\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9313 - accuracy: 0.4946\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9199 - accuracy: 0.4946\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9104 - accuracy: 0.4946\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9116 - accuracy: 0.4982\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8958 - accuracy: 0.5036\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8717 - accuracy: 0.5232\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8575 - accuracy: 0.5089\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8413 - accuracy: 0.5304\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8309 - accuracy: 0.5357\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8130 - accuracy: 0.5732\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8008 - accuracy: 0.5679\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7832 - accuracy: 0.5929\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.7664 - accuracy: 0.6036\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7519 - accuracy: 0.6071\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7380 - accuracy: 0.6250\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7228 - accuracy: 0.6500\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7069 - accuracy: 0.6429\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6937 - accuracy: 0.6571\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6783 - accuracy: 0.6732\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6519 - accuracy: 0.6893\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6350 - accuracy: 0.7054\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6270 - accuracy: 0.6964\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6018 - accuracy: 0.7464\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5849 - accuracy: 0.7500\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5638 - accuracy: 0.7714\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5509 - accuracy: 0.7875\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5288 - accuracy: 0.8214\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5235 - accuracy: 0.7804\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4986 - accuracy: 0.8411\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4800 - accuracy: 0.8446\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4647 - accuracy: 0.8571\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4472 - accuracy: 0.8893\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4474 - accuracy: 0.8464\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4159 - accuracy: 0.9036\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4063 - accuracy: 0.8982\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3899 - accuracy: 0.9232\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3767 - accuracy: 0.9411\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3684 - accuracy: 0.8982\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3582 - accuracy: 0.9196\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3424 - accuracy: 0.9571\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3318 - accuracy: 0.9518\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3315 - accuracy: 0.9268\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3370 - accuracy: 0.9143\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3279 - accuracy: 0.8857\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3064 - accuracy: 0.9196\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2893 - accuracy: 0.9554\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2827 - accuracy: 0.9554\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2815 - accuracy: 0.9500\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2701 - accuracy: 0.9554\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2675 - accuracy: 0.9411\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2589 - accuracy: 0.9446\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.2485 - accuracy: 0.9750\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2430 - accuracy: 0.9607\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2362 - accuracy: 0.9607\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2330 - accuracy: 0.9643\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2295 - accuracy: 0.9518\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2232 - accuracy: 0.9571\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2173 - accuracy: 0.9732\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2146 - accuracy: 0.9696\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2087 - accuracy: 0.9714\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2104 - accuracy: 0.9643\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2029 - accuracy: 0.9750\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2043 - accuracy: 0.9500\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1930 - accuracy: 0.9625\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1911 - accuracy: 0.9750\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1916 - accuracy: 0.9661\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2007 - accuracy: 0.9393\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1929 - accuracy: 0.9536\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1849 - accuracy: 0.9661\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1877 - accuracy: 0.9500\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1769 - accuracy: 0.9589\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1777 - accuracy: 0.9518\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1656 - accuracy: 0.9804\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1771 - accuracy: 0.9393\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1657 - accuracy: 0.9750\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1676 - accuracy: 0.9607\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1583 - accuracy: 0.9768\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1571 - accuracy: 0.9786\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1553 - accuracy: 0.9768\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1588 - accuracy: 0.9714\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1868 - accuracy: 0.9286\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1608 - accuracy: 0.9571\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1493 - accuracy: 0.9768\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1506 - accuracy: 0.9607\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1442 - accuracy: 0.9750\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1445 - accuracy: 0.9750\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1430 - accuracy: 0.9589\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1416 - accuracy: 0.9750\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.1508 - accuracy: 0.9607\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1450 - accuracy: 0.9571\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1491 - accuracy: 0.9536\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1510 - accuracy: 0.9589\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1343 - accuracy: 0.9768\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1323 - accuracy: 0.9875\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1300 - accuracy: 0.9821\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1403 - accuracy: 0.9571\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1642 - accuracy: 0.9375\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "---\n",
      "Fold 1:\n",
      "Acurácia: 0.9640287769784173\n",
      "Precisão: 0.9650660293682862\n",
      "Revocação: 0.9640287769784173\n",
      "F1-Score: 0.9637161339577105\n",
      "---\n",
      "Fold 2:\n",
      "Acurácia: 0.9496402877697842\n",
      "Precisão: 0.9509916391211355\n",
      "Revocação: 0.9496402877697842\n",
      "F1-Score: 0.9490823383083069\n",
      "---\n",
      "Fold 3:\n",
      "Acurácia: 0.9645390070921985\n",
      "Precisão: 0.9663891458526055\n",
      "Revocação: 0.9645390070921985\n",
      "F1-Score: 0.9649037088481763\n",
      "---\n",
      "Fold 4:\n",
      "Acurácia: 0.9858156028368794\n",
      "Precisão: 0.9864323157570151\n",
      "Revocação: 0.9858156028368794\n",
      "F1-Score: 0.9857105332282636\n",
      "---\n",
      "Fold 5:\n",
      "Acurácia: 0.9071428571428571\n",
      "Precisão: 0.9174107142857143\n",
      "Revocação: 0.9071428571428571\n",
      "F1-Score: 0.9084037335864579\n",
      "---\n",
      "\n",
      "Médias e Desvios Padrão Gerais:\n",
      "----------------------------------------------------------------\n",
      "Média Acurácias: 0.9542333063640275\n",
      "Desvio Padrão Acurácias: 0.026222915132432557\n",
      "\n",
      "Média Precisões: 0.9572579688769514\n",
      "Desvio Padrão Precisões: 0.02290221519653865\n",
      "\n",
      "Média Revocações: 0.9542333063640275\n",
      "Desvio Padrão Revocações: 0.026222915132432557\n",
      "\n",
      "Média F1-Scores: 0.9543632895857831\n",
      "Desvio Padrão F1-Scores: 0.025773610744727827\n",
      "\n",
      "\n",
      "Conjunto 9\n",
      "\n",
      "Fold 1\n",
      "Model: \"sequential_246\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_738 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_739 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_740 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.0228 - accuracy: 0.4624\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.9645 - accuracy: 0.5036\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9496 - accuracy: 0.5036\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9369 - accuracy: 0.5036\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9198 - accuracy: 0.5036\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9065 - accuracy: 0.5036\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8947 - accuracy: 0.5054\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8861 - accuracy: 0.5161\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8688 - accuracy: 0.5466\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8587 - accuracy: 0.5591\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8385 - accuracy: 0.5717\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8274 - accuracy: 0.5932\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8116 - accuracy: 0.6022\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7994 - accuracy: 0.6075\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7802 - accuracy: 0.6237\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7643 - accuracy: 0.6183\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7490 - accuracy: 0.6398\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7289 - accuracy: 0.6434\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7133 - accuracy: 0.6523\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6968 - accuracy: 0.6631\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6736 - accuracy: 0.6864\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6659 - accuracy: 0.6900\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6439 - accuracy: 0.6971\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6283 - accuracy: 0.7079\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6038 - accuracy: 0.7204\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5827 - accuracy: 0.7401\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5668 - accuracy: 0.7724\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5632 - accuracy: 0.7634\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5288 - accuracy: 0.7957\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5094 - accuracy: 0.7885\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4953 - accuracy: 0.8100\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4726 - accuracy: 0.8244\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.4666 - accuracy: 0.8387\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4368 - accuracy: 0.8674\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4273 - accuracy: 0.8781\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4075 - accuracy: 0.8943\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3944 - accuracy: 0.9194\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3827 - accuracy: 0.9014\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3767 - accuracy: 0.9050\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3543 - accuracy: 0.9301\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3452 - accuracy: 0.9283\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3438 - accuracy: 0.9122\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3280 - accuracy: 0.9265\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3129 - accuracy: 0.9516\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3023 - accuracy: 0.9624\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2946 - accuracy: 0.9588\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2864 - accuracy: 0.9570\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2827 - accuracy: 0.9462\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2700 - accuracy: 0.9642\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2651 - accuracy: 0.9606\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2544 - accuracy: 0.9570\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2501 - accuracy: 0.9588\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2480 - accuracy: 0.9624\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2372 - accuracy: 0.9731\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2437 - accuracy: 0.9552\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2276 - accuracy: 0.9624\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2234 - accuracy: 0.9677\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2223 - accuracy: 0.9480\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2155 - accuracy: 0.9498\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2119 - accuracy: 0.9606\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2168 - accuracy: 0.9444\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2281 - accuracy: 0.9283\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1997 - accuracy: 0.9570\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1918 - accuracy: 0.9695\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1877 - accuracy: 0.9767\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1878 - accuracy: 0.9731\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1847 - accuracy: 0.9749\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1824 - accuracy: 0.9677\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1721 - accuracy: 0.9731\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1963 - accuracy: 0.9355\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1839 - accuracy: 0.9480\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1691 - accuracy: 0.9659\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.1716 - accuracy: 0.9731\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1692 - accuracy: 0.9588\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1675 - accuracy: 0.9642\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1550 - accuracy: 0.9821\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1583 - accuracy: 0.9677\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1506 - accuracy: 0.9785\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1482 - accuracy: 0.9749\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1493 - accuracy: 0.9803\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1468 - accuracy: 0.9821\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1431 - accuracy: 0.9803\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1488 - accuracy: 0.9749\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1461 - accuracy: 0.9749\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1384 - accuracy: 0.9821\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1384 - accuracy: 0.9892\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1350 - accuracy: 0.9821\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1398 - accuracy: 0.9695\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1422 - accuracy: 0.9624\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1428 - accuracy: 0.9677\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1279 - accuracy: 0.9803\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1408 - accuracy: 0.9588\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1290 - accuracy: 0.9731\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1501 - accuracy: 0.9498\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1276 - accuracy: 0.9803\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1231 - accuracy: 0.9785\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1221 - accuracy: 0.9803\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1237 - accuracy: 0.9821\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1188 - accuracy: 0.9785\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1245 - accuracy: 0.9624\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "\n",
      "Fold 2\n",
      "Model: \"sequential_247\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_741 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_742 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_743 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 1.1030 - accuracy: 0.4153\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9746 - accuracy: 0.5027\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9531 - accuracy: 0.5027\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9437 - accuracy: 0.5027\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9340 - accuracy: 0.5027\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9282 - accuracy: 0.5027\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9192 - accuracy: 0.5027\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9072 - accuracy: 0.5027\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8963 - accuracy: 0.5062\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8954 - accuracy: 0.5045\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8795 - accuracy: 0.5401\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8666 - accuracy: 0.5169\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8565 - accuracy: 0.5597\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8442 - accuracy: 0.5633\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8360 - accuracy: 0.5419\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8185 - accuracy: 0.5936\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8063 - accuracy: 0.6025\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7856 - accuracy: 0.6078\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7715 - accuracy: 0.6221\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7625 - accuracy: 0.6292\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7424 - accuracy: 0.6346\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7342 - accuracy: 0.6488\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7082 - accuracy: 0.6774\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6968 - accuracy: 0.6684\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6827 - accuracy: 0.6809\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6559 - accuracy: 0.6952\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6342 - accuracy: 0.7166\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6217 - accuracy: 0.7041\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5981 - accuracy: 0.7540\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5900 - accuracy: 0.7415\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5709 - accuracy: 0.7665\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5475 - accuracy: 0.7807\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5213 - accuracy: 0.7950\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5034 - accuracy: 0.8093\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4882 - accuracy: 0.8235\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4650 - accuracy: 0.8396\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4492 - accuracy: 0.8574\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4366 - accuracy: 0.8681\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4214 - accuracy: 0.8645\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4070 - accuracy: 0.8824\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4007 - accuracy: 0.8663\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3734 - accuracy: 0.8966\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3643 - accuracy: 0.9180\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3499 - accuracy: 0.9037\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3407 - accuracy: 0.9251\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3266 - accuracy: 0.9394\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3129 - accuracy: 0.9358\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3043 - accuracy: 0.9483\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2968 - accuracy: 0.9340\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2865 - accuracy: 0.9519\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2771 - accuracy: 0.9394\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2708 - accuracy: 0.9430\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.2738 - accuracy: 0.9412\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2564 - accuracy: 0.9430\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2490 - accuracy: 0.9465\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2429 - accuracy: 0.9608\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2402 - accuracy: 0.9501\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2323 - accuracy: 0.9447\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2302 - accuracy: 0.9572\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2254 - accuracy: 0.9679\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2280 - accuracy: 0.9251\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2071 - accuracy: 0.9733\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2082 - accuracy: 0.9554\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2008 - accuracy: 0.9626\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2136 - accuracy: 0.9412\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1955 - accuracy: 0.9590\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2066 - accuracy: 0.9376\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1997 - accuracy: 0.9465\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1841 - accuracy: 0.9643\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1848 - accuracy: 0.9572\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1841 - accuracy: 0.9537\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1744 - accuracy: 0.9750\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1803 - accuracy: 0.9572\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1671 - accuracy: 0.9715\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1660 - accuracy: 0.9750\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1614 - accuracy: 0.9733\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1652 - accuracy: 0.9697\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1624 - accuracy: 0.9661\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1582 - accuracy: 0.9626\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1537 - accuracy: 0.9733\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1697 - accuracy: 0.9483\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1599 - accuracy: 0.9483\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1724 - accuracy: 0.9430\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1634 - accuracy: 0.9519\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1442 - accuracy: 0.9750\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1387 - accuracy: 0.9822\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1439 - accuracy: 0.9643\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1373 - accuracy: 0.9786\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1377 - accuracy: 0.9768\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1333 - accuracy: 0.9715\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1408 - accuracy: 0.9679\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1308 - accuracy: 0.9715\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1306 - accuracy: 0.9715\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1344 - accuracy: 0.9697\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1281 - accuracy: 0.9786\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1352 - accuracy: 0.9733\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1263 - accuracy: 0.9786\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1260 - accuracy: 0.9733\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1226 - accuracy: 0.9786\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1219 - accuracy: 0.9733\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "Fold 3\n",
      "Model: \"sequential_248\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_744 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_745 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_746 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 1.0523 - accuracy: 0.5027\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9521 - accuracy: 0.5027\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9335 - accuracy: 0.5027\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9180 - accuracy: 0.5098\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9018 - accuracy: 0.5027\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.8882 - accuracy: 0.5081\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8672 - accuracy: 0.5170\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8581 - accuracy: 0.5206\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8423 - accuracy: 0.5635\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8305 - accuracy: 0.5814\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8142 - accuracy: 0.5725\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7979 - accuracy: 0.5886\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7834 - accuracy: 0.6315\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7712 - accuracy: 0.6136\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7543 - accuracy: 0.6154\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7368 - accuracy: 0.6386\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7335 - accuracy: 0.6691\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7040 - accuracy: 0.6547\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6923 - accuracy: 0.6798\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6690 - accuracy: 0.6691\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6523 - accuracy: 0.7013\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6451 - accuracy: 0.6977\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6251 - accuracy: 0.7263\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.6106 - accuracy: 0.6995\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6050 - accuracy: 0.7156\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5744 - accuracy: 0.7585\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5456 - accuracy: 0.7710\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5368 - accuracy: 0.7603\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5279 - accuracy: 0.8086\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4966 - accuracy: 0.8104\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4761 - accuracy: 0.8193\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4595 - accuracy: 0.8623\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4425 - accuracy: 0.8676\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4268 - accuracy: 0.8766\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4090 - accuracy: 0.8980\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4120 - accuracy: 0.8587\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3813 - accuracy: 0.9141\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.3709 - accuracy: 0.9231\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.9338\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3377 - accuracy: 0.9231\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3313 - accuracy: 0.9338\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3192 - accuracy: 0.9249\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3016 - accuracy: 0.9517\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2930 - accuracy: 0.9499\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2801 - accuracy: 0.9714\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2708 - accuracy: 0.9589\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2616 - accuracy: 0.9696\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2522 - accuracy: 0.9642\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2523 - accuracy: 0.9499\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2354 - accuracy: 0.9750\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2314 - accuracy: 0.9624\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2222 - accuracy: 0.9589\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2201 - accuracy: 0.9571\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2138 - accuracy: 0.9606\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2039 - accuracy: 0.9785\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2004 - accuracy: 0.9750\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1972 - accuracy: 0.9606\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1896 - accuracy: 0.9767\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1885 - accuracy: 0.9660\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1848 - accuracy: 0.9678\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1751 - accuracy: 0.9750\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1848 - accuracy: 0.9624\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1788 - accuracy: 0.9606\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1687 - accuracy: 0.9624\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1595 - accuracy: 0.9839\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1570 - accuracy: 0.9857\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1525 - accuracy: 0.9821\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1721 - accuracy: 0.9571\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1617 - accuracy: 0.9589\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1472 - accuracy: 0.9732\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1463 - accuracy: 0.9767\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1416 - accuracy: 0.9767\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1378 - accuracy: 0.9875\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1380 - accuracy: 0.9767\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1369 - accuracy: 0.9803\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1327 - accuracy: 0.9785\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1475 - accuracy: 0.9678\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1260 - accuracy: 0.9875\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1256 - accuracy: 0.9875\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1313 - accuracy: 0.9660\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1368 - accuracy: 0.9589\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1256 - accuracy: 0.9767\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1306 - accuracy: 0.9624\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1277 - accuracy: 0.9571\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1263 - accuracy: 0.9660\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1143 - accuracy: 0.9875\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1161 - accuracy: 0.9767\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1141 - accuracy: 0.9857\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1094 - accuracy: 0.9893\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1173 - accuracy: 0.9678\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1122 - accuracy: 0.9785\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1103 - accuracy: 0.9732\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1094 - accuracy: 0.9839\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1054 - accuracy: 0.9839\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1099 - accuracy: 0.9803\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1147 - accuracy: 0.9660\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.9785\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.9678\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1080 - accuracy: 0.9714\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1036 - accuracy: 0.9821\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "\n",
      "Fold 4\n",
      "Model: \"sequential_249\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_747 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_748 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_749 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 1.2200 - accuracy: 0.4118\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9991 - accuracy: 0.5134\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9450 - accuracy: 0.5027\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9354 - accuracy: 0.5027\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9291 - accuracy: 0.5027\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9205 - accuracy: 0.5027\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9113 - accuracy: 0.5116\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9016 - accuracy: 0.5134\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8944 - accuracy: 0.5116\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8843 - accuracy: 0.5134\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8761 - accuracy: 0.5187\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8673 - accuracy: 0.5419\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8559 - accuracy: 0.5294\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8447 - accuracy: 0.5419\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8334 - accuracy: 0.5348\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8269 - accuracy: 0.5686\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8141 - accuracy: 0.5472\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8000 - accuracy: 0.5597\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7880 - accuracy: 0.5793\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7823 - accuracy: 0.5900\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7637 - accuracy: 0.5900\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7471 - accuracy: 0.6007\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7360 - accuracy: 0.6239\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7162 - accuracy: 0.6613\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7089 - accuracy: 0.6506\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6854 - accuracy: 0.6435\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6731 - accuracy: 0.6667\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6543 - accuracy: 0.7041\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6372 - accuracy: 0.7059\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6379 - accuracy: 0.7201\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6126 - accuracy: 0.7433\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5980 - accuracy: 0.7558\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5752 - accuracy: 0.7594\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5653 - accuracy: 0.7504\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5392 - accuracy: 0.7914\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5253 - accuracy: 0.7932\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5126 - accuracy: 0.8039\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4891 - accuracy: 0.8467\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4825 - accuracy: 0.8253\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4660 - accuracy: 0.8449\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4481 - accuracy: 0.8663\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4404 - accuracy: 0.8592\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4382 - accuracy: 0.8503\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4029 - accuracy: 0.8913\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3994 - accuracy: 0.8877\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3796 - accuracy: 0.9073\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3707 - accuracy: 0.9198\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3600 - accuracy: 0.9251\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3555 - accuracy: 0.9109\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3431 - accuracy: 0.9323\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3358 - accuracy: 0.9198\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3138 - accuracy: 0.9572\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3074 - accuracy: 0.9465\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3063 - accuracy: 0.9269\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3106 - accuracy: 0.9198\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2865 - accuracy: 0.9323\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2835 - accuracy: 0.9412\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2650 - accuracy: 0.9590\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2653 - accuracy: 0.9430\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2498 - accuracy: 0.9733\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2459 - accuracy: 0.9643\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2405 - accuracy: 0.9590\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2355 - accuracy: 0.9537\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2276 - accuracy: 0.9661\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2204 - accuracy: 0.9643\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2334 - accuracy: 0.9394\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2147 - accuracy: 0.9697\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2084 - accuracy: 0.9697\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2112 - accuracy: 0.9572\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1991 - accuracy: 0.9697\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1953 - accuracy: 0.9715\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1920 - accuracy: 0.9733\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1951 - accuracy: 0.9554\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1841 - accuracy: 0.9715\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1776 - accuracy: 0.9679\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1797 - accuracy: 0.9554\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1739 - accuracy: 0.9750\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1741 - accuracy: 0.9715\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1643 - accuracy: 0.9840\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1615 - accuracy: 0.9715\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1807 - accuracy: 0.9430\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1843 - accuracy: 0.9447\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1638 - accuracy: 0.9643\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1541 - accuracy: 0.9608\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9733\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1606 - accuracy: 0.9608\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1452 - accuracy: 0.9822\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1493 - accuracy: 0.9697\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1464 - accuracy: 0.9840\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1391 - accuracy: 0.9786\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1431 - accuracy: 0.9786\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1343 - accuracy: 0.9911\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1335 - accuracy: 0.9768\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1345 - accuracy: 0.9786\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1341 - accuracy: 0.9822\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1383 - accuracy: 0.9679\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1288 - accuracy: 0.9840\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1247 - accuracy: 0.9840\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1329 - accuracy: 0.9697\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1316 - accuracy: 0.9697\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "Fold 5\n",
      "Model: \"sequential_250\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_750 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_751 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_752 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9738 - accuracy: 0.5027\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9566 - accuracy: 0.5027\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9539 - accuracy: 0.5045\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9365 - accuracy: 0.5045\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9289 - accuracy: 0.5027\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9177 - accuracy: 0.5027\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9053 - accuracy: 0.5152\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8976 - accuracy: 0.5045\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8860 - accuracy: 0.5080\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8782 - accuracy: 0.5401\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8538 - accuracy: 0.5312\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8402 - accuracy: 0.5330\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8270 - accuracy: 0.5508\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8215 - accuracy: 0.5847\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8088 - accuracy: 0.5918\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7850 - accuracy: 0.5740\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7646 - accuracy: 0.6292\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7496 - accuracy: 0.6239\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7300 - accuracy: 0.6471\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7116 - accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6942 - accuracy: 0.6791\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6812 - accuracy: 0.6934\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6619 - accuracy: 0.7112\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6417 - accuracy: 0.7201\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6229 - accuracy: 0.7166\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6068 - accuracy: 0.7380\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5846 - accuracy: 0.7558\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5635 - accuracy: 0.7683\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5531 - accuracy: 0.7701\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5291 - accuracy: 0.7986\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5162 - accuracy: 0.7986\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5022 - accuracy: 0.8039\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4736 - accuracy: 0.8307\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4612 - accuracy: 0.8431\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4435 - accuracy: 0.8538\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4319 - accuracy: 0.8699\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4220 - accuracy: 0.8681\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4029 - accuracy: 0.8788\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3813 - accuracy: 0.9073\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3700 - accuracy: 0.9109\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3568 - accuracy: 0.9144\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3446 - accuracy: 0.9216\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3329 - accuracy: 0.9198\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3164 - accuracy: 0.9269\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3064 - accuracy: 0.9323\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2936 - accuracy: 0.9483\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2847 - accuracy: 0.9483\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2852 - accuracy: 0.9305\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2647 - accuracy: 0.9554\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2670 - accuracy: 0.9465\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2577 - accuracy: 0.9412\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2463 - accuracy: 0.9572\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2382 - accuracy: 0.9608\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2281 - accuracy: 0.9643\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2217 - accuracy: 0.9661\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2228 - accuracy: 0.9519\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2138 - accuracy: 0.9643\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2118 - accuracy: 0.9608\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2045 - accuracy: 0.9608\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2083 - accuracy: 0.9501\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1933 - accuracy: 0.9661\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1957 - accuracy: 0.9554\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.9715\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1903 - accuracy: 0.9537\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1772 - accuracy: 0.9679\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1778 - accuracy: 0.9554\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1726 - accuracy: 0.9679\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1649 - accuracy: 0.9786\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1652 - accuracy: 0.9643\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1652 - accuracy: 0.9661\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1585 - accuracy: 0.9750\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1564 - accuracy: 0.9643\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1741 - accuracy: 0.9430\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1751 - accuracy: 0.9412\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1525 - accuracy: 0.9750\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1507 - accuracy: 0.9697\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1469 - accuracy: 0.9715\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1541 - accuracy: 0.9519\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1487 - accuracy: 0.9643\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1447 - accuracy: 0.9715\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1413 - accuracy: 0.9572\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1397 - accuracy: 0.9733\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1465 - accuracy: 0.9554\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1314 - accuracy: 0.9804\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1290 - accuracy: 0.9733\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1318 - accuracy: 0.9733\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1405 - accuracy: 0.9590\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1295 - accuracy: 0.9661\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1331 - accuracy: 0.9679\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1225 - accuracy: 0.9768\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1219 - accuracy: 0.9768\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1243 - accuracy: 0.9715\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1199 - accuracy: 0.9840\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1172 - accuracy: 0.9768\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1181 - accuracy: 0.9786\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1138 - accuracy: 0.9822\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1350 - accuracy: 0.9572\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1262 - accuracy: 0.9590\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1208 - accuracy: 0.9661\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1162 - accuracy: 0.9697\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "---\n",
      "Fold 1:\n",
      "Acurácia: 0.971830985915493\n",
      "Precisão: 0.9733904593059524\n",
      "Revocação: 0.971830985915493\n",
      "F1-Score: 0.9719569188178717\n",
      "---\n",
      "Fold 2:\n",
      "Acurácia: 0.9928057553956835\n",
      "Precisão: 0.9929070827844766\n",
      "Revocação: 0.9928057553956835\n",
      "F1-Score: 0.9927857337076742\n",
      "---\n",
      "Fold 3:\n",
      "Acurácia: 0.9645390070921985\n",
      "Precisão: 0.9650378692931885\n",
      "Revocação: 0.9645390070921985\n",
      "F1-Score: 0.9642901145710474\n",
      "---\n",
      "Fold 4:\n",
      "Acurácia: 0.9640287769784173\n",
      "Precisão: 0.9656832226526472\n",
      "Revocação: 0.9640287769784173\n",
      "F1-Score: 0.9642275695579843\n",
      "---\n",
      "Fold 5:\n",
      "Acurácia: 0.9568345323741008\n",
      "Precisão: 0.9584332533972822\n",
      "Revocação: 0.9568345323741008\n",
      "F1-Score: 0.9562556851070867\n",
      "---\n",
      "\n",
      "Médias e Desvios Padrão Gerais:\n",
      "----------------------------------------------------------------\n",
      "Média Acurácias: 0.9700078115511787\n",
      "Desvio Padrão Acurácias: 0.012347162987585123\n",
      "\n",
      "Média Precisões: 0.9710903774867095\n",
      "Desvio Padrão Precisões: 0.011893964649957161\n",
      "\n",
      "Média Revocações: 0.9700078115511787\n",
      "Desvio Padrão Revocações: 0.012347162987585123\n",
      "\n",
      "Média F1-Scores: 0.9699032043523328\n",
      "Desvio Padrão F1-Scores: 0.012472387755077034\n",
      "\n",
      "\n",
      "Conjunto 10\n",
      "\n",
      "Fold 1\n",
      "Model: \"sequential_251\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_753 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_754 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_755 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0011 - accuracy: 0.4571\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.9713 - accuracy: 0.4714\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9571 - accuracy: 0.4714\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9396 - accuracy: 0.4714\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9279 - accuracy: 0.4946\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9244 - accuracy: 0.4911\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8968 - accuracy: 0.5179\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8800 - accuracy: 0.5196\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8684 - accuracy: 0.5321\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8463 - accuracy: 0.5571\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.8346 - accuracy: 0.5661\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8214 - accuracy: 0.5821\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8053 - accuracy: 0.5911\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7951 - accuracy: 0.6018\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.7794 - accuracy: 0.6179\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7663 - accuracy: 0.6250\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7441 - accuracy: 0.6536\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7298 - accuracy: 0.6464\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7110 - accuracy: 0.6661\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7015 - accuracy: 0.6661\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6789 - accuracy: 0.7036\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6679 - accuracy: 0.7018\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6433 - accuracy: 0.7232\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6301 - accuracy: 0.7411\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6165 - accuracy: 0.7411\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5925 - accuracy: 0.7768\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5710 - accuracy: 0.7964\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5532 - accuracy: 0.7964\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5367 - accuracy: 0.8268\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5305 - accuracy: 0.7946\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5160 - accuracy: 0.8196\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4890 - accuracy: 0.8536\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4706 - accuracy: 0.8786\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4522 - accuracy: 0.8786\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4344 - accuracy: 0.8964\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4215 - accuracy: 0.9179\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4064 - accuracy: 0.9089\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3926 - accuracy: 0.9286\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3803 - accuracy: 0.9321\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3674 - accuracy: 0.9375\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3551 - accuracy: 0.9339\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3563 - accuracy: 0.9089\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3379 - accuracy: 0.9482\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3235 - accuracy: 0.9482\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3191 - accuracy: 0.9393\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3082 - accuracy: 0.9411\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2927 - accuracy: 0.9607\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2858 - accuracy: 0.9500\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2794 - accuracy: 0.9482\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2735 - accuracy: 0.9429\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2667 - accuracy: 0.9589\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2558 - accuracy: 0.9696\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2564 - accuracy: 0.9446\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2475 - accuracy: 0.9482\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2407 - accuracy: 0.9536\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2318 - accuracy: 0.9500\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2247 - accuracy: 0.9750\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.2197 - accuracy: 0.9679\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2139 - accuracy: 0.9696\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2084 - accuracy: 0.9750\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2078 - accuracy: 0.9607\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2023 - accuracy: 0.9554\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2041 - accuracy: 0.9571\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1922 - accuracy: 0.9679\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1862 - accuracy: 0.9714\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1842 - accuracy: 0.9768\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1790 - accuracy: 0.9839\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1942 - accuracy: 0.9411\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1773 - accuracy: 0.9696\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1736 - accuracy: 0.9714\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1808 - accuracy: 0.9554\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1717 - accuracy: 0.9589\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1629 - accuracy: 0.9750\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1611 - accuracy: 0.9750\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1561 - accuracy: 0.9786\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1555 - accuracy: 0.9732\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1521 - accuracy: 0.9732\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1537 - accuracy: 0.9732\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1494 - accuracy: 0.9821\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1468 - accuracy: 0.9732\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1464 - accuracy: 0.9786\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1492 - accuracy: 0.9732\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1677 - accuracy: 0.9357\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1402 - accuracy: 0.9732\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1486 - accuracy: 0.9536\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1678 - accuracy: 0.9411\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1478 - accuracy: 0.9643\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1415 - accuracy: 0.9607\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1302 - accuracy: 0.9732\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1286 - accuracy: 0.9821\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1405 - accuracy: 0.9750\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1340 - accuracy: 0.9643\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1262 - accuracy: 0.9750\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1251 - accuracy: 0.9821\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1242 - accuracy: 0.9714\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1204 - accuracy: 0.9804\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.1193 - accuracy: 0.9857\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1200 - accuracy: 0.9839\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1232 - accuracy: 0.9643\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1196 - accuracy: 0.9750\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "Fold 2\n",
      "Model: \"sequential_252\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_756 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_757 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_758 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 1.5908 - accuracy: 0.3429\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 1.0269 - accuracy: 0.4804\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9750 - accuracy: 0.5107\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9536 - accuracy: 0.4714\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9406 - accuracy: 0.4732\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9295 - accuracy: 0.4732\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9209 - accuracy: 0.5089\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9039 - accuracy: 0.4964\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8925 - accuracy: 0.5357\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8840 - accuracy: 0.5339\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8724 - accuracy: 0.5375\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8640 - accuracy: 0.5714\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8464 - accuracy: 0.5696\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8429 - accuracy: 0.5804\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8280 - accuracy: 0.5911\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8196 - accuracy: 0.6107\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8118 - accuracy: 0.5982\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7988 - accuracy: 0.5982\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7887 - accuracy: 0.5964\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7766 - accuracy: 0.6161\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7634 - accuracy: 0.6268\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7567 - accuracy: 0.6321\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7435 - accuracy: 0.6375\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7234 - accuracy: 0.6554\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7165 - accuracy: 0.6554\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7001 - accuracy: 0.6589\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6855 - accuracy: 0.6821\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6795 - accuracy: 0.6804\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6565 - accuracy: 0.7107\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6457 - accuracy: 0.7161\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6299 - accuracy: 0.7232\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6188 - accuracy: 0.7393\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5983 - accuracy: 0.7429\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5872 - accuracy: 0.7607\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5722 - accuracy: 0.7625\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5523 - accuracy: 0.8018\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5413 - accuracy: 0.7893\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5226 - accuracy: 0.7875\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5033 - accuracy: 0.8196\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4903 - accuracy: 0.8304\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4758 - accuracy: 0.8339\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4568 - accuracy: 0.8500\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4451 - accuracy: 0.8714\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4288 - accuracy: 0.8768\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4224 - accuracy: 0.8857\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4013 - accuracy: 0.9036\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3881 - accuracy: 0.9125\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.3753 - accuracy: 0.9179\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3601 - accuracy: 0.9196\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3485 - accuracy: 0.9393\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.3408 - accuracy: 0.9339\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3256 - accuracy: 0.9304\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3198 - accuracy: 0.9357\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3146 - accuracy: 0.9214\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3108 - accuracy: 0.9161\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2869 - accuracy: 0.9411\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2812 - accuracy: 0.9464\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2865 - accuracy: 0.9196\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2728 - accuracy: 0.9393\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2524 - accuracy: 0.9536\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2475 - accuracy: 0.9589\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2428 - accuracy: 0.9571\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2340 - accuracy: 0.9571\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2294 - accuracy: 0.9554\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2257 - accuracy: 0.9661\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2309 - accuracy: 0.9554\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2311 - accuracy: 0.9357\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2442 - accuracy: 0.9054\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2117 - accuracy: 0.9571\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2022 - accuracy: 0.9625\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2047 - accuracy: 0.9536\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1974 - accuracy: 0.9607\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1947 - accuracy: 0.9589\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1889 - accuracy: 0.9696\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1849 - accuracy: 0.9625\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1843 - accuracy: 0.9571\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1852 - accuracy: 0.9571\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1756 - accuracy: 0.9696\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1776 - accuracy: 0.9571\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1766 - accuracy: 0.9625\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1756 - accuracy: 0.9643\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1686 - accuracy: 0.9554\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1632 - accuracy: 0.9625\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1571 - accuracy: 0.9768\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1651 - accuracy: 0.9607\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1581 - accuracy: 0.9732\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1672 - accuracy: 0.9500\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1572 - accuracy: 0.9696\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1599 - accuracy: 0.9554\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1564 - accuracy: 0.9500\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1475 - accuracy: 0.9732\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1568 - accuracy: 0.9589\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1500 - accuracy: 0.9643\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1502 - accuracy: 0.9643\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1558 - accuracy: 0.9482\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1371 - accuracy: 0.9714\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1374 - accuracy: 0.9768\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1404 - accuracy: 0.9607\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1304 - accuracy: 0.9804\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1314 - accuracy: 0.9714\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "Fold 3\n",
      "Model: \"sequential_253\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_759 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_760 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_761 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 1.8628 - accuracy: 0.2357\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 1.0145 - accuracy: 0.4571\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.9922 - accuracy: 0.4714\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9804 - accuracy: 0.4714\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9766 - accuracy: 0.4714\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9736 - accuracy: 0.4714\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9702 - accuracy: 0.4714\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9670 - accuracy: 0.4714\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9642 - accuracy: 0.4714\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9587 - accuracy: 0.4714\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9541 - accuracy: 0.4714\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9544 - accuracy: 0.4714\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9449 - accuracy: 0.4714\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9408 - accuracy: 0.4714\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9324 - accuracy: 0.4714\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9332 - accuracy: 0.4714\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9208 - accuracy: 0.4714\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9187 - accuracy: 0.4714\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9118 - accuracy: 0.4875\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9032 - accuracy: 0.4804\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8918 - accuracy: 0.4893\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8822 - accuracy: 0.4946\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8742 - accuracy: 0.5232\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8611 - accuracy: 0.5393\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8465 - accuracy: 0.5482\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8358 - accuracy: 0.6196\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8306 - accuracy: 0.5661\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8155 - accuracy: 0.6125\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8041 - accuracy: 0.5839\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7923 - accuracy: 0.6518\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7822 - accuracy: 0.6393\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7643 - accuracy: 0.6232\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7505 - accuracy: 0.6607\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7432 - accuracy: 0.6714\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7215 - accuracy: 0.6768\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7052 - accuracy: 0.6786\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6888 - accuracy: 0.6929\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.6724 - accuracy: 0.7107\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6682 - accuracy: 0.6786\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6434 - accuracy: 0.7107\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6211 - accuracy: 0.7375\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6035 - accuracy: 0.7554\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5873 - accuracy: 0.7500\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5721 - accuracy: 0.7696\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5665 - accuracy: 0.7964\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5353 - accuracy: 0.7929\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5179 - accuracy: 0.8107\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5050 - accuracy: 0.8214\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4938 - accuracy: 0.8232\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4701 - accuracy: 0.8500\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4537 - accuracy: 0.8893\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4416 - accuracy: 0.8929\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4258 - accuracy: 0.9018\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.4148 - accuracy: 0.9000\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4078 - accuracy: 0.8946\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3933 - accuracy: 0.8982\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3847 - accuracy: 0.9089\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3715 - accuracy: 0.9107\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3616 - accuracy: 0.9232\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3478 - accuracy: 0.9286\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3370 - accuracy: 0.9339\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3434 - accuracy: 0.9071\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3342 - accuracy: 0.9125\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3151 - accuracy: 0.9393\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3064 - accuracy: 0.9482\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2995 - accuracy: 0.9375\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2947 - accuracy: 0.9375\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2870 - accuracy: 0.9482\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2815 - accuracy: 0.9411\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2714 - accuracy: 0.9536\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2666 - accuracy: 0.9446\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2648 - accuracy: 0.9464\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2532 - accuracy: 0.9500\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2480 - accuracy: 0.9589\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2438 - accuracy: 0.9607\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2458 - accuracy: 0.9536\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2392 - accuracy: 0.9589\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2372 - accuracy: 0.9393\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2392 - accuracy: 0.9268\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2258 - accuracy: 0.9482\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2231 - accuracy: 0.9661\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2195 - accuracy: 0.9500\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2116 - accuracy: 0.9679\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2081 - accuracy: 0.9554\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2045 - accuracy: 0.9554\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.2004 - accuracy: 0.9714\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2019 - accuracy: 0.9518\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1946 - accuracy: 0.9643\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1976 - accuracy: 0.9571\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1957 - accuracy: 0.9589\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1865 - accuracy: 0.9750\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1827 - accuracy: 0.9786\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1886 - accuracy: 0.9571\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1819 - accuracy: 0.9625\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1863 - accuracy: 0.9446\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1816 - accuracy: 0.9464\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1776 - accuracy: 0.9607\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1727 - accuracy: 0.9607\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1713 - accuracy: 0.9750\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1848 - accuracy: 0.9357\n",
      "5/5 [==============================] - 0s 1000us/step\n",
      "\n",
      "Fold 4\n",
      "Model: \"sequential_254\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_762 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_763 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_764 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 1.2347 - accuracy: 0.3565\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9642 - accuracy: 0.4706\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9553 - accuracy: 0.4706\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9472 - accuracy: 0.4706\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9336 - accuracy: 0.4706\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.9232 - accuracy: 0.4724\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9133 - accuracy: 0.4902\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9056 - accuracy: 0.4848\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8906 - accuracy: 0.5098\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8743 - accuracy: 0.5330\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8629 - accuracy: 0.5348\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8472 - accuracy: 0.5597\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8358 - accuracy: 0.5526\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8200 - accuracy: 0.5811\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8039 - accuracy: 0.6025\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7903 - accuracy: 0.6114\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7762 - accuracy: 0.6221\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7589 - accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7469 - accuracy: 0.6649\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7279 - accuracy: 0.6560\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7061 - accuracy: 0.6970\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6851 - accuracy: 0.7308\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6728 - accuracy: 0.7077\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6459 - accuracy: 0.7451\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6245 - accuracy: 0.7683\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6024 - accuracy: 0.7736\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5802 - accuracy: 0.7879\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5623 - accuracy: 0.8075\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5495 - accuracy: 0.8057\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5218 - accuracy: 0.8307\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5010 - accuracy: 0.8556\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4851 - accuracy: 0.8627\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4754 - accuracy: 0.8503\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4495 - accuracy: 0.8877\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4311 - accuracy: 0.8948\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4194 - accuracy: 0.8948\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4129 - accuracy: 0.8877\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3964 - accuracy: 0.9020\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3743 - accuracy: 0.9287\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3630 - accuracy: 0.9287\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3496 - accuracy: 0.9358\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3393 - accuracy: 0.9287\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.3292 - accuracy: 0.9465\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3266 - accuracy: 0.9269\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3123 - accuracy: 0.9287\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3024 - accuracy: 0.9234\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3006 - accuracy: 0.9305\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2913 - accuracy: 0.9323\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2749 - accuracy: 0.9554\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2718 - accuracy: 0.9501\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2696 - accuracy: 0.9358\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2576 - accuracy: 0.9608\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2545 - accuracy: 0.9483\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2512 - accuracy: 0.9412\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2375 - accuracy: 0.9679\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2345 - accuracy: 0.9519\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2283 - accuracy: 0.9608\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2288 - accuracy: 0.9590\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2260 - accuracy: 0.9501\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2187 - accuracy: 0.9519\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2116 - accuracy: 0.9554\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2084 - accuracy: 0.9590\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1997 - accuracy: 0.9733\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1957 - accuracy: 0.9768\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2137 - accuracy: 0.9305\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2096 - accuracy: 0.9412\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1873 - accuracy: 0.9626\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1973 - accuracy: 0.9519\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2147 - accuracy: 0.9144\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2020 - accuracy: 0.9412\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1841 - accuracy: 0.9661\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1851 - accuracy: 0.9501\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1769 - accuracy: 0.9519\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1848 - accuracy: 0.9376\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1672 - accuracy: 0.9768\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1642 - accuracy: 0.9750\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1695 - accuracy: 0.9643\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1822 - accuracy: 0.9430\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1632 - accuracy: 0.9554\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1553 - accuracy: 0.9822\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1576 - accuracy: 0.9697\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1595 - accuracy: 0.9679\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1617 - accuracy: 0.9608\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1498 - accuracy: 0.9786\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.1524 - accuracy: 0.9750\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1455 - accuracy: 0.9822\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1445 - accuracy: 0.9893\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1470 - accuracy: 0.9715\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1456 - accuracy: 0.9786\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1440 - accuracy: 0.9715\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1386 - accuracy: 0.9768\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.1421 - accuracy: 0.9804\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1422 - accuracy: 0.9661\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1353 - accuracy: 0.9804\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1350 - accuracy: 0.9733\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1332 - accuracy: 0.9768\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1352 - accuracy: 0.9697\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1298 - accuracy: 0.9733\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1275 - accuracy: 0.9822\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1348 - accuracy: 0.9643\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "\n",
      "Fold 5\n",
      "Model: \"sequential_255\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_765 (Dense)           (None, 64)                320       \n",
      "                                                                 \n",
      " dense_766 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_767 (Dense)           (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 1.2604 - accuracy: 0.4275\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9752 - accuracy: 0.4741\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9495 - accuracy: 0.4848\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9382 - accuracy: 0.4830\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9339 - accuracy: 0.5027\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9238 - accuracy: 0.5098\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.9125 - accuracy: 0.5277\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9010 - accuracy: 0.5277\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8938 - accuracy: 0.5277\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8893 - accuracy: 0.5420\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8701 - accuracy: 0.5385\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8695 - accuracy: 0.5474\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8593 - accuracy: 0.5778\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.8440 - accuracy: 0.5725\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8444 - accuracy: 0.5581\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8288 - accuracy: 0.5653\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.8114 - accuracy: 0.5886\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7993 - accuracy: 0.5886\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7943 - accuracy: 0.5868\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7828 - accuracy: 0.6029\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.7681 - accuracy: 0.6011\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7547 - accuracy: 0.6100\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7556 - accuracy: 0.5939\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7284 - accuracy: 0.6440\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7234 - accuracy: 0.6637\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7042 - accuracy: 0.6655\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6893 - accuracy: 0.6637\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6787 - accuracy: 0.6852\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6883 - accuracy: 0.6565\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6522 - accuracy: 0.6941\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6516 - accuracy: 0.7030\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6306 - accuracy: 0.6995\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6181 - accuracy: 0.7299\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6069 - accuracy: 0.7424\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5845 - accuracy: 0.7764\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.5843 - accuracy: 0.7138\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5687 - accuracy: 0.7621\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5492 - accuracy: 0.7961\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5412 - accuracy: 0.7710\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5218 - accuracy: 0.7889\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5073 - accuracy: 0.8086\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4952 - accuracy: 0.8175\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4806 - accuracy: 0.8444\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4695 - accuracy: 0.8444\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4550 - accuracy: 0.8676\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4436 - accuracy: 0.8784\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4325 - accuracy: 0.8801\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4177 - accuracy: 0.8962\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4092 - accuracy: 0.8909\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3968 - accuracy: 0.8855\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3907 - accuracy: 0.9016\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3748 - accuracy: 0.9141\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3706 - accuracy: 0.9106\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3579 - accuracy: 0.9177\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3424 - accuracy: 0.9338\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3415 - accuracy: 0.9159\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3267 - accuracy: 0.9392\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3186 - accuracy: 0.9249\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.3071 - accuracy: 0.9410\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3036 - accuracy: 0.9159\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2953 - accuracy: 0.9356\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2905 - accuracy: 0.9374\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3035 - accuracy: 0.8837\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2910 - accuracy: 0.9141\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2662 - accuracy: 0.9374\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2649 - accuracy: 0.9463\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2576 - accuracy: 0.9338\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2475 - accuracy: 0.9445\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2561 - accuracy: 0.9374\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2387 - accuracy: 0.9481\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2340 - accuracy: 0.9589\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2389 - accuracy: 0.9445\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2282 - accuracy: 0.9428\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2193 - accuracy: 0.9589\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2170 - accuracy: 0.9571\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.2185 - accuracy: 0.9606\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2287 - accuracy: 0.9374\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2026 - accuracy: 0.9642\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1974 - accuracy: 0.9732\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1986 - accuracy: 0.9589\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1992 - accuracy: 0.9392\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2297 - accuracy: 0.9052\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2030 - accuracy: 0.9428\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1895 - accuracy: 0.9660\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1937 - accuracy: 0.9535\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1861 - accuracy: 0.9553\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.2078 - accuracy: 0.9231\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1990 - accuracy: 0.9338\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1865 - accuracy: 0.9463\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1752 - accuracy: 0.9624\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1831 - accuracy: 0.9410\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1855 - accuracy: 0.9445\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1670 - accuracy: 0.9767\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1625 - accuracy: 0.9803\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1756 - accuracy: 0.9535\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1667 - accuracy: 0.9553\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1781 - accuracy: 0.9392\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1696 - accuracy: 0.9428\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1633 - accuracy: 0.9660\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1515 - accuracy: 0.9714\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "\n",
      "---\n",
      "Fold 1:\n",
      "Acurácia: 0.95\n",
      "Precisão: 0.9515395797541958\n",
      "Revocação: 0.95\n",
      "F1-Score: 0.9494080113434951\n",
      "---\n",
      "Fold 2:\n",
      "Acurácia: 0.9428571428571428\n",
      "Precisão: 0.9456221198156681\n",
      "Revocação: 0.9428571428571428\n",
      "F1-Score: 0.9435159637366969\n",
      "---\n",
      "Fold 3:\n",
      "Acurácia: 0.9928571428571429\n",
      "Precisão: 0.9930059523809522\n",
      "Revocação: 0.9928571428571429\n",
      "F1-Score: 0.9928674740285828\n",
      "---\n",
      "Fold 4:\n",
      "Acurácia: 0.9712230215827338\n",
      "Precisão: 0.9721223021582733\n",
      "Revocação: 0.9712230215827338\n",
      "F1-Score: 0.9714184789647823\n",
      "---\n",
      "Fold 5:\n",
      "Acurácia: 0.950354609929078\n",
      "Precisão: 0.9534381745297564\n",
      "Revocação: 0.950354609929078\n",
      "F1-Score: 0.9507859234312125\n",
      "---\n",
      "\n",
      "Médias e Desvios Padrão Gerais:\n",
      "----------------------------------------------------------------\n",
      "Média Acurácias: 0.9614583834452194\n",
      "Desvio Padrão Acurácias: 0.018340254848040697\n",
      "\n",
      "Média Precisões: 0.9631456257277691\n",
      "Desvio Padrão Precisões: 0.01736794748337697\n",
      "\n",
      "Média Revocações: 0.9614583834452194\n",
      "Desvio Padrão Revocações: 0.018340254848040697\n",
      "\n",
      "Média F1-Scores: 0.9615991703009538\n",
      "Desvio Padrão F1-Scores: 0.018257484300288333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conjuntos = 10\n",
    "resultados_acuracia = []\n",
    "resultados_precisao = []\n",
    "resultados_revocacao = []\n",
    "resultados_f1 = []\n",
    "best_models = []\n",
    "\n",
    "for i in range(conjuntos):\n",
    "    print(f'\\nConjunto {i + 1}')\n",
    "    num_classes, input, X_train_array, y_train_array, X_test_array, y_test_array = get_data_from_conjunto(i)\n",
    "\n",
    "    media_acuracia, media_precisao, media_revocacao, media_f1, best_model = kfold_cross_validation(X_train_array[i], y_train_array[i], num_classes, input)\n",
    "\n",
    "    resultados_acuracia.append(media_acuracia)\n",
    "    resultados_precisao.append(media_precisao)\n",
    "    resultados_revocacao.append(media_revocacao)\n",
    "    resultados_f1.append(media_f1)\n",
    "    best_models.append(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6) Analisando resultados gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Acurácia  Precisão  Revocação  F1-Score\n",
      "0  0.964295   0.96588   0.964295  0.964242\n"
     ]
    }
   ],
   "source": [
    "# Calculate the overall mean\n",
    "overall_mean_acuracia = sum(resultados_acuracia) / len(resultados_acuracia)\n",
    "overall_mean_precisao = sum(resultados_precisao) / len(resultados_precisao)\n",
    "overall_mean_revocacao = sum(resultados_revocacao) / len(resultados_revocacao)\n",
    "overall_mean_f1 = sum(resultados_f1) / len(resultados_f1)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Acurácia': [overall_mean_acuracia],\n",
    "    'Precisão': [overall_mean_precisao],\n",
    "    'Revocação': [overall_mean_revocacao],\n",
    "    'F1-Score': [overall_mean_f1]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the table\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7) Predição, Matriz de confusão e Métricas de eficácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "Eficácia do conjunto 1\n",
      "10/10 [==============================] - 0s 666us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no conjunto de teste: 98.67%\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       151\n",
      "           1       1.00      0.97      0.99        69\n",
      "           2       0.95      1.00      0.98        80\n",
      "\n",
      "    accuracy                           0.99       300\n",
      "   macro avg       0.98      0.99      0.98       300\n",
      "weighted avg       0.99      0.99      0.99       300\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Eficácia do conjunto 2\n",
      "10/10 [==============================] - 0s 667us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no conjunto de teste: 98.33%\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       168\n",
      "           1       1.00      1.00      1.00        46\n",
      "           2       0.97      0.98      0.97        86\n",
      "\n",
      "    accuracy                           0.98       300\n",
      "   macro avg       0.98      0.99      0.99       300\n",
      "weighted avg       0.98      0.98      0.98       300\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Eficácia do conjunto 3\n",
      "10/10 [==============================] - 0s 778us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no conjunto de teste: 96.67%\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       153\n",
      "           1       1.00      0.95      0.98        62\n",
      "           2       0.93      0.95      0.94        85\n",
      "\n",
      "    accuracy                           0.97       300\n",
      "   macro avg       0.97      0.96      0.96       300\n",
      "weighted avg       0.97      0.97      0.97       300\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Eficácia do conjunto 4\n",
      "10/10 [==============================] - 0s 555us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no conjunto de teste: 99.33%\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       143\n",
      "           1       0.98      0.98      0.98        58\n",
      "           2       0.99      0.99      0.99        99\n",
      "\n",
      "    accuracy                           0.99       300\n",
      "   macro avg       0.99      0.99      0.99       300\n",
      "weighted avg       0.99      0.99      0.99       300\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Eficácia do conjunto 5\n",
      "10/10 [==============================] - 0s 667us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no conjunto de teste: 98.67%\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       140\n",
      "           1       1.00      0.97      0.99        76\n",
      "           2       0.97      0.99      0.98        84\n",
      "\n",
      "    accuracy                           0.99       300\n",
      "   macro avg       0.99      0.98      0.99       300\n",
      "weighted avg       0.99      0.99      0.99       300\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Eficácia do conjunto 6\n",
      "10/10 [==============================] - 0s 667us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no conjunto de teste: 96.00%\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99       141\n",
      "           1       0.94      0.94      0.94        65\n",
      "           2       0.92      0.96      0.94        94\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.95      0.96      0.95       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Eficácia do conjunto 7\n",
      "10/10 [==============================] - 0s 666us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no conjunto de teste: 99.67%\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       142\n",
      "           1       1.00      1.00      1.00        66\n",
      "           2       0.99      1.00      0.99        92\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Eficácia do conjunto 8\n",
      "10/10 [==============================] - 0s 667us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no conjunto de teste: 99.00%\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       144\n",
      "           1       0.97      0.98      0.98        64\n",
      "           2       0.99      0.98      0.98        92\n",
      "\n",
      "    accuracy                           0.99       300\n",
      "   macro avg       0.99      0.99      0.99       300\n",
      "weighted avg       0.99      0.99      0.99       300\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Eficácia do conjunto 9\n",
      "10/10 [==============================] - 0s 667us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no conjunto de teste: 96.67%\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       164\n",
      "           1       1.00      0.98      0.99        52\n",
      "           2       0.96      0.92      0.94        84\n",
      "\n",
      "    accuracy                           0.97       300\n",
      "   macro avg       0.97      0.96      0.97       300\n",
      "weighted avg       0.97      0.97      0.97       300\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Eficácia do conjunto 10\n",
      "10/10 [==============================] - 0s 778us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no conjunto de teste: 99.00%\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       147\n",
      "           1       0.97      1.00      0.98        56\n",
      "           2       0.99      0.98      0.98        97\n",
      "\n",
      "    accuracy                           0.99       300\n",
      "   macro avg       0.99      0.99      0.99       300\n",
      "weighted avg       0.99      0.99      0.99       300\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------------------------------------\")\n",
    "# List to store average accuracies for each conjunto\n",
    "average_accuracies = []\n",
    "for i in range(conjuntos):\n",
    "    print(f'Eficácia do conjunto {i + 1}')\n",
    "    X_test = X_test_array[i]\n",
    "    y_test = y_test_array[i]\n",
    "\n",
    "    # Load the trained model for the current dataset\n",
    "    neuralNetwork = best_models[i]\n",
    "\n",
    "    # Ensure that the data type is float32\n",
    "    X_test = X_test.astype('float32')\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = neuralNetwork.predict(X_test)\n",
    "\n",
    "    # Convert predictions to labels\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "    y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(y_test_labels, y_pred_labels)\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=range(num_classes), yticklabels=range(num_classes))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix - Conjunto {i + 1}')\n",
    "    plt.show()\n",
    "\n",
    "      # Calculate and print accuracy\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
    "\n",
    "    # Append accuracy to the list\n",
    "    average_accuracies.append(accuracy)\n",
    "    \n",
    "    print(f'Acurácia no conjunto de teste: {accuracy * 100:.2f}%\\n')\n",
    "\n",
    "\n",
    "    # Print classification report\n",
    "    classification_rep = classification_report(y_test_labels, y_pred_labels)\n",
    "    print(f'Relatório de Classificação:\\n{classification_rep}')\n",
    "    \n",
    "\n",
    "    print('\\n----------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBS: Verificando qual conjunto obteve o melhor resultado para ser usado nos testes dos parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "O conjunto 7 obteve os melhores resultados.\n"
     ]
    }
   ],
   "source": [
    "# Find the index of the conjunto with the highest average accuracy\n",
    "best_conjunto_index = np.argmax(average_accuracies)\n",
    "\n",
    "# Print the conjunto with the highest average accuracy\n",
    "print(f\"\\nO conjunto {best_conjunto_index + 1} obteve os melhores resultados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Experimentando as melhores configurações de parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Carregar os dados de treinamento e teste do melhor conjunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUDAR ISSO -> ESCOLHER UM NUMERO ENTRE 1 A 10 E PEGAR AQUELE CONJUNTO\n",
    "\n",
    "X_train = X_train_array[best_conjunto_index]\n",
    "y_train = y_train_array[best_conjunto_index]\n",
    "X_test = X_test_array[best_conjunto_index]\n",
    "y_test = y_test_array[best_conjunto_index]\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Experimentando diferentes redes neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = [\n",
    "    (32, 32),        # Exemplo de arquitetura 1\n",
    "    (64, 32, 16),    # Exemplo de arquitetura 2\n",
    "    (128, 64),       # Exemplo de arquitetura 3\n",
    "]\n",
    "\n",
    "hyperparameters = {\n",
    "    'activation_function': ['relu', 'tanh', 'sigmoid'],\n",
    "    'optimizer': ['adam', 'sgd', 'rmsprop'],\n",
    "    'batch_size': [32, 64, 128]\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_accuracy = 0.0\n",
    "min_loss = 100\n",
    "\n",
    "accuracies_train = []  \n",
    "accuracies_test = [] \n",
    "\n",
    "table_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Treinando redes neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 889us/step - loss: 0.3177 - accuracy: 0.9500\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 95.00%\n",
      "Loss final: 31.77%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.5616 - accuracy: 0.7800\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 78.00%\n",
      "Loss final: 56.16%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.7138 - accuracy: 0.6533\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 65.33%\n",
      "Loss final: 71.38%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.7535 - accuracy: 0.5167\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 51.67%\n",
      "Loss final: 75.35%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.8428 - accuracy: 0.5000\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 50.00%\n",
      "Loss final: 84.28%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9418 - accuracy: 0.4733\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 47.33%\n",
      "Loss final: 94.18%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.3601 - accuracy: 0.9167\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 91.67%\n",
      "Loss final: 36.01%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.6164 - accuracy: 0.7233\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 72.33%\n",
      "Loss final: 61.64%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 778us/step - loss: 0.7412 - accuracy: 0.6100\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 61.00%\n",
      "Loss final: 74.12%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.1682 - accuracy: 0.9867\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 98.67%\n",
      "Loss final: 16.82%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.2355 - accuracy: 0.9667\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 96.67%\n",
      "Loss final: 23.55%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.4967 - accuracy: 0.8600\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 86.00%\n",
      "Loss final: 49.67%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 1000us/step - loss: 0.5353 - accuracy: 0.7133\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 71.33%\n",
      "Loss final: 53.53%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.7248 - accuracy: 0.7433\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 74.33%\n",
      "Loss final: 72.48%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.8860 - accuracy: 0.4767\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 47.67%\n",
      "Loss final: 88.60%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.1402 - accuracy: 0.9800\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 98.00%\n",
      "Loss final: 14.02%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.2572 - accuracy: 0.9367\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 93.67%\n",
      "Loss final: 25.72%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.4246 - accuracy: 0.8333\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 83.33%\n",
      "Loss final: 42.46%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.3848 - accuracy: 0.9333\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 93.33%\n",
      "Loss final: 38.48%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.5035 - accuracy: 0.8733\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 87.33%\n",
      "Loss final: 50.35%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.8328 - accuracy: 0.5433\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 54.33%\n",
      "Loss final: 83.28%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0286 - accuracy: 0.4733\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 47.33%\n",
      "Loss final: 102.86%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 1.0378 - accuracy: 0.4733\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 47.33%\n",
      "Loss final: 103.78%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0442 - accuracy: 0.4733\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 47.33%\n",
      "Loss final: 104.42%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 778us/step - loss: 0.4008 - accuracy: 0.9033\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 90.33%\n",
      "Loss final: 40.08%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.6220 - accuracy: 0.7867\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 78.67%\n",
      "Loss final: 62.20%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.8381 - accuracy: 0.4833\n",
      "Arquitetura (32, 32):\n",
      "Acurácia na validação: 48.33%\n",
      "Loss final: 83.81%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.1254 - accuracy: 0.9833\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 98.33%\n",
      "Loss final: 12.54%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.3068 - accuracy: 0.9533\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 95.33%\n",
      "Loss final: 30.68%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7679 - accuracy: 0.5500\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 55.00%\n",
      "Loss final: 76.79%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 1000us/step - loss: 0.6381 - accuracy: 0.8067\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 80.67%\n",
      "Loss final: 63.81%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.8534 - accuracy: 0.4767\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 47.67%\n",
      "Loss final: 85.34%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.9071 - accuracy: 0.5200\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 52.00%\n",
      "Loss final: 90.71%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2088 - accuracy: 0.9767\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 97.67%\n",
      "Loss final: 20.88%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.4525 - accuracy: 0.9067\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 90.67%\n",
      "Loss final: 45.25%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.5971 - accuracy: 0.8333\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 83.33%\n",
      "Loss final: 59.71%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.1518 - accuracy: 0.9233\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 92.33%\n",
      "Loss final: 15.18%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.0851 - accuracy: 0.9900\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 99.00%\n",
      "Loss final: 8.51%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 888us/step - loss: 0.1561 - accuracy: 0.9667\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 96.67%\n",
      "Loss final: 15.61%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.3831 - accuracy: 0.8300\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 83.00%\n",
      "Loss final: 38.31%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.4377 - accuracy: 0.9233\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 92.33%\n",
      "Loss final: 43.77%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.6670 - accuracy: 0.8033\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 80.33%\n",
      "Loss final: 66.70%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.9667\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 96.67%\n",
      "Loss final: 9.44%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1456 - accuracy: 0.9533\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 95.33%\n",
      "Loss final: 14.56%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.2334 - accuracy: 0.9100\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 91.00%\n",
      "Loss final: 23.34%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.2045 - accuracy: 0.9767\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 97.67%\n",
      "Loss final: 20.45%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 1000us/step - loss: 0.3654 - accuracy: 0.9333\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 93.33%\n",
      "Loss final: 36.54%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.8236 - accuracy: 0.5800\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 58.00%\n",
      "Loss final: 82.36%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 1.0444 - accuracy: 0.4733\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 47.33%\n",
      "Loss final: 104.44%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 1.0524 - accuracy: 0.4733\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 47.33%\n",
      "Loss final: 105.24%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 1.0509 - accuracy: 0.4733\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 47.33%\n",
      "Loss final: 105.09%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.2563 - accuracy: 0.9433\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 94.33%\n",
      "Loss final: 25.63%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 1000us/step - loss: 0.4281 - accuracy: 0.8833\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 88.33%\n",
      "Loss final: 42.81%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.8895 - accuracy: 0.5233\n",
      "Arquitetura (64, 32, 16):\n",
      "Acurácia na validação: 52.33%\n",
      "Loss final: 88.95%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.1839 - accuracy: 0.9867\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 98.67%\n",
      "Loss final: 18.39%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.2632 - accuracy: 0.9733\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 97.33%\n",
      "Loss final: 26.32%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.4313 - accuracy: 0.9267\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 92.67%\n",
      "Loss final: 43.13%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6449 - accuracy: 0.8033\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 80.33%\n",
      "Loss final: 64.49%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.8392 - accuracy: 0.5100\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 51.00%\n",
      "Loss final: 83.92%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.9141 - accuracy: 0.4733\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 47.33%\n",
      "Loss final: 91.41%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 1000us/step - loss: 0.2522 - accuracy: 0.9133\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 91.33%\n",
      "Loss final: 25.22%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.4855 - accuracy: 0.7400\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 74.00%\n",
      "Loss final: 48.55%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6361 - accuracy: 0.6533\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 65.33%\n",
      "Loss final: 63.61%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: relu\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9700\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 97.00%\n",
      "Loss final: 9.68%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.1305 - accuracy: 0.9900\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 99.00%\n",
      "Loss final: 13.05%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.1894 - accuracy: 0.9933\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 99.33%\n",
      "Loss final: 18.94%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.3291 - accuracy: 0.9333\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 93.33%\n",
      "Loss final: 32.91%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.5204 - accuracy: 0.9033\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 90.33%\n",
      "Loss final: 52.04%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.6513 - accuracy: 0.6233\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 62.33%\n",
      "Loss final: 65.13%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.1246 - accuracy: 0.9500\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 95.00%\n",
      "Loss final: 12.46%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.1843 - accuracy: 0.9433\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 94.33%\n",
      "Loss final: 18.43%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.3286 - accuracy: 0.8433\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 84.33%\n",
      "Loss final: 32.86%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.1580 - accuracy: 0.9767\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 97.67%\n",
      "Loss final: 15.80%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.2824 - accuracy: 0.9400\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 94.00%\n",
      "Loss final: 28.24%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.4220 - accuracy: 0.9033\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 90.33%\n",
      "Loss final: 42.20%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.9660 - accuracy: 0.4733\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 47.33%\n",
      "Loss final: 96.60%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 1.0006 - accuracy: 0.4733\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 47.33%\n",
      "Loss final: 100.06%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 1.0261 - accuracy: 0.4733\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 47.33%\n",
      "Loss final: 102.61%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: sgd\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.2161 - accuracy: 0.9367\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 93.67%\n",
      "Loss final: 21.61%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 32\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.2954 - accuracy: 0.9333\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 93.33%\n",
      "Loss final: 29.54%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 64\n",
      "----------------------------------------------------------------\n",
      "\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.8933\n",
      "Arquitetura (128, 64):\n",
      "Acurácia na validação: 89.33%\n",
      "Loss final: 44.83%\n",
      "Hiperparâmetros:\n",
      "- Função de Ativação: sigmoid\n",
      "- Otimizador: rmsprop\n",
      "- Tamanho do Lote: 128\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Melhor Modelo:\n",
      "Acurácia na Validação: 99.33%\n",
      "Melhores Hiperparâmetros:\n",
      "- Arquitetura: (128, 64)\n",
      "- Função de Ativação: tanh\n",
      "- Otimizador: adam\n",
      "- Tamanho do Lote: 128\n"
     ]
    }
   ],
   "source": [
    "combination_number = 1\n",
    "\n",
    "for architecture in architectures:\n",
    "    for activation_function in hyperparameters['activation_function']:\n",
    "        for optimizer in hyperparameters['optimizer']:\n",
    "            for batch_size in hyperparameters['batch_size']:\n",
    "                    model = Sequential()\n",
    "                    for units in architecture:\n",
    "                        model.add(Dense(units, activation=activation_function, input_dim=X_train.shape[1]))\n",
    "                    model.add(Dense(3, activation='softmax'))\n",
    "                    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "                    \n",
    "                    history = model.fit(X_train, y_train, epochs=50, batch_size=batch_size, verbose=0)\n",
    "\n",
    "                    final_training_accuracy = history.history['accuracy'][-1]\n",
    "                        \n",
    "                    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "                    # _, test_accuracy = model.evaluate(X_test, y_test)\n",
    "                    # accuracies_train.append(train_accuracy)\n",
    "                    # accuracies_test.append(test_accuracy)\n",
    "\n",
    "                    print(f'Arquitetura {architecture}:')\n",
    "                    print(f'Acurácia na validação: {accuracy * 100:.2f}%')\n",
    "                    print(f'Loss final: {loss * 100:.2f}%')\n",
    "                    print(\"Hiperparâmetros:\")\n",
    "                    print(f'- Função de Ativação: {activation_function}')\n",
    "                    print(f'- Otimizador: {optimizer}')\n",
    "                    print(f'- Tamanho do Lote: {batch_size}')\n",
    "                    print(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "                    # Coletar informações da iteração atual para tabela\n",
    "                    row = [combination_number, f'Arquitetura {architecture}', activation_function, optimizer, batch_size, final_training_accuracy * 100, accuracy * 100, loss * 100]\n",
    "                    table_data.append(row)\n",
    "\n",
    "                    combination_number += 1\n",
    "                    \n",
    "                    if accuracy > best_accuracy and loss < min_loss:\n",
    "                        best_accuracy = accuracy\n",
    "                        best_model = model\n",
    "                        best_hyperparameters = {\n",
    "                        'Arquitetura': architecture,\n",
    "                        'Função de Ativação': activation_function,\n",
    "                        'Otimizador': optimizer,\n",
    "                        'Tamanho do Lote': batch_size\n",
    "                    }\n",
    "\n",
    "        \n",
    "# Imprimir informações sobre o melhor modelo\n",
    "print(\"Melhor Modelo:\")\n",
    "print(f\"Acurácia na Validação: {best_accuracy * 100:.2f}%\")\n",
    "print(\"Melhores Hiperparâmetros:\")\n",
    "for key, value in best_hyperparameters.items():\n",
    "    print(f\"- {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3.1) Construindo redes neurais\n",
    "# for architecture in architectures:\n",
    "#     model = Sequential()\n",
    "#     for units in architecture:\n",
    "#         model.add(Dense(units, activation='relu', input_dim=X_train.shape[1]))\n",
    "#     model.add(Dense(3, activation='softmax'))  # 3 unidades na camada de saída para as três classes\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     history = model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "#     train_accuracy = [acc * 100 for acc in history.history['accuracy']]\n",
    "\n",
    "#     loss, accuracy = model.evaluate(X_val, y_val)\n",
    "\n",
    "#     _, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    \n",
    "#     accuracies_train.append(train_accuracy)\n",
    "#     accuracies_test.append(test_accuracy)\n",
    "\n",
    "#     print(f'Arquitetura {architecture}: Acurácia na validação: {accuracy * 100:.2f}%')\n",
    "#     print(f'Arquitetura {architecture}: Loss final: {loss * 100:.2f}%')\n",
    "#     print(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "#     if accuracy > best_accuracy and loss < min_loss:\n",
    "#         best_accuracy = accuracy\n",
    "#         best_model = model\n",
    "\n",
    "### 3.2) Plotando Diferenças\n",
    "# plt.figure(figsize=(12, 6))\n",
    "\n",
    "# for i, architecture in enumerate(architectures):\n",
    "#     plt.plot(accuracies_train[i], label=f'Treinamento - Arquitetura {architecture}')\n",
    "\n",
    "# plt.title('Acurácia de Treinamento')\n",
    "# plt.xlabel('Épocas')\n",
    "# plt.ylabel('Acurácia')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.ylim(0, 100)\n",
    "\n",
    "# test_accuracies = [accuracy * 100 for accuracy in accuracies_test]\n",
    "# architecture_labels = [f'Arquitetura {architecture}' for architecture in architectures]\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.bar(architecture_labels, test_accuracies, color='dodgerblue', alpha=0.7)\n",
    "# plt.title('Acurácia no Conjunto de Teste')\n",
    "# plt.xlabel('Arquitetura da Rede Neural')\n",
    "# plt.ylabel('Acurácia')\n",
    "# plt.ylim(0, 100) \n",
    "# plt.xticks(rotation=45)\n",
    "\n",
    "# # Adicionar os valores das barras\n",
    "# for i, v in enumerate(test_accuracies):\n",
    "#     plt.text(i, v, f'{v:.2f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Tabela comparativa para todas combinações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════════╤══════════════════════════╤══════════════════════╤══════════════╤═══════════════════╤═══════════════╤═════════════════════╤══════════════╕\n",
      "│ Combinação   │ Arquitetura              │ Função de Ativação   │ Otimizador   │ Tamanho do Lote   │ Train Score   │  Validation Score   │ Final Loss   │\n",
      "╞══════════════╪══════════════════════════╪══════════════════════╪══════════════╪═══════════════════╪═══════════════╪═════════════════════╪══════════════╡\n",
      "│ 1            │ Arquitetura (32, 32)     │ relu                 │ adam         │ 32                │ 94.5714       │ 91.3333             │ 17.9234      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 2            │ Arquitetura (32, 32)     │ relu                 │ adam         │ 64                │ 91.7143       │ 92.6667             │ 23.5033      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 3            │ Arquitetura (32, 32)     │ relu                 │ adam         │ 128               │ 89.5714       │ 90.6667             │ 27.6143      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 4            │ Arquitetura (32, 32)     │ relu                 │ sgd          │ 32                │ 81.2857       │ 85.3333             │ 46.4838      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 5            │ Arquitetura (32, 32)     │ relu                 │ sgd          │ 64                │ 73.1429       │ 80.6667             │ 55.605       │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 6            │ Arquitetura (32, 32)     │ relu                 │ sgd          │ 128               │ 70.7143       │ 76.6667             │ 63.8779      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 7            │ Arquitetura (32, 32)     │ relu                 │ rmsprop      │ 32                │ 93.2857       │ 94.6667             │ 17.2456      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 8            │ Arquitetura (32, 32)     │ relu                 │ rmsprop      │ 64                │ 90.4286       │ 91.3333             │ 22.4487      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 9            │ Arquitetura (32, 32)     │ relu                 │ rmsprop      │ 128               │ 88.7143       │ 88                  │ 32.2217      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 10           │ Arquitetura (32, 32)     │ tanh                 │ adam         │ 32                │ 89            │ 92                  │ 25.1247      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 11           │ Arquitetura (32, 32)     │ tanh                 │ adam         │ 64                │ 85.7143       │ 86                  │ 35.3843      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 12           │ Arquitetura (32, 32)     │ tanh                 │ adam         │ 128               │ 82.5714       │ 83.3333             │ 44.6376      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 13           │ Arquitetura (32, 32)     │ tanh                 │ sgd          │ 32                │ 79.7143       │ 83.3333             │ 49.0935      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 14           │ Arquitetura (32, 32)     │ tanh                 │ sgd          │ 64                │ 76.2857       │ 82                  │ 55.275       │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 15           │ Arquitetura (32, 32)     │ tanh                 │ sgd          │ 128               │ 75.1429       │ 83.3333             │ 57.1586      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 16           │ Arquitetura (32, 32)     │ tanh                 │ rmsprop      │ 32                │ 88.5714       │ 90                  │ 25.8779      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 17           │ Arquitetura (32, 32)     │ tanh                 │ rmsprop      │ 64                │ 88.2857       │ 89.3333             │ 28.4575      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 18           │ Arquitetura (32, 32)     │ tanh                 │ rmsprop      │ 128               │ 85.1429       │ 87.3333             │ 36.7593      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 19           │ Arquitetura (32, 32)     │ sigmoid              │ adam         │ 32                │ 79.8571       │ 80.6667             │ 53.475       │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 20           │ Arquitetura (32, 32)     │ sigmoid              │ adam         │ 64                │ 76.7143       │ 81.3333             │ 57.6022      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 21           │ Arquitetura (32, 32)     │ sigmoid              │ adam         │ 128               │ 73.1429       │ 80.6667             │ 61.4548      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 22           │ Arquitetura (32, 32)     │ sigmoid              │ sgd          │ 32                │ 46.5714       │ 54.6667             │ 96.0045      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 23           │ Arquitetura (32, 32)     │ sigmoid              │ sgd          │ 64                │ 46.5714       │ 54.6667             │ 96.4965      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 24           │ Arquitetura (32, 32)     │ sigmoid              │ sgd          │ 128               │ 46.5714       │ 54.6667             │ 100.928      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 25           │ Arquitetura (32, 32)     │ sigmoid              │ rmsprop      │ 32                │ 82.7143       │ 84.6667             │ 49.9113      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 26           │ Arquitetura (32, 32)     │ sigmoid              │ rmsprop      │ 64                │ 79.4286       │ 84                  │ 55.402       │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 27           │ Arquitetura (32, 32)     │ sigmoid              │ rmsprop      │ 128               │ 72            │ 83.3333             │ 62.2706      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 28           │ Arquitetura (64, 32, 16) │ relu                 │ adam         │ 32                │ 96.2857       │ 95.3333             │ 12.1717      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 29           │ Arquitetura (64, 32, 16) │ relu                 │ adam         │ 64                │ 94.8571       │ 98                  │ 13.5028      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 30           │ Arquitetura (64, 32, 16) │ relu                 │ adam         │ 128               │ 91.7143       │ 92                  │ 19.7867      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 31           │ Arquitetura (64, 32, 16) │ relu                 │ sgd          │ 32                │ 84.5714       │ 86                  │ 38.1151      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 32           │ Arquitetura (64, 32, 16) │ relu                 │ sgd          │ 64                │ 74.1429       │ 82                  │ 53.8725      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 33           │ Arquitetura (64, 32, 16) │ relu                 │ sgd          │ 128               │ 71.1429       │ 78.6667             │ 61.914       │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 34           │ Arquitetura (64, 32, 16) │ relu                 │ rmsprop      │ 32                │ 95.2857       │ 94.6667             │ 11.794       │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 35           │ Arquitetura (64, 32, 16) │ relu                 │ rmsprop      │ 64                │ 93.7143       │ 94.6667             │ 16.5201      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 36           │ Arquitetura (64, 32, 16) │ relu                 │ rmsprop      │ 128               │ 91.8571       │ 90.6667             │ 23.2635      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 37           │ Arquitetura (64, 32, 16) │ tanh                 │ adam         │ 32                │ 90            │ 94                  │ 16.7063      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 38           │ Arquitetura (64, 32, 16) │ tanh                 │ adam         │ 64                │ 89.8571       │ 92.6667             │ 20.2266      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 39           │ Arquitetura (64, 32, 16) │ tanh                 │ adam         │ 128               │ 87.8571       │ 90.6667             │ 28.1994      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 40           │ Arquitetura (64, 32, 16) │ tanh                 │ sgd          │ 32                │ 81.1429       │ 84.6667             │ 46.1801      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 41           │ Arquitetura (64, 32, 16) │ tanh                 │ sgd          │ 64                │ 82.7143       │ 84                  │ 47.7204      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 42           │ Arquitetura (64, 32, 16) │ tanh                 │ sgd          │ 128               │ 75.1429       │ 80.6667             │ 55.8973      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 43           │ Arquitetura (64, 32, 16) │ tanh                 │ rmsprop      │ 32                │ 90.1429       │ 92                  │ 18.7298      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 44           │ Arquitetura (64, 32, 16) │ tanh                 │ rmsprop      │ 64                │ 88.8571       │ 94                  │ 19.4616      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 45           │ Arquitetura (64, 32, 16) │ tanh                 │ rmsprop      │ 128               │ 87.7143       │ 90                  │ 24.2241      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 46           │ Arquitetura (64, 32, 16) │ sigmoid              │ adam         │ 32                │ 86.2857       │ 86.6667             │ 42.0308      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 47           │ Arquitetura (64, 32, 16) │ sigmoid              │ adam         │ 64                │ 82            │ 84                  │ 49.6746      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 48           │ Arquitetura (64, 32, 16) │ sigmoid              │ adam         │ 128               │ 77.4286       │ 82.6667             │ 57.1715      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 49           │ Arquitetura (64, 32, 16) │ sigmoid              │ sgd          │ 32                │ 46.5714       │ 54.6667             │ 99.8019      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 50           │ Arquitetura (64, 32, 16) │ sigmoid              │ sgd          │ 64                │ 46.5714       │ 54.6667             │ 100.615      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 51           │ Arquitetura (64, 32, 16) │ sigmoid              │ sgd          │ 128               │ 46.5714       │ 54.6667             │ 100.874      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 52           │ Arquitetura (64, 32, 16) │ sigmoid              │ rmsprop      │ 32                │ 86.4286       │ 88                  │ 41.5967      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 53           │ Arquitetura (64, 32, 16) │ sigmoid              │ rmsprop      │ 64                │ 78.7143       │ 84                  │ 55.1186      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 54           │ Arquitetura (64, 32, 16) │ sigmoid              │ rmsprop      │ 128               │ 77.4286       │ 83.3333             │ 58.6234      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 55           │ Arquitetura (128, 64)    │ relu                 │ adam         │ 32                │ 97.8571       │ 98                  │ 10.0167      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 56           │ Arquitetura (128, 64)    │ relu                 │ adam         │ 64                │ 96.2857       │ 96.6667             │ 12.2983      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 57           │ Arquitetura (128, 64)    │ relu                 │ adam         │ 128               │ 94.5714       │ 93.3333             │ 17.7367      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 58           │ Arquitetura (128, 64)    │ relu                 │ sgd          │ 32                │ 84            │ 83.3333             │ 42.5011      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 59           │ Arquitetura (128, 64)    │ relu                 │ sgd          │ 64                │ 75.4286       │ 80.6667             │ 53.323       │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 60           │ Arquitetura (128, 64)    │ relu                 │ sgd          │ 128               │ 71.5714       │ 82                  │ 61.1862      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 61           │ Arquitetura (128, 64)    │ relu                 │ rmsprop      │ 32                │ 96.1429       │ 95.3333             │ 12.9566      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 62           │ Arquitetura (128, 64)    │ relu                 │ rmsprop      │ 64                │ 95            │ 94.6667             │ 14.5757      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 63           │ Arquitetura (128, 64)    │ relu                 │ rmsprop      │ 128               │ 93.4286       │ 93.3333             │ 18.4873      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 64           │ Arquitetura (128, 64)    │ tanh                 │ adam         │ 32                │ 92.2857       │ 95.3333             │ 17.3307      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 65           │ Arquitetura (128, 64)    │ tanh                 │ adam         │ 64                │ 89.1429       │ 93.3333             │ 21.5521      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 66           │ Arquitetura (128, 64)    │ tanh                 │ adam         │ 128               │ 86.5714       │ 86.6667             │ 35.6478      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 67           │ Arquitetura (128, 64)    │ tanh                 │ sgd          │ 32                │ 80            │ 81.3333             │ 50.5597      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 68           │ Arquitetura (128, 64)    │ tanh                 │ sgd          │ 64                │ 76.5714       │ 82                  │ 54.2217      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 69           │ Arquitetura (128, 64)    │ tanh                 │ sgd          │ 128               │ 75.5714       │ 81.3333             │ 55.0067      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 70           │ Arquitetura (128, 64)    │ tanh                 │ rmsprop      │ 32                │ 90.7143       │ 92.6667             │ 19.303       │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 71           │ Arquitetura (128, 64)    │ tanh                 │ rmsprop      │ 64                │ 88.2857       │ 94.6667             │ 22.2882      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 72           │ Arquitetura (128, 64)    │ tanh                 │ rmsprop      │ 128               │ 88.4286       │ 90                  │ 25.9967      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 73           │ Arquitetura (128, 64)    │ sigmoid              │ adam         │ 32                │ 82.7143       │ 84.6667             │ 42.6029      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 74           │ Arquitetura (128, 64)    │ sigmoid              │ adam         │ 64                │ 80.4286       │ 84.6667             │ 52.1224      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 75           │ Arquitetura (128, 64)    │ sigmoid              │ adam         │ 128               │ 77.5714       │ 84                  │ 56.2238      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 76           │ Arquitetura (128, 64)    │ sigmoid              │ sgd          │ 32                │ 50.5714       │ 59.3333             │ 89.5272      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 77           │ Arquitetura (128, 64)    │ sigmoid              │ sgd          │ 64                │ 46.5714       │ 54.6667             │ 97.3877      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 78           │ Arquitetura (128, 64)    │ sigmoid              │ sgd          │ 128               │ 46.5714       │ 54.6667             │ 98.4208      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 79           │ Arquitetura (128, 64)    │ sigmoid              │ rmsprop      │ 32                │ 84.2857       │ 86                  │ 36.9583      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 80           │ Arquitetura (128, 64)    │ sigmoid              │ rmsprop      │ 64                │ 81.8571       │ 82.6667             │ 51.616       │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 81           │ Arquitetura (128, 64)    │ sigmoid              │ rmsprop      │ 128               │ 77.8571       │ 82.6667             │ 56.1573      │\n",
      "╘══════════════╧══════════════════════════╧══════════════════════╧══════════════╧═══════════════════╧═══════════════╧═════════════════════╧══════════════╛\n"
     ]
    }
   ],
   "source": [
    "headers = ['Combinação', 'Arquitetura', 'Função de Ativação', 'Otimizador', 'Tamanho do Lote', 'Train Score', ' Validation Score', 'Final Loss']\n",
    "table = tabulate(table_data, headers, tablefmt='fancy_grid', numalign='left')\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Avaliando melhor rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1722 - accuracy: 0.9467\n",
      "Melhor modelo - Acurácia no conjunto de teste: 94.67%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f'Melhor modelo - Acurácia no conjunto de teste: {test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) Predição do melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) Matriz Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transformar as previsões de volta para as classes originais\n",
    "y_pred_classes = label_encoder.inverse_transform(np.argmax(y_pred, axis=1))\n",
    "y_test_classes = label_encoder.inverse_transform(np.argmax(y_test, axis=1))\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test_classes, y_pred_classes)  \n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Bem', 'Médio', 'Mal'], yticklabels=['Bem', 'Médio', 'Mal'])\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3) Métricas de eficácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "Acurácia no conjunto de teste: 94.67%\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        62\n",
      "           1       0.91      0.93      0.92        46\n",
      "           2       0.93      0.90      0.92        42\n",
      "\n",
      "    accuracy                           0.95       150\n",
      "   macro avg       0.94      0.94      0.94       150\n",
      "weighted avg       0.95      0.95      0.95       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------------------------------------\")\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)  \n",
    "print(f'Acurácia no conjunto de teste: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "print(\"----------------------------------------------------------------\\n\")\n",
    "classification_rep = classification_report(y_test_classes, y_pred_classes)\n",
    "print(f'Relatório de Classificação:\\n{classification_rep}')\n",
    "\n",
    "\n",
    "# precision = precision_score(y_test, y_pred)  # Substitua y_test e y_pred pelos seus dados reais e previstos\n",
    "# print(f'Precisão: {precision}')\n",
    "\n",
    "# recall = recall_score(y_test, y_pred)  # Substitua y_test e y_pred pelos seus dados reais e previstos\n",
    "# print(f'Recall: {recall}')\n",
    "\n",
    "# f1 = f1_score(y_test, y_pred)  # Substitua y_test e y_pred pelos seus dados reais e previstos\n",
    "# print(f'Medida F: {f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
