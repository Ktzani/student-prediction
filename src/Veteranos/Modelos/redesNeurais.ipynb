{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tabulate import tabulate\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Carregar os dados de treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../Dados/RedesNeurais/X_train.csv')\n",
    "y_train = pd.read_csv('../Dados/RedesNeurais/y_train.csv')\n",
    "X_test = pd.read_csv('../Dados/RedesNeurais/X_test.csv')\n",
    "y_test = pd.read_csv('../Dados/RedesNeurais/y_test.csv')\n",
    "\n",
    "\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Configurando LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Pré-processando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_train_encoded))\n",
    "\n",
    "# Converta as classes em vetores one-hot (para a camada de saída)\n",
    "y_train_onehot = to_categorical(y_train_encoded, num_classes=num_classes)\n",
    "y_test_onehot = to_categorical(y_test_encoded, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) A) Testando Conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 64)                320       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 2499 (9.76 KB)\n",
      "Trainable params: 2499 (9.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "neuralNetwork = Sequential()\n",
    "neuralNetwork.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "neuralNetwork.add(Dense(32, activation='relu'))\n",
    "neuralNetwork.add(Dense(num_classes, activation='softmax'))  \n",
    "\n",
    "neuralNetwork.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) A.1) Treinando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 1.1219 - accuracy: 0.4054\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.9557 - accuracy: 0.5125\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9388 - accuracy: 0.5125\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.9296 - accuracy: 0.5125\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.9208 - accuracy: 0.5125\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.9110 - accuracy: 0.5125\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.9019 - accuracy: 0.5125\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8960 - accuracy: 0.5125\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.8890 - accuracy: 0.5143\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.8766 - accuracy: 0.5125\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8638 - accuracy: 0.5125\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8559 - accuracy: 0.5339\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8538 - accuracy: 0.5339\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8373 - accuracy: 0.5696\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.8291 - accuracy: 0.5661\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8124 - accuracy: 0.5679\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.8005 - accuracy: 0.5768\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7912 - accuracy: 0.5768\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.7792 - accuracy: 0.6071\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7667 - accuracy: 0.6089\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.7576 - accuracy: 0.6000\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.7425 - accuracy: 0.6143\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7252 - accuracy: 0.6375\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.7207 - accuracy: 0.6357\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.7031 - accuracy: 0.6429\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.6895 - accuracy: 0.6571\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 764us/step - loss: 0.6698 - accuracy: 0.6679\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.6492 - accuracy: 0.7000\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.6347 - accuracy: 0.6982\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6162 - accuracy: 0.7179\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5950 - accuracy: 0.7286\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.5785 - accuracy: 0.7411\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5596 - accuracy: 0.7464\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5380 - accuracy: 0.7607\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5158 - accuracy: 0.7857\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.4937 - accuracy: 0.8143\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4711 - accuracy: 0.8268\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4614 - accuracy: 0.8321\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4355 - accuracy: 0.8357\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4292 - accuracy: 0.8732\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4116 - accuracy: 0.8714\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.3962 - accuracy: 0.8786\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3887 - accuracy: 0.8607\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.3774 - accuracy: 0.8964\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.3452 - accuracy: 0.9304\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3334 - accuracy: 0.9393\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3265 - accuracy: 0.9089\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3119 - accuracy: 0.9464\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.3038 - accuracy: 0.9339\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2904 - accuracy: 0.9482\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2831 - accuracy: 0.9500\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2808 - accuracy: 0.9446\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.2627 - accuracy: 0.9571\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2506 - accuracy: 0.9643\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.2479 - accuracy: 0.9571\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.2372 - accuracy: 0.9589\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.2340 - accuracy: 0.9625\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2243 - accuracy: 0.9786\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.2203 - accuracy: 0.9643\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2148 - accuracy: 0.9571\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2408 - accuracy: 0.9375\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.2031 - accuracy: 0.9679\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1998 - accuracy: 0.9714\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1924 - accuracy: 0.9696\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1889 - accuracy: 0.9804\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1835 - accuracy: 0.9750\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1768 - accuracy: 0.9768\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1757 - accuracy: 0.9768\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1902 - accuracy: 0.9625\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1697 - accuracy: 0.9679\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1700 - accuracy: 0.9679\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1633 - accuracy: 0.9768\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1587 - accuracy: 0.9786\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1564 - accuracy: 0.9750\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1552 - accuracy: 0.9804\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1503 - accuracy: 0.9786\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1454 - accuracy: 0.9786\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1473 - accuracy: 0.9732\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1394 - accuracy: 0.9821\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1398 - accuracy: 0.9857\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1394 - accuracy: 0.9732\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1347 - accuracy: 0.9804\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1308 - accuracy: 0.9732\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.1273 - accuracy: 0.9839\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1303 - accuracy: 0.9768\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1249 - accuracy: 0.9857\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.1290 - accuracy: 0.9750\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1269 - accuracy: 0.9714\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1314 - accuracy: 0.9607\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1195 - accuracy: 0.9821\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1216 - accuracy: 0.9750\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1163 - accuracy: 0.9839\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1130 - accuracy: 0.9839\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1197 - accuracy: 0.9786\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.1143 - accuracy: 0.9786\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1173 - accuracy: 0.9732\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.1153 - accuracy: 0.9768\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1073 - accuracy: 0.9857\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1074 - accuracy: 0.9750\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1067 - accuracy: 0.9893\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1241 - accuracy: 0.9696\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1096 - accuracy: 0.9786\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1041 - accuracy: 0.9893\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1057 - accuracy: 0.9857\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1059 - accuracy: 0.9786\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.1035 - accuracy: 0.9786\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1150 - accuracy: 0.9714\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.1101 - accuracy: 0.9732\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.1141 - accuracy: 0.9643\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.1036 - accuracy: 0.9804\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.0981 - accuracy: 0.9857\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0957 - accuracy: 0.9893\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0989 - accuracy: 0.9786\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.1001 - accuracy: 0.9786\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0987 - accuracy: 0.9732\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0909 - accuracy: 0.9893\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.0952 - accuracy: 0.9821\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0915 - accuracy: 0.9804\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0999 - accuracy: 0.9714\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0886 - accuracy: 0.9875\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0865 - accuracy: 0.9929\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0865 - accuracy: 0.9857\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0874 - accuracy: 0.9857\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0901 - accuracy: 0.9857\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.1060 - accuracy: 0.9625\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0905 - accuracy: 0.9732\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0826 - accuracy: 0.9857\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0833 - accuracy: 0.9893\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0843 - accuracy: 0.9804\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.0916 - accuracy: 0.9696\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0801 - accuracy: 0.9929\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 859us/step - loss: 0.0792 - accuracy: 0.9893\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0781 - accuracy: 0.9839\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0776 - accuracy: 0.9964\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0806 - accuracy: 0.9839\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0763 - accuracy: 0.9839\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 857us/step - loss: 0.0779 - accuracy: 0.9893\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0757 - accuracy: 0.9875\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0823 - accuracy: 0.9786\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0942 - accuracy: 0.9732\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0856 - accuracy: 0.9821\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0782 - accuracy: 0.9821\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.0916 - accuracy: 0.9607\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0752 - accuracy: 0.9839\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0785 - accuracy: 0.9804\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0776 - accuracy: 0.9786\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0772 - accuracy: 0.9857\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0718 - accuracy: 0.9821\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0773 - accuracy: 0.9875\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0764 - accuracy: 0.9786\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0861 - accuracy: 0.9714\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0714 - accuracy: 0.9929\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0703 - accuracy: 0.9857\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0672 - accuracy: 0.9857\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0683 - accuracy: 0.9875\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0677 - accuracy: 0.9839\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0741 - accuracy: 0.9857\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0754 - accuracy: 0.9839\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0706 - accuracy: 0.9839\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0702 - accuracy: 0.9821\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0697 - accuracy: 0.9875\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0801 - accuracy: 0.9768\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0699 - accuracy: 0.9750\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0661 - accuracy: 0.9893\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0661 - accuracy: 0.9857\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0645 - accuracy: 0.9875\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0700 - accuracy: 0.9839\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0660 - accuracy: 0.9804\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0634 - accuracy: 0.9893\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0626 - accuracy: 0.9929\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0620 - accuracy: 0.9875\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0617 - accuracy: 0.9911\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0648 - accuracy: 0.9875\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0600 - accuracy: 0.9857\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0659 - accuracy: 0.9857\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0665 - accuracy: 0.9857\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0666 - accuracy: 0.9804\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0604 - accuracy: 0.9875\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0677 - accuracy: 0.9839\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0773 - accuracy: 0.9696\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0638 - accuracy: 0.9804\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0626 - accuracy: 0.9821\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0584 - accuracy: 0.9929\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0572 - accuracy: 0.9893\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0602 - accuracy: 0.9875\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0591 - accuracy: 0.9839\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0609 - accuracy: 0.9911\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0612 - accuracy: 0.9857\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0573 - accuracy: 0.9875\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.0598 - accuracy: 0.9929\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0636 - accuracy: 0.9839\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0596 - accuracy: 0.9857\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 821us/step - loss: 0.0551 - accuracy: 0.9857\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0546 - accuracy: 0.9929\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0560 - accuracy: 0.9857\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0690 - accuracy: 0.9732\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0680 - accuracy: 0.9679\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0784 - accuracy: 0.9679\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0632 - accuracy: 0.9786\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0689 - accuracy: 0.9768\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0692 - accuracy: 0.9750\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0622 - accuracy: 0.9821\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0610 - accuracy: 0.9821\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0590 - accuracy: 0.9929\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0573 - accuracy: 0.9911\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0567 - accuracy: 0.9929\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0588 - accuracy: 0.9893\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0561 - accuracy: 0.9875\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0561 - accuracy: 0.9857\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0603 - accuracy: 0.9821\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0629 - accuracy: 0.9821\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0570 - accuracy: 0.9893\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0614 - accuracy: 0.9750\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0620 - accuracy: 0.9804\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0520 - accuracy: 0.9911\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0528 - accuracy: 0.9929\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0550 - accuracy: 0.9804\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0677 - accuracy: 0.9750\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0636 - accuracy: 0.9750\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0775 - accuracy: 0.9661\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0623 - accuracy: 0.9768\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0508 - accuracy: 0.9929\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0512 - accuracy: 0.9857\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.0609 - accuracy: 0.9821\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0553 - accuracy: 0.9839\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0555 - accuracy: 0.9893\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 857us/step - loss: 0.0526 - accuracy: 0.9893\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0578 - accuracy: 0.9839\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0768 - accuracy: 0.9643\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0624 - accuracy: 0.9821\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0478 - accuracy: 0.9929\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0491 - accuracy: 0.9893\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0495 - accuracy: 0.9893\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0597 - accuracy: 0.9804\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0510 - accuracy: 0.9821\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0584 - accuracy: 0.9786\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0499 - accuracy: 0.9911\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0507 - accuracy: 0.9839\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0580 - accuracy: 0.9804\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0480 - accuracy: 0.9929\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0491 - accuracy: 0.9893\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0473 - accuracy: 0.9929\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0478 - accuracy: 0.9946\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0493 - accuracy: 0.9875\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0516 - accuracy: 0.9875\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0579 - accuracy: 0.9821\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0509 - accuracy: 0.9839\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0571 - accuracy: 0.9821\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0501 - accuracy: 0.9839\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0453 - accuracy: 0.9946\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0434 - accuracy: 0.9911\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0498 - accuracy: 0.9857\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0483 - accuracy: 0.9893\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0505 - accuracy: 0.9875\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0501 - accuracy: 0.9929\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0561 - accuracy: 0.9821\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0441 - accuracy: 0.9946\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0562 - accuracy: 0.9821\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0506 - accuracy: 0.9857\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0562 - accuracy: 0.9804\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0771 - accuracy: 0.9625\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0708 - accuracy: 0.9732\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0868 - accuracy: 0.9589\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.0619 - accuracy: 0.9732\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0470 - accuracy: 0.9946\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0435 - accuracy: 0.9893\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0673 - accuracy: 0.9696\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0450 - accuracy: 0.9875\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0412 - accuracy: 0.9946\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0423 - accuracy: 0.9929\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0567 - accuracy: 0.9839\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0501 - accuracy: 0.9857\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0465 - accuracy: 0.9893\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0798 - accuracy: 0.9732\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0944 - accuracy: 0.9536\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0590 - accuracy: 0.9768\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0509 - accuracy: 0.9821\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0408 - accuracy: 0.9929\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0405 - accuracy: 0.9946\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0429 - accuracy: 0.9893\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0415 - accuracy: 0.9893\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0419 - accuracy: 0.9946\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0434 - accuracy: 0.9893\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0516 - accuracy: 0.9821\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0485 - accuracy: 0.9911\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0482 - accuracy: 0.9875\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0413 - accuracy: 0.9929\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 826us/step - loss: 0.0540 - accuracy: 0.9821\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0433 - accuracy: 0.9893\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0586 - accuracy: 0.9750\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0502 - accuracy: 0.9839\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0399 - accuracy: 0.9929\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0458 - accuracy: 0.9839\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0409 - accuracy: 0.9964\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0420 - accuracy: 0.9929\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0413 - accuracy: 0.9929\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0422 - accuracy: 0.9929\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0412 - accuracy: 0.9893\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0429 - accuracy: 0.9857\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.0455 - accuracy: 0.9821\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0395 - accuracy: 0.9875\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0464 - accuracy: 0.9839\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0427 - accuracy: 0.9893\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0428 - accuracy: 0.9839\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0425 - accuracy: 0.9893\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0343 - accuracy: 0.9929\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0412 - accuracy: 0.9893\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0384 - accuracy: 0.9911\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0376 - accuracy: 0.9929\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0351 - accuracy: 0.9929\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0366 - accuracy: 0.9911\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0412 - accuracy: 0.9893\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0338 - accuracy: 0.9929\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0343 - accuracy: 0.9946\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0486 - accuracy: 0.9804\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0661 - accuracy: 0.9714\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0538 - accuracy: 0.9804\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0533 - accuracy: 0.9821\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0313 - accuracy: 0.9946\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 859us/step - loss: 0.0415 - accuracy: 0.9875\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0527 - accuracy: 0.9768\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 800us/step - loss: 0.0538 - accuracy: 0.9768\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0563 - accuracy: 0.9661\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0534 - accuracy: 0.9732\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0326 - accuracy: 0.9911\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0354 - accuracy: 0.9893\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0331 - accuracy: 0.9946\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0326 - accuracy: 0.9946\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0333 - accuracy: 0.9929\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0328 - accuracy: 0.9911\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0389 - accuracy: 0.9929\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0397 - accuracy: 0.9857\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0379 - accuracy: 0.9875\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0400 - accuracy: 0.9929\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0352 - accuracy: 0.9946\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0375 - accuracy: 0.9911\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0329 - accuracy: 0.9946\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0289 - accuracy: 0.9982\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0339 - accuracy: 0.9929\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0340 - accuracy: 0.9911\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0301 - accuracy: 0.9964\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0309 - accuracy: 0.9929\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0362 - accuracy: 0.9911\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0364 - accuracy: 0.9893\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0383 - accuracy: 0.9893\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0505 - accuracy: 0.9768\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0818 - accuracy: 0.9661\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0720 - accuracy: 0.9696\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0285 - accuracy: 0.9964\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0317 - accuracy: 0.9929\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0304 - accuracy: 0.9982\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0501 - accuracy: 0.9732\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0373 - accuracy: 0.9857\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0387 - accuracy: 0.9875\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0319 - accuracy: 0.9893\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0325 - accuracy: 0.9911\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0328 - accuracy: 0.9929\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0352 - accuracy: 0.9893\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0296 - accuracy: 0.9946\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0277 - accuracy: 0.9964\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0321 - accuracy: 0.9893\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0304 - accuracy: 0.9946\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0276 - accuracy: 0.9964\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0280 - accuracy: 0.9964\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0275 - accuracy: 0.9929\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0312 - accuracy: 0.9946\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0316 - accuracy: 0.9929\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0273 - accuracy: 0.9946\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0284 - accuracy: 0.9911\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0270 - accuracy: 0.9946\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0316 - accuracy: 0.9893\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0310 - accuracy: 0.9964\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0336 - accuracy: 0.9875\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0319 - accuracy: 0.9911\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0291 - accuracy: 0.9982\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0331 - accuracy: 0.9893\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0279 - accuracy: 0.9946\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0295 - accuracy: 0.9929\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0321 - accuracy: 0.9893\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0288 - accuracy: 0.9929\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0262 - accuracy: 0.9946\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0282 - accuracy: 0.9964\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 851us/step - loss: 0.0348 - accuracy: 0.9893\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0286 - accuracy: 0.9946\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0328 - accuracy: 0.9893\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0449 - accuracy: 0.9821\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 857us/step - loss: 0.0341 - accuracy: 0.9857\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0344 - accuracy: 0.9893\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0441 - accuracy: 0.9839\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0614 - accuracy: 0.9714\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0342 - accuracy: 0.9893\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0273 - accuracy: 0.9946\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0301 - accuracy: 0.9911\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0383 - accuracy: 0.9839\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0308 - accuracy: 0.9946\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0418 - accuracy: 0.9857\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0262 - accuracy: 0.9964\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0354 - accuracy: 0.9839\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0330 - accuracy: 0.9875\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0332 - accuracy: 0.9911\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0714 - accuracy: 0.9643\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0491 - accuracy: 0.9786\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0451 - accuracy: 0.9857\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0369 - accuracy: 0.9875\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0448 - accuracy: 0.9875\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0374 - accuracy: 0.9857\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0338 - accuracy: 0.9946\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0430 - accuracy: 0.9857\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0411 - accuracy: 0.9839\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.0708 - accuracy: 0.9714\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0366 - accuracy: 0.9893\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0333 - accuracy: 0.9911\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0361 - accuracy: 0.9911\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0351 - accuracy: 0.9893\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0384 - accuracy: 0.9911\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0459 - accuracy: 0.9821\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0429 - accuracy: 0.9804\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 984us/step - loss: 0.0348 - accuracy: 0.9911\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0384 - accuracy: 0.9875\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0466 - accuracy: 0.9786\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0359 - accuracy: 0.9911\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0386 - accuracy: 0.9875\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0451 - accuracy: 0.9839\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0500 - accuracy: 0.9821\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0486 - accuracy: 0.9768\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0436 - accuracy: 0.9821\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0555 - accuracy: 0.9786\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0353 - accuracy: 0.9911\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0450 - accuracy: 0.9804\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0339 - accuracy: 0.9946\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0364 - accuracy: 0.9893\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0331 - accuracy: 0.9911\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0343 - accuracy: 0.9893\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0426 - accuracy: 0.9857\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0477 - accuracy: 0.9804\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0426 - accuracy: 0.9857\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 0.9839\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9893\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0368 - accuracy: 0.9857\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.0372 - accuracy: 0.9911\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0406 - accuracy: 0.9875\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0649 - accuracy: 0.9732\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0331 - accuracy: 0.9875\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0359 - accuracy: 0.9893\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0322 - accuracy: 0.9964\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0356 - accuracy: 0.9875\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0661 - accuracy: 0.9696\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0389 - accuracy: 0.9875\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0365 - accuracy: 0.9893\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0488 - accuracy: 0.9804\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0383 - accuracy: 0.9875\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0451 - accuracy: 0.9875\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0396 - accuracy: 0.9839\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0304 - accuracy: 0.9911\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0407 - accuracy: 0.9893\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0616 - accuracy: 0.9714\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0363 - accuracy: 0.9893\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0334 - accuracy: 0.9929\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0331 - accuracy: 0.9893\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0306 - accuracy: 0.9893\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0312 - accuracy: 0.9929\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0326 - accuracy: 0.9911\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0328 - accuracy: 0.9893\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0347 - accuracy: 0.9929\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0440 - accuracy: 0.9857\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0300 - accuracy: 0.9946\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0328 - accuracy: 0.9893\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0363 - accuracy: 0.9857\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0333 - accuracy: 0.9911\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0382 - accuracy: 0.9857\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0436 - accuracy: 0.9857\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0400 - accuracy: 0.9839\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0388 - accuracy: 0.9857\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0382 - accuracy: 0.9875\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0411 - accuracy: 0.9857\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0560 - accuracy: 0.9750\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0385 - accuracy: 0.9821\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.0416 - accuracy: 0.9804\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0331 - accuracy: 0.9946\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0316 - accuracy: 0.9875\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0292 - accuracy: 0.9929\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0366 - accuracy: 0.9875\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0345 - accuracy: 0.9893\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0310 - accuracy: 0.9929\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0404 - accuracy: 0.9875\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0636 - accuracy: 0.9661\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.0671 - accuracy: 0.9661\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0345 - accuracy: 0.9911\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0402 - accuracy: 0.9857\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0334 - accuracy: 0.9946\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0311 - accuracy: 0.9946\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0371 - accuracy: 0.9875\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0291 - accuracy: 0.9929\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0295 - accuracy: 0.9929\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0308 - accuracy: 0.9911\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0300 - accuracy: 0.9911\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.0356 - accuracy: 0.9839\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0496 - accuracy: 0.9821\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.0376 - accuracy: 0.9911\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.0324 - accuracy: 0.9929\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "\n",
      "---\n",
      "Fold 1:\n",
      "Acurácia: 0.9714285714285714\n",
      "Precisão: 0.9716592899519729\n",
      "Revocação: 0.9714285714285714\n",
      "F1-Score: 0.9712841300903924\n",
      "---\n",
      "Fold 2:\n",
      "Acurácia: 0.9714285714285714\n",
      "Precisão: 0.9719372822299651\n",
      "Revocação: 0.9714285714285714\n",
      "F1-Score: 0.9712342079689019\n",
      "---\n",
      "Fold 3:\n",
      "Acurácia: 0.9928571428571429\n",
      "Precisão: 0.9930194805194805\n",
      "Revocação: 0.9928571428571429\n",
      "F1-Score: 0.9928253074628866\n",
      "---\n",
      "Fold 4:\n",
      "Acurácia: 0.9785714285714285\n",
      "Precisão: 0.9794595616024188\n",
      "Revocação: 0.9785714285714285\n",
      "F1-Score: 0.9786951284010107\n",
      "---\n",
      "Fold 5:\n",
      "Acurácia: 0.9928571428571429\n",
      "Precisão: 0.9930158730158729\n",
      "Revocação: 0.9928571428571429\n",
      "F1-Score: 0.9928719419874094\n",
      "---\n",
      "\n",
      "Médias e Desvios Padrão Gerais:\n",
      "----------------------------------------------------------------\n",
      "Média Acurácias: 0.9814285714285715\n",
      "Desvio Padrão Acurácias: 0.021665358411575898\n",
      "\n",
      "Média Precisões: 0.981818297463942\n",
      "Desvio Padrão Precisões: 0.021383538777097845\n",
      "\n",
      "Média Revocações: 0.9814285714285715\n",
      "Desvio Padrão Revocações: 0.021665358411575898\n",
      "\n",
      "Média F1-Scores: 0.9813821431821201\n",
      "Desvio Padrão F1-Scores: 0.02179752259475636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "acuracias = []\n",
    "precisoes = []\n",
    "revocacoes = []\n",
    "f1_scores = []\n",
    "\n",
    "# Setando a seed\n",
    "np.random.seed(10)\n",
    "\n",
    "i = 1\n",
    "\n",
    "for train_index, test_index in kfold.split(X_train, y_train):\n",
    "    print(f'\\nFold {i}')\n",
    "\n",
    "\n",
    "    X_treino_fold, X_teste_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_treino_fold, y_teste_fold = y_train_onehot[train_index], y_train_onehot[test_index]\n",
    "\n",
    "    X_treino_fold = X_treino_fold.astype('float32')\n",
    "    y_treino_fold = y_treino_fold.astype('float32')\n",
    "    X_teste_fold = X_teste_fold.astype('float32')\n",
    "\n",
    "    # Compilando o modelo\n",
    "    neuralNetwork.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    neuralNetwork.fit(X_treino_fold, y_treino_fold, epochs=100, batch_size=32)\n",
    "\n",
    "    y_pred = neuralNetwork.predict(X_teste_fold)\n",
    "\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "    y_teste_labels = np.argmax(y_teste_fold, axis=1)\n",
    "\n",
    "    acuracia = accuracy_score(y_teste_labels, y_pred_labels)\n",
    "    precisao = precision_score(y_teste_labels, y_pred_labels, average='weighted')\n",
    "    revocacao = recall_score(y_teste_labels, y_pred_labels, average='weighted')\n",
    "    f1 = f1_score(y_teste_labels, y_pred_labels, average='weighted')\n",
    "\n",
    "\n",
    "    acuracias.append(acuracia)\n",
    "    precisoes.append(precisao)\n",
    "    revocacoes.append(revocacao)\n",
    "    f1_scores.append(f1)\n",
    "    i = i + 1\n",
    "\n",
    "media_acuracias = np.mean(acuracias)\n",
    "media_precisoes = np.mean(precisoes)\n",
    "media_revocacoes = np.mean(revocacoes)\n",
    "media_f1_scores = np.mean(f1_scores)\n",
    "\n",
    "desvio_padrao_acuracias = np.sqrt(np.mean(sum((x - media_acuracias) ** 2 for x in acuracias)))\n",
    "desvio_padrao_precisoes = np.sqrt(np.mean(sum((x - media_precisoes) ** 2 for x in precisoes)))\n",
    "desvio_padrao_revocacoes = np.sqrt(np.mean(sum((x - media_revocacoes) ** 2 for x in revocacoes)))\n",
    "desvio_padrao_f1_scores = np.sqrt(np.mean(sum((x - media_f1_scores) ** 2 for x in f1_scores)))\n",
    "\n",
    "# Exibir resultados\n",
    "print('\\n---')\n",
    "for i in range(len(acuracias)):\n",
    "    print(f'Fold {i + 1}:')\n",
    "    print(f'Acurácia: {acuracias[i]}')\n",
    "    print(f'Precisão: {precisoes[i]}')\n",
    "    print(f'Revocação: {revocacoes[i]}')\n",
    "    print(f'F1-Score: {f1_scores[i]}')\n",
    "    print('---')\n",
    "\n",
    "print('\\nMédias e Desvios Padrão Gerais:')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(f'Média Acurácias: {media_acuracias}')\n",
    "print(f'Desvio Padrão Acurácias: {desvio_padrao_acuracias}\\n')\n",
    "print(f'Média Precisões: {media_precisoes}')\n",
    "print(f'Desvio Padrão Precisões: {desvio_padrao_precisoes}\\n')\n",
    "print(f'Média Revocações: {media_revocacoes}')\n",
    "print(f'Desvio Padrão Revocações: {desvio_padrao_revocacoes}\\n')\n",
    "print(f'Média F1-Scores: {media_f1_scores}')\n",
    "print(f'Desvio Padrão F1-Scores: {desvio_padrao_f1_scores}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) A.2) Predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 778us/step\n"
     ]
    }
   ],
   "source": [
    "X_test = X_test.astype('float32')\n",
    "y_pred = neuralNetwork.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.2) Matriz Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Documents\\GitHub\\student-prediction\\src\\Veteranos\\Modelos\\redesNeurais.ipynb Cell 15\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/student-prediction/src/Veteranos/Modelos/redesNeurais.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Obtendo as classes preditas diretamente dos rótulos codificados\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/student-prediction/src/Veteranos/Modelos/redesNeurais.ipynb#X63sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_pred_classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(y_pred, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/student-prediction/src/Veteranos/Modelos/redesNeurais.ipynb#X63sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y_test_classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49margmax(y_test, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/student-prediction/src/Veteranos/Modelos/redesNeurais.ipynb#X63sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Convertendo as classes numéricas de volta para as classes originais usando label_encoder\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/student-prediction/src/Veteranos/Modelos/redesNeurais.ipynb#X63sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m y_pred_original \u001b[39m=\u001b[39m label_encoder\u001b[39m.\u001b[39minverse_transform(y_pred_classes\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\fromnumeric.py:1242\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[39mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1239\u001b[0m \u001b[39m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1240\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1241\u001b[0m kwds \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mkeepdims\u001b[39m\u001b[39m'\u001b[39m: keepdims} \u001b[39mif\u001b[39;00m keepdims \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m-> 1242\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39m\u001b[39margmax\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "# Obtendo as classes preditas diretamente dos rótulos codificados\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Convertendo as classes numéricas de volta para as classes originais usando label_encoder\n",
    "y_pred_original = label_encoder.inverse_transform(y_pred_classes.reshape(-1, 1))\n",
    "y_test_original = label_encoder.inverse_transform(y_test_classes.reshape(-1, 1))\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test_classes, y_pred_classes) \n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Bem', 'Médio', 'Mal'], yticklabels=['Bem', 'Médio', 'Mal'])\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.3) Métricas de eficácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "Acurácia no conjunto de teste: 96.00%\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        62\n",
      "           1       0.94      0.96      0.95        46\n",
      "           2       0.95      0.93      0.94        42\n",
      "\n",
      "    accuracy                           0.96       150\n",
      "   macro avg       0.96      0.96      0.96       150\n",
      "weighted avg       0.96      0.96      0.96       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------------------------------------\")\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)  \n",
    "print(f'Acurácia no conjunto de teste: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "print(\"----------------------------------------------------------------\\n\")\n",
    "classification_rep = classification_report(y_test_classes, y_pred_classes)\n",
    "print(f'Relatório de Classificação:\\n{classification_rep}')\n",
    "\n",
    "\n",
    "# precision = precision_score(y_test, y_pred)  # Substitua y_test e y_pred pelos seus dados reais e previstos\n",
    "# print(f'Precisão: {precision}')\n",
    "\n",
    "# recall = recall_score(y_test, y_pred)  # Substitua y_test e y_pred pelos seus dados reais e previstos\n",
    "# print(f'Recall: {recall}')\n",
    "\n",
    "# f1 = f1_score(y_test, y_pred)  # Substitua y_test e y_pred pelos seus dados reais e previstos\n",
    "# print(f'Medida F: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Carregar os dados de treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../Dados/RedesNeurais/X_train.csv')\n",
    "y_train = pd.read_csv('../Dados/RedesNeurais/y_train.csv')\n",
    "X_test = pd.read_csv('../Dados/RedesNeurais/X_test.csv')\n",
    "y_test = pd.read_csv('../Dados/RedesNeurais/y_test.csv')\n",
    "\n",
    "\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Configurando LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Pré-processando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Corrigindo dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padronizar as características (normalização)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Converter as classes em vetores one-hot (para a camada de saída)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Experimentando diferentes redes neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = [\n",
    "    (32, 32),        # Exemplo de arquitetura 1\n",
    "    (64, 32, 16),    # Exemplo de arquitetura 2\n",
    "    (128, 64),       # Exemplo de arquitetura 3\n",
    "]\n",
    "\n",
    "hyperparameters = {\n",
    "    'activation_function': ['relu', 'tanh', 'sigmoid'],\n",
    "    'optimizer': ['adam', 'sgd', 'rmsprop'],\n",
    "    'batch_size': [32, 64, 128]\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_accuracy = 0.0\n",
    "min_loss = 100\n",
    "\n",
    "accuracies_train = []  \n",
    "accuracies_test = [] \n",
    "\n",
    "table_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Treinando redes neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Documents\\GitHub\\student-prediction\\src\\Veteranos\\Modelos\\redesNeurais.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/student-prediction/src/Veteranos/Modelos/redesNeurais.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(X_train, y_train, epochs\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, batch_size\u001b[39m=\u001b[39mbatch_size, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/student-prediction/src/Veteranos/Modelos/redesNeurais.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m final_training_accuracy \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/student-prediction/src/Veteranos/Modelos/redesNeurais.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_val, y_val)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/student-prediction/src/Veteranos/Modelos/redesNeurais.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# _, test_accuracy = model.evaluate(X_test, y_test)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/student-prediction/src/Veteranos/Modelos/redesNeurais.ipynb#X14sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# accuracies_train.append(train_accuracy)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/student-prediction/src/Veteranos/Modelos/redesNeurais.ipynb#X14sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# accuracies_test.append(test_accuracy)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/student-prediction/src/Veteranos/Modelos/redesNeurais.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mArquitetura \u001b[39m\u001b[39m{\u001b[39;00marchitecture\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_val' is not defined"
     ]
    }
   ],
   "source": [
    "combination_number = 1\n",
    "\n",
    "for architecture in architectures:\n",
    "    for activation_function in hyperparameters['activation_function']:\n",
    "        for optimizer in hyperparameters['optimizer']:\n",
    "            for batch_size in hyperparameters['batch_size']:\n",
    "                    model = Sequential()\n",
    "                    for units in architecture:\n",
    "                        model.add(Dense(units, activation=activation_function, input_dim=X_train.shape[1]))\n",
    "                    model.add(Dense(3, activation='softmax'))\n",
    "                    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "                    \n",
    "                    history = model.fit(X_train, y_train, epochs=50, batch_size=batch_size, verbose=0)\n",
    "\n",
    "                    final_training_accuracy = history.history['accuracy'][-1]\n",
    "                        \n",
    "                    loss, accuracy = model.evaluate(X_val, y_val)\n",
    "\n",
    "                    # _, test_accuracy = model.evaluate(X_test, y_test)\n",
    "                    # accuracies_train.append(train_accuracy)\n",
    "                    # accuracies_test.append(test_accuracy)\n",
    "\n",
    "                    print(f'Arquitetura {architecture}:')\n",
    "                    print(f'Acurácia na validação: {accuracy * 100:.2f}%')\n",
    "                    print(f'Loss final: {loss * 100:.2f}%')\n",
    "                    print(\"Hiperparâmetros:\")\n",
    "                    print(f'- Função de Ativação: {activation_function}')\n",
    "                    print(f'- Otimizador: {optimizer}')\n",
    "                    print(f'- Tamanho do Lote: {batch_size}')\n",
    "                    print(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "                    # Coletar informações da iteração atual para tabela\n",
    "                    row = [combination_number, f'Arquitetura {architecture}', activation_function, optimizer, batch_size, final_training_accuracy * 100, accuracy * 100, loss * 100]\n",
    "                    table_data.append(row)\n",
    "\n",
    "                    combination_number += 1\n",
    "                    \n",
    "                    if accuracy > best_accuracy and loss < min_loss:\n",
    "                        best_accuracy = accuracy\n",
    "                        best_model = model\n",
    "                        best_hyperparameters = {\n",
    "                        'Arquitetura': architecture,\n",
    "                        'Função de Ativação': activation_function,\n",
    "                        'Otimizador': optimizer,\n",
    "                        'Tamanho do Lote': batch_size\n",
    "                    }\n",
    "\n",
    "        \n",
    "# Imprimir informações sobre o melhor modelo\n",
    "print(\"Melhor Modelo:\")\n",
    "print(f\"Acurácia na Validação: {best_accuracy * 100:.2f}%\")\n",
    "print(\"Melhores Hiperparâmetros:\")\n",
    "for key, value in best_hyperparameters.items():\n",
    "    print(f\"- {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3.1) Construindo redes neurais\n",
    "# for architecture in architectures:\n",
    "#     model = Sequential()\n",
    "#     for units in architecture:\n",
    "#         model.add(Dense(units, activation='relu', input_dim=X_train.shape[1]))\n",
    "#     model.add(Dense(3, activation='softmax'))  # 3 unidades na camada de saída para as três classes\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     history = model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "#     train_accuracy = [acc * 100 for acc in history.history['accuracy']]\n",
    "\n",
    "#     loss, accuracy = model.evaluate(X_val, y_val)\n",
    "\n",
    "#     _, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    \n",
    "#     accuracies_train.append(train_accuracy)\n",
    "#     accuracies_test.append(test_accuracy)\n",
    "\n",
    "#     print(f'Arquitetura {architecture}: Acurácia na validação: {accuracy * 100:.2f}%')\n",
    "#     print(f'Arquitetura {architecture}: Loss final: {loss * 100:.2f}%')\n",
    "#     print(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "#     if accuracy > best_accuracy and loss < min_loss:\n",
    "#         best_accuracy = accuracy\n",
    "#         best_model = model\n",
    "\n",
    "### 3.2) Plotando Diferenças\n",
    "# plt.figure(figsize=(12, 6))\n",
    "\n",
    "# for i, architecture in enumerate(architectures):\n",
    "#     plt.plot(accuracies_train[i], label=f'Treinamento - Arquitetura {architecture}')\n",
    "\n",
    "# plt.title('Acurácia de Treinamento')\n",
    "# plt.xlabel('Épocas')\n",
    "# plt.ylabel('Acurácia')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.ylim(0, 100)\n",
    "\n",
    "# test_accuracies = [accuracy * 100 for accuracy in accuracies_test]\n",
    "# architecture_labels = [f'Arquitetura {architecture}' for architecture in architectures]\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.bar(architecture_labels, test_accuracies, color='dodgerblue', alpha=0.7)\n",
    "# plt.title('Acurácia no Conjunto de Teste')\n",
    "# plt.xlabel('Arquitetura da Rede Neural')\n",
    "# plt.ylabel('Acurácia')\n",
    "# plt.ylim(0, 100) \n",
    "# plt.xticks(rotation=45)\n",
    "\n",
    "# # Adicionar os valores das barras\n",
    "# for i, v in enumerate(test_accuracies):\n",
    "#     plt.text(i, v, f'{v:.2f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Tabela comparativa para todas combinações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════════╤══════════════════════════╤══════════════════════╤══════════════╤═══════════════════╤═══════════════╤═════════════════════╤══════════════╕\n",
      "│ Combinação   │ Arquitetura              │ Função de Ativação   │ Otimizador   │ Tamanho do Lote   │ Train Score   │  Validation Score   │ Final Loss   │\n",
      "╞══════════════╪══════════════════════════╪══════════════════════╪══════════════╪═══════════════════╪═══════════════╪═════════════════════╪══════════════╡\n",
      "│ 1            │ Arquitetura (32, 32)     │ relu                 │ adam         │ 32                │ 94.5714       │ 91.3333             │ 17.9234      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 2            │ Arquitetura (32, 32)     │ relu                 │ adam         │ 64                │ 91.7143       │ 92.6667             │ 23.5033      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 3            │ Arquitetura (32, 32)     │ relu                 │ adam         │ 128               │ 89.5714       │ 90.6667             │ 27.6143      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 4            │ Arquitetura (32, 32)     │ relu                 │ sgd          │ 32                │ 81.2857       │ 85.3333             │ 46.4838      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 5            │ Arquitetura (32, 32)     │ relu                 │ sgd          │ 64                │ 73.1429       │ 80.6667             │ 55.605       │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 6            │ Arquitetura (32, 32)     │ relu                 │ sgd          │ 128               │ 70.7143       │ 76.6667             │ 63.8779      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 7            │ Arquitetura (32, 32)     │ relu                 │ rmsprop      │ 32                │ 93.2857       │ 94.6667             │ 17.2456      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 8            │ Arquitetura (32, 32)     │ relu                 │ rmsprop      │ 64                │ 90.4286       │ 91.3333             │ 22.4487      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 9            │ Arquitetura (32, 32)     │ relu                 │ rmsprop      │ 128               │ 88.7143       │ 88                  │ 32.2217      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 10           │ Arquitetura (32, 32)     │ tanh                 │ adam         │ 32                │ 89            │ 92                  │ 25.1247      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 11           │ Arquitetura (32, 32)     │ tanh                 │ adam         │ 64                │ 85.7143       │ 86                  │ 35.3843      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 12           │ Arquitetura (32, 32)     │ tanh                 │ adam         │ 128               │ 82.5714       │ 83.3333             │ 44.6376      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 13           │ Arquitetura (32, 32)     │ tanh                 │ sgd          │ 32                │ 79.7143       │ 83.3333             │ 49.0935      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 14           │ Arquitetura (32, 32)     │ tanh                 │ sgd          │ 64                │ 76.2857       │ 82                  │ 55.275       │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 15           │ Arquitetura (32, 32)     │ tanh                 │ sgd          │ 128               │ 75.1429       │ 83.3333             │ 57.1586      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 16           │ Arquitetura (32, 32)     │ tanh                 │ rmsprop      │ 32                │ 88.5714       │ 90                  │ 25.8779      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 17           │ Arquitetura (32, 32)     │ tanh                 │ rmsprop      │ 64                │ 88.2857       │ 89.3333             │ 28.4575      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 18           │ Arquitetura (32, 32)     │ tanh                 │ rmsprop      │ 128               │ 85.1429       │ 87.3333             │ 36.7593      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 19           │ Arquitetura (32, 32)     │ sigmoid              │ adam         │ 32                │ 79.8571       │ 80.6667             │ 53.475       │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 20           │ Arquitetura (32, 32)     │ sigmoid              │ adam         │ 64                │ 76.7143       │ 81.3333             │ 57.6022      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 21           │ Arquitetura (32, 32)     │ sigmoid              │ adam         │ 128               │ 73.1429       │ 80.6667             │ 61.4548      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 22           │ Arquitetura (32, 32)     │ sigmoid              │ sgd          │ 32                │ 46.5714       │ 54.6667             │ 96.0045      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 23           │ Arquitetura (32, 32)     │ sigmoid              │ sgd          │ 64                │ 46.5714       │ 54.6667             │ 96.4965      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 24           │ Arquitetura (32, 32)     │ sigmoid              │ sgd          │ 128               │ 46.5714       │ 54.6667             │ 100.928      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 25           │ Arquitetura (32, 32)     │ sigmoid              │ rmsprop      │ 32                │ 82.7143       │ 84.6667             │ 49.9113      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 26           │ Arquitetura (32, 32)     │ sigmoid              │ rmsprop      │ 64                │ 79.4286       │ 84                  │ 55.402       │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 27           │ Arquitetura (32, 32)     │ sigmoid              │ rmsprop      │ 128               │ 72            │ 83.3333             │ 62.2706      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 28           │ Arquitetura (64, 32, 16) │ relu                 │ adam         │ 32                │ 96.2857       │ 95.3333             │ 12.1717      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 29           │ Arquitetura (64, 32, 16) │ relu                 │ adam         │ 64                │ 94.8571       │ 98                  │ 13.5028      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 30           │ Arquitetura (64, 32, 16) │ relu                 │ adam         │ 128               │ 91.7143       │ 92                  │ 19.7867      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 31           │ Arquitetura (64, 32, 16) │ relu                 │ sgd          │ 32                │ 84.5714       │ 86                  │ 38.1151      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 32           │ Arquitetura (64, 32, 16) │ relu                 │ sgd          │ 64                │ 74.1429       │ 82                  │ 53.8725      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 33           │ Arquitetura (64, 32, 16) │ relu                 │ sgd          │ 128               │ 71.1429       │ 78.6667             │ 61.914       │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 34           │ Arquitetura (64, 32, 16) │ relu                 │ rmsprop      │ 32                │ 95.2857       │ 94.6667             │ 11.794       │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 35           │ Arquitetura (64, 32, 16) │ relu                 │ rmsprop      │ 64                │ 93.7143       │ 94.6667             │ 16.5201      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 36           │ Arquitetura (64, 32, 16) │ relu                 │ rmsprop      │ 128               │ 91.8571       │ 90.6667             │ 23.2635      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 37           │ Arquitetura (64, 32, 16) │ tanh                 │ adam         │ 32                │ 90            │ 94                  │ 16.7063      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 38           │ Arquitetura (64, 32, 16) │ tanh                 │ adam         │ 64                │ 89.8571       │ 92.6667             │ 20.2266      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 39           │ Arquitetura (64, 32, 16) │ tanh                 │ adam         │ 128               │ 87.8571       │ 90.6667             │ 28.1994      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 40           │ Arquitetura (64, 32, 16) │ tanh                 │ sgd          │ 32                │ 81.1429       │ 84.6667             │ 46.1801      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 41           │ Arquitetura (64, 32, 16) │ tanh                 │ sgd          │ 64                │ 82.7143       │ 84                  │ 47.7204      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 42           │ Arquitetura (64, 32, 16) │ tanh                 │ sgd          │ 128               │ 75.1429       │ 80.6667             │ 55.8973      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 43           │ Arquitetura (64, 32, 16) │ tanh                 │ rmsprop      │ 32                │ 90.1429       │ 92                  │ 18.7298      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 44           │ Arquitetura (64, 32, 16) │ tanh                 │ rmsprop      │ 64                │ 88.8571       │ 94                  │ 19.4616      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 45           │ Arquitetura (64, 32, 16) │ tanh                 │ rmsprop      │ 128               │ 87.7143       │ 90                  │ 24.2241      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 46           │ Arquitetura (64, 32, 16) │ sigmoid              │ adam         │ 32                │ 86.2857       │ 86.6667             │ 42.0308      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 47           │ Arquitetura (64, 32, 16) │ sigmoid              │ adam         │ 64                │ 82            │ 84                  │ 49.6746      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 48           │ Arquitetura (64, 32, 16) │ sigmoid              │ adam         │ 128               │ 77.4286       │ 82.6667             │ 57.1715      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 49           │ Arquitetura (64, 32, 16) │ sigmoid              │ sgd          │ 32                │ 46.5714       │ 54.6667             │ 99.8019      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 50           │ Arquitetura (64, 32, 16) │ sigmoid              │ sgd          │ 64                │ 46.5714       │ 54.6667             │ 100.615      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 51           │ Arquitetura (64, 32, 16) │ sigmoid              │ sgd          │ 128               │ 46.5714       │ 54.6667             │ 100.874      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 52           │ Arquitetura (64, 32, 16) │ sigmoid              │ rmsprop      │ 32                │ 86.4286       │ 88                  │ 41.5967      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 53           │ Arquitetura (64, 32, 16) │ sigmoid              │ rmsprop      │ 64                │ 78.7143       │ 84                  │ 55.1186      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 54           │ Arquitetura (64, 32, 16) │ sigmoid              │ rmsprop      │ 128               │ 77.4286       │ 83.3333             │ 58.6234      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 55           │ Arquitetura (128, 64)    │ relu                 │ adam         │ 32                │ 97.8571       │ 98                  │ 10.0167      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 56           │ Arquitetura (128, 64)    │ relu                 │ adam         │ 64                │ 96.2857       │ 96.6667             │ 12.2983      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 57           │ Arquitetura (128, 64)    │ relu                 │ adam         │ 128               │ 94.5714       │ 93.3333             │ 17.7367      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 58           │ Arquitetura (128, 64)    │ relu                 │ sgd          │ 32                │ 84            │ 83.3333             │ 42.5011      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 59           │ Arquitetura (128, 64)    │ relu                 │ sgd          │ 64                │ 75.4286       │ 80.6667             │ 53.323       │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 60           │ Arquitetura (128, 64)    │ relu                 │ sgd          │ 128               │ 71.5714       │ 82                  │ 61.1862      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 61           │ Arquitetura (128, 64)    │ relu                 │ rmsprop      │ 32                │ 96.1429       │ 95.3333             │ 12.9566      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 62           │ Arquitetura (128, 64)    │ relu                 │ rmsprop      │ 64                │ 95            │ 94.6667             │ 14.5757      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 63           │ Arquitetura (128, 64)    │ relu                 │ rmsprop      │ 128               │ 93.4286       │ 93.3333             │ 18.4873      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 64           │ Arquitetura (128, 64)    │ tanh                 │ adam         │ 32                │ 92.2857       │ 95.3333             │ 17.3307      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 65           │ Arquitetura (128, 64)    │ tanh                 │ adam         │ 64                │ 89.1429       │ 93.3333             │ 21.5521      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 66           │ Arquitetura (128, 64)    │ tanh                 │ adam         │ 128               │ 86.5714       │ 86.6667             │ 35.6478      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 67           │ Arquitetura (128, 64)    │ tanh                 │ sgd          │ 32                │ 80            │ 81.3333             │ 50.5597      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 68           │ Arquitetura (128, 64)    │ tanh                 │ sgd          │ 64                │ 76.5714       │ 82                  │ 54.2217      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 69           │ Arquitetura (128, 64)    │ tanh                 │ sgd          │ 128               │ 75.5714       │ 81.3333             │ 55.0067      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 70           │ Arquitetura (128, 64)    │ tanh                 │ rmsprop      │ 32                │ 90.7143       │ 92.6667             │ 19.303       │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 71           │ Arquitetura (128, 64)    │ tanh                 │ rmsprop      │ 64                │ 88.2857       │ 94.6667             │ 22.2882      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 72           │ Arquitetura (128, 64)    │ tanh                 │ rmsprop      │ 128               │ 88.4286       │ 90                  │ 25.9967      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 73           │ Arquitetura (128, 64)    │ sigmoid              │ adam         │ 32                │ 82.7143       │ 84.6667             │ 42.6029      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 74           │ Arquitetura (128, 64)    │ sigmoid              │ adam         │ 64                │ 80.4286       │ 84.6667             │ 52.1224      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 75           │ Arquitetura (128, 64)    │ sigmoid              │ adam         │ 128               │ 77.5714       │ 84                  │ 56.2238      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 76           │ Arquitetura (128, 64)    │ sigmoid              │ sgd          │ 32                │ 50.5714       │ 59.3333             │ 89.5272      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 77           │ Arquitetura (128, 64)    │ sigmoid              │ sgd          │ 64                │ 46.5714       │ 54.6667             │ 97.3877      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 78           │ Arquitetura (128, 64)    │ sigmoid              │ sgd          │ 128               │ 46.5714       │ 54.6667             │ 98.4208      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 79           │ Arquitetura (128, 64)    │ sigmoid              │ rmsprop      │ 32                │ 84.2857       │ 86                  │ 36.9583      │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 80           │ Arquitetura (128, 64)    │ sigmoid              │ rmsprop      │ 64                │ 81.8571       │ 82.6667             │ 51.616       │\n",
      "├──────────────┼──────────────────────────┼──────────────────────┼──────────────┼───────────────────┼───────────────┼─────────────────────┼──────────────┤\n",
      "│ 81           │ Arquitetura (128, 64)    │ sigmoid              │ rmsprop      │ 128               │ 77.8571       │ 82.6667             │ 56.1573      │\n",
      "╘══════════════╧══════════════════════════╧══════════════════════╧══════════════╧═══════════════════╧═══════════════╧═════════════════════╧══════════════╛\n"
     ]
    }
   ],
   "source": [
    "headers = ['Combinação', 'Arquitetura', 'Função de Ativação', 'Otimizador', 'Tamanho do Lote', 'Train Score', ' Validation Score', 'Final Loss']\n",
    "table = tabulate(table_data, headers, tablefmt='fancy_grid', numalign='left')\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Avaliando melhor rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1722 - accuracy: 0.9467\n",
      "Melhor modelo - Acurácia no conjunto de teste: 94.67%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f'Melhor modelo - Acurácia no conjunto de teste: {test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) Predição do melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) Matriz Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transformar as previsões de volta para as classes originais\n",
    "y_pred_classes = label_encoder.inverse_transform(np.argmax(y_pred, axis=1))\n",
    "y_test_classes = label_encoder.inverse_transform(np.argmax(y_test, axis=1))\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test_classes, y_pred_classes)  \n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Bem', 'Médio', 'Mal'], yticklabels=['Bem', 'Médio', 'Mal'])\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3) Métricas de eficácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "Acurácia no conjunto de teste: 94.67%\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        62\n",
      "           1       0.91      0.93      0.92        46\n",
      "           2       0.93      0.90      0.92        42\n",
      "\n",
      "    accuracy                           0.95       150\n",
      "   macro avg       0.94      0.94      0.94       150\n",
      "weighted avg       0.95      0.95      0.95       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------------------------------------\")\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)  \n",
    "print(f'Acurácia no conjunto de teste: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "print(\"----------------------------------------------------------------\\n\")\n",
    "classification_rep = classification_report(y_test_classes, y_pred_classes)\n",
    "print(f'Relatório de Classificação:\\n{classification_rep}')\n",
    "\n",
    "\n",
    "# precision = precision_score(y_test, y_pred)  # Substitua y_test e y_pred pelos seus dados reais e previstos\n",
    "# print(f'Precisão: {precision}')\n",
    "\n",
    "# recall = recall_score(y_test, y_pred)  # Substitua y_test e y_pred pelos seus dados reais e previstos\n",
    "# print(f'Recall: {recall}')\n",
    "\n",
    "# f1 = f1_score(y_test, y_pred)  # Substitua y_test e y_pred pelos seus dados reais e previstos\n",
    "# print(f'Medida F: {f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
